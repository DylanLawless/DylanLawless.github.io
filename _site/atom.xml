<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">

 <title>Tom Preston-Werner</title>
 <link href="https://tom.preston-werner.com/atom.xml" rel="self"/>
 <link href="https://tom.preston-werner.com/"/>
 <updated>2021-06-19T23:55:43+02:00</updated>
 <id>https://tom.preston-werner.com/</id>
 <author>
   <name>Tom Preston-Werner</name>
   <email>tom@mojombo.com</email>
 </author>

 
 <entry>
   <title>Weeknotes</title>
   <link href="https://tom.preston-werner.com/2021/06/14/weeknotes.html"/>
   <updated>2021-06-14T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2021/06/14/weeknotes</id>
   <content type="html">&lt;h1 id=&quot;weeknotes&quot;&gt;Weeknotes&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;14 June 2021&lt;/p&gt;

&lt;h1 id=&quot;work&quot;&gt;Work&lt;/h1&gt;

&lt;h1 id=&quot;personal&quot;&gt;Personal&lt;/h1&gt;

&lt;h1 id=&quot;reading&quot;&gt;Reading&lt;/h1&gt;

&lt;h1 id=&quot;other-media&quot;&gt;Other media&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Adam Curtis documentary: &lt;a href=&quot;https://www.youtube.com/watch?v=xanSAr83w-k&amp;amp;list=PLt4ukDNowDWc0AvV8pImCrk4pK_tZXOyF&amp;amp;index=2&quot;&gt;Cant Get You Out of My Head E02&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Weeknotes</title>
   <link href="https://tom.preston-werner.com/2021/06/07/weeknotes.html"/>
   <updated>2021-06-07T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2021/06/07/weeknotes</id>
   <content type="html">&lt;h1 id=&quot;weeknotes&quot;&gt;Weeknotes&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;7 June 2021&lt;/p&gt;

&lt;h1 id=&quot;work&quot;&gt;Work&lt;/h1&gt;

&lt;h1 id=&quot;personal&quot;&gt;Personal&lt;/h1&gt;

&lt;h1 id=&quot;reading&quot;&gt;Reading&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Honourable_Schoolboy&quot;&gt;The Honourable Schoolboy&lt;/a&gt;, John le Carré.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/Advanced-Level-Statistics-Francis/dp/0859508137&quot;&gt;Advanced level statistics&lt;/a&gt;, A. Francis. A good read on basic fundamentals but not a prefered over other modern textbooks with R code.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;other-media&quot;&gt;Other media&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Oliver Nelson - &lt;a href=&quot;https://www.youtube.com/watch?v=k-zaI8lLrQA&quot;&gt;The Blues And The Abstract Truth 1961&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Podcast - BBC, In Our Time with Melvyn Bragg, &lt;a href=&quot;https://www.bbc.co.uk/programmes/b0435jyv&quot;&gt;Photosynthesis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Adam Curtis documentary: &lt;a href=&quot;https://www.youtube.com/watch?v=hqX1J-1LyzA&amp;amp;list=PLt4ukDNowDWc0AvV8pImCrk4pK_tZXOyF&amp;amp;index=1&quot;&gt;Cant Get You Out of My Head E01&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>SARS-CoV-2 variants of concern</title>
   <link href="https://tom.preston-werner.com/2021/06/07/variants_of_concern.html"/>
   <updated>2021-06-07T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2021/06/07/variants_of_concern</id>
   <content type="html">&lt;h1 id=&quot;sars-cov-2-variants-of-concern&quot;&gt;SARS-CoV-2 variants of concern&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;07 June 2021&lt;/p&gt;

&lt;h1 id=&quot;variants-of-concern-aligned-to-vaccine-coding-sequences&quot;&gt;Variants of concern aligned to vaccine coding sequences&lt;/h1&gt;

&lt;p&gt;This work has not been peer reviewed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.pdf&quot;&gt;Open PDF visualisation - variants_of_concern_to_vaccine.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;aims-and-results&quot;&gt;Aims and results&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;To produce standardized alignments of vaccine sequences.&lt;/li&gt;
  &lt;li&gt;Determine which are at risk to emerging variants.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the data presented within:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The translated amino acid sequences for all vaccines were derived.&lt;/li&gt;
  &lt;li&gt;These were aligned to the SARS-CoV-2 reference amino acid sequences of spike glycoprotein.&lt;/li&gt;
  &lt;li&gt;Known variants-of-concern were then annotated and visualised.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Variants-of-concern for five SARS-CoV-2 strains 
(&lt;a href=&quot;https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-info.html?CDC_AA_refVal=https%3A%2F%2Fwww.cdc.gov%2Fcoronavirus%2F2019-ncov%2Fcases-updates%2Fvariant-surveillance%2Fvariant-info.html&quot;&gt;CDC 4 Jun 2021&lt;/a&gt;)
are illustrated against the 
translated amino acid sequences of the vaccines;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Moderna mRNA-1273&lt;/li&gt;
  &lt;li&gt;Pfizer/BioNTech BNT-162b2&lt;/li&gt;
  &lt;li&gt;Janssen/Johnson &amp;amp; Johnson Ad26.COV2-S&lt;/li&gt;
  &lt;li&gt;Novavax NVX-CoV2373&lt;/li&gt;
  &lt;li&gt;Curevac CVnCoV&lt;/li&gt;
  &lt;li&gt;Sputnik V&lt;/li&gt;
  &lt;li&gt;AstraZeneca AZD1222&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and reference genome sequences;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;QHD43416.1 [MN908947.3] and&lt;/li&gt;
  &lt;li&gt;YP_009724390.1 [NC_045512.2].&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The variants-of-concern are shown here, illustrated on the protein structure;
&lt;a href=&quot;https://www.rcsb.org/structure/6ZOX&quot;&gt;6ZOX.pdb DOI: 10.2210/pdb6ZOX/pdb&lt;/a&gt;
&lt;em&gt;Structure of Disulphide-stabilized SARS-CoV-2 Spike Protein Trimer (x2 disulphide-bond mutant, G413C, V987C, single Arg S1/S2 cleavage site),&lt;/em&gt;
provided by Xiong et al., 2020 &lt;a href=&quot;https://www.nature.com/articles/s41594-020-0478-5&quot;&gt;10.1038/s41594-020-0478-5&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_front.jpg&quot;&gt;6zox_voc_20210604_front.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_side.jpg&quot;&gt;6zox_voc_20210604_side.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_top.jpg&quot;&gt;6zox_voc_20210604_top.jpg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/6zox_voc_20210604_stage.gif&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Two of the defining genetic features that are different between vaccines are seen here,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the S glycoprotein furin cleavage modification region (p.682-685)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/snapshot_furin_cleavage_region.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the S glycoprotein stabilization modification region (p.986-987)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/snapshot_stabilizing_region_PP.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Visual alignment is shown against translated coding sequence for spike glycoprotein,
illustrated here via&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://nextstrain.org/sars-cov-2&quot;&gt;nextstrain.org&lt;/a&gt;.
&lt;img src=&quot;/images/posts/nextstrain_spike.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Fasta sequences are included for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Variants of Concern B.1.1.7&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.351&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.427&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.429&lt;/li&gt;
  &lt;li&gt;Variants of Concern P.1&lt;/li&gt;
  &lt;li&gt;Ref QHD43416.1 [MN908947.3]&lt;/li&gt;
  &lt;li&gt;Ref YP_009724390.1 [NC_045512.2]&lt;/li&gt;
  &lt;li&gt;mRNA-1273 vaccine translated&lt;/li&gt;
  &lt;li&gt;BNT-162b2 vaccine translated&lt;/li&gt;
  &lt;li&gt;Ad26.COV2-S vaccine translated&lt;/li&gt;
  &lt;li&gt;NVX-CoV2373 vaccine translated&lt;/li&gt;
  &lt;li&gt;Sputnik V alleged unmodified YP_009724390.1&lt;/li&gt;
  &lt;li&gt;AZD1222 alleged unmodified YP_009724390.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference-genome-sequence&quot;&gt;Reference genome sequence&lt;/h2&gt;
&lt;p&gt;The two reference sequences that are used by vaccine developers are;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Complete genome DNA and translated coding sequences:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/nuccore/NC_045512.2&quot;&gt;NC_045512.2&lt;/a&gt;,&lt;/li&gt;
      &lt;li&gt;Protein ID for spike glycoprotein &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/protein/YP_009724390.1&quot;&gt;YP_009724390.1&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;Date: 18-JUL-2020&lt;/li&gt;
      &lt;li&gt;This the same translated protein sequence as that is referred to based on genomic coordinates &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/nuccore/NC_045512&quot;&gt;NC_045512.2:21563-25384 translated GU280_gp02&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Complete genome DNA and translated coding sequences:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/nuccore/mn908947.3&quot;&gt;MN908947.3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Protein ID for spike glycoprotein &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/protein/QHD43416.1&quot;&gt;QHD43416.1&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Date: 18-MAR-2020&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both reference sequences are provided in files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_reference_sequence/reference_sequence_NC_045512.2.21563-25384.md&quot;&gt;reference_sequence_NC_045512.2.21563-25384.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_reference_sequence/reference_sequence_MN908947.3.md&quot;&gt;reference_sequence_MN908947.3.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vaccine-sequence-reproduction&quot;&gt;Vaccine sequence reproduction&lt;/h2&gt;
&lt;p&gt;The sequences for vaccines have been reproduced by careful reconstruction based on&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The authors’ reported reference sequence and&lt;/li&gt;
  &lt;li&gt;The description of the genetic modifications used during vaccine development.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The primary sources are provided in each case, along with a detailed description of the genetic variants provided by authors.
Additionally, the correct &lt;a href=&quot;https://varnomen.hgvs.org/recommendations&quot;&gt;HGVS-recommended nomenclature&lt;/a&gt; has been used for more reliable reproduction than some of the primary sources.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For visual simplicity, an X symbol was used to illustrate amino acid deletions&lt;/strong&gt;.
All other amino acid changes use their correct symbol.&lt;/p&gt;

&lt;p&gt;For vaccines BNT-162b2 and mRNA-1273, the assemblies have also been sourced from &lt;a href=&quot;https://github.com/NAalytics/Assemblies-of-putative-SARS-CoV2-spike-encoding-mRNA-sequences-for-vaccines-BNT-162b2-and-mRNA-1273&quot;&gt;NAalytics&lt;/a&gt;.
This data matches the vaccine sequences that have been reproduced here based on primary literature.
Briefly, 
their experimental sequence information from the initial 
Moderna (&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/32756549/&quot;&gt;Corbett Nature 2020 Oct&lt;/a&gt;)
and Pfizer/BioNTech (&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/33301246/&quot;&gt;Polack NEJM 2020 Dec&lt;/a&gt;)
COVID-19 vaccines, allowed them to produce a working assembly of the former 
and a confirmation of previously reported sequence information for the latter RNA.
Their data was sourced and formatted to select the coding sequences.
The nucleotide sequences were then translated into amino acid coding sequences
using &lt;a href=&quot;https://web.expasy.org/translate/&quot;&gt;https://web.expasy.org/translate/&lt;/a&gt;,
as shown in files:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_mRNA-1273.md&quot;&gt;sarscov2_vaccine_sequence_translated_mRNA-1273.md&lt;/a&gt;
&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_BNT-162b2.md&quot;&gt;sarscov2_vaccine_sequence_translated_BNT-162b2.md&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;covid-19-vaccine-sequences-summarised&quot;&gt;Covid-19 vaccine sequences summarised&lt;/h2&gt;
&lt;p&gt;The correct &lt;a href=&quot;https://varnomen.hgvs.org/recommendations/protein/variant/delins/&quot;&gt;HGVS standard notation is used&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mRNA-1273
    &lt;ul&gt;
      &lt;li&gt;Genetics: p.(Lys986_Val987delinsProPro)			- stabilizing x2 (PP)&lt;/li&gt;
      &lt;li&gt;Delivery: Lipid-nanoparticle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BNT162b2
    &lt;ul&gt;
      &lt;li&gt;Genetics: p.(Lys986_Val987delinsProPro)			- stabilizing x2 (PP)&lt;/li&gt;
      &lt;li&gt;Delivery: Lipid-nanoparticle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ad26.COV2-S
    &lt;ul&gt;
      &lt;li&gt;Genetics: p.[Arg682Ser;p.Arg685Gln]				- furin cleavage x2 (SRAG)&lt;/li&gt;
      &lt;li&gt;Genetics: p.(Lys986_Val987delinsProPro)			- stabilizing x2 (PP)&lt;/li&gt;
      &lt;li&gt;Delivery: Adenovirus vector (Ad26)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;NVX-CoV2373
    &lt;ul&gt;
      &lt;li&gt;Genetics: p.[Arg682_Arg683delinsGlnGln;Arg685Gln]	- furin cleavage x3 (GGAG)&lt;/li&gt;
      &lt;li&gt;Genetics: p.(Lys986_Val987delinsProPro)				- stabilizing x2 (PP)&lt;/li&gt;
      &lt;li&gt;Delivery: Lipid-nanoparticle, baculovirus expression cultured in Sf9&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sputnik V
    &lt;ul&gt;
      &lt;li&gt;Genetics: “unmodified” full-length S-protein&lt;/li&gt;
      &lt;li&gt;Genetics: No reference sequence found&lt;/li&gt;
      &lt;li&gt;Delivery: Adenovirus vectors (Ad26 dose 1) and (Ad5 dose 2)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Incomplete others:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;CVnCoV
    &lt;ul&gt;
      &lt;li&gt;Genetics: modified S protein.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AZD1222
    &lt;ul&gt;
      &lt;li&gt;Genetics: Unmodified S protein&lt;/li&gt;
      &lt;li&gt;Genetics: No reference sequence found&lt;/li&gt;
      &lt;li&gt;Adenovirus vector (ChAdOx1).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CoronaVac
    &lt;ul&gt;
      &lt;li&gt;a preparation of inactivated SARS-CoV-2 virions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;covid-19-vaccine-details&quot;&gt;Covid-19 vaccine details&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;BioNTech/Pfizer: BNT162b2
    &lt;ul&gt;
      &lt;li&gt;Modified mRNA-in-lipid-nanoparticle vaccine&lt;/li&gt;
      &lt;li&gt;Expressing a modified S protein.&lt;/li&gt;
      &lt;li&gt;Stabiliazation by proline substitutions p.K986P, p.V987P.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Moderna: mRNA-1273
    &lt;ul&gt;
      &lt;li&gt;Modified mRNA-in-lipid-nanoparticle vaccine&lt;/li&gt;
      &lt;li&gt;Expressing a modified S protein.&lt;/li&gt;
      &lt;li&gt;Stabiliazation by proline substitutions p.K986P, p.V987P.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Janssen/Johnson &amp;amp; Johnson: Ad26.COV2-S aka JNJ-78436735
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.07.30.227470v1&quot;&gt;Pre-prindt&lt;/a&gt;, &lt;a href=&quot;https://www.nature.com/articles/s41541-020-00243-x&quot;&gt;Published&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;Adenovirus serotype 26 (Ad26) viral vector vaccine&lt;/li&gt;
      &lt;li&gt;Expressing a modified S protein.&lt;/li&gt;
      &lt;li&gt;S protein of SARS-CoV-2 corresponding to positions 21,536–25,384 in SARS-CoV-2 isolate Wuhan-Hu-1 (genome MN908947 (18-MAR-2020))&lt;a href=&quot;https://www.nature.com/articles/s41541-020-00243-x&quot;&gt;Published&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;For Ad26.S.PP, the two stabilising variants p.(Lys986_Val987delinsProPro) are included as well as two mutations in the furin cleavage site that preserve the prefusion conformation and blocks shedding of S1.&lt;/li&gt;
      &lt;li&gt;The furin cleavage site was abolished by amino acid changes p.R682S and p.R685G.&lt;/li&gt;
      &lt;li&gt;Stabiliazation by proline substitutions p.K986P, p.V987P.&lt;/li&gt;
      &lt;li&gt;The correct &lt;a href=&quot;https://varnomen.hgvs.org/recommendations/protein/variant/delins/&quot;&gt;HGVS standard notation&lt;/a&gt; should be: p.[Arg682Ser;p.Arg685Gln] and p.(Lys986_Val987delinsProPro).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Novavax: NVX-CoV2373
    &lt;ul&gt;
      &lt;li&gt;A protein subunit vaccine containing a doubly modified S protein, with adjuvant.&lt;/li&gt;
      &lt;li&gt;Part of a 27.2nm nanoparticle.&lt;/li&gt;
      &lt;li&gt;S protein of SARS-CoV-2 corresponding to GenBank MN908947 nucleotides 21563-25384 &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7584426/&quot;&gt;as published&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;Contains the modified S protein with the two Proline substitutions, K986P and V987P. Additionally, three amino acids are changed (682-RRAR-685 to 682-QQAQ-685) to protect the protein against proteases.&lt;/li&gt;
      &lt;li&gt;The authors failed to write the correct &lt;a href=&quot;https://varnomen.hgvs.org/recommendations/protein/variant/delins/&quot;&gt;HGVS standard notation&lt;/a&gt;: p.[Arg682_Arg683delinsGlnGln;Arg685Gln] and p.(Lys986_Val987delinsProPro),
a simple list would even be better: p.R682Q, p.R683Q, p.R685Q, p.K986P, and p.V987P.&lt;/li&gt;
      &lt;li&gt;Saponin-based Matrix-M adjuvent.&lt;/li&gt;
      &lt;li&gt;Protein expression by a baculovirus in an Sf9 insect infection culture.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.06.29.178509v1.full.pdf&quot;&gt;https://www.biorxiv.org/content/10.1101/2020.06.29.178509v1.full.pdf&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Delivery in lipid nanoparticle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gamaleya Research Institute of Epidemiology and Microbiology: Sputnik V
    &lt;ul&gt;
      &lt;li&gt;aka Гам-КОВИД-Вак (Gam-COVID-Vac).&lt;/li&gt;
      &lt;li&gt;Two differnt adenovirus viral vectors.&lt;/li&gt;
      &lt;li&gt;Uses two different adenovirus serotypes; &lt;a href=&quot;https://sputnikvaccine.com/about-vaccine/&quot;&gt;recombinant Ad26 (dose 1) and recombinant Ad5 (dose 2)&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;Both carrying the gene for Spike glycoprotein (rAd26-S and rAd5-S).&lt;/li&gt;
      &lt;li&gt;Antigen insert is an “unmodified” full-length S-protein (no reference sequence).&lt;/li&gt;
      &lt;li&gt;Produced in HEK293 cell line.&lt;/li&gt;
      &lt;li&gt;No reference sequence found&lt;/li&gt;
      &lt;li&gt;The first major paper [Logunov et al Lancet. 2020] is this clinical trial of frozen and lyophilised vaccine. It mentions previous unpublished pre-clinical trials. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7471804/&quot;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7471804/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Curevac: CVnCoV
    &lt;ul&gt;
      &lt;li&gt;Unmodified mRNA-in-lipid-nanoparticle vaccine&lt;/li&gt;
      &lt;li&gt;Expressing a modified S protein.&lt;/li&gt;
      &lt;li&gt;Based on genome from first isolate &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/nuccore/NC_045512.2&quot;&gt;NC_045512.2&lt;/a&gt;, Spike glycoprotein &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/protein/YP_009724390.1&quot;&gt;YP_009724390.1&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;full-length S featuring K986P and V987P mutations.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/33863911/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/33863911/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Oxford/AstraZeneca: AZD1222 (formerly ChAdOx1 nCoV-19)
    &lt;ul&gt;
      &lt;li&gt;A viral vector vaccine&lt;/li&gt;
      &lt;li&gt;Viral vector (ChAdOx1 - chimpanzee adenovirus Oxford 1, &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/22808149/&quot;&gt;as published&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;Expressing the unmodified S protein.&lt;/li&gt;
      &lt;li&gt;No reference sequence found&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.thelancet.com/retrieve/pii/S0140673620316044&quot;&gt;Folegatti et al, Lancet July 2020&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vaccine-multiple-sequence-alignment&quot;&gt;Vaccine Multiple Sequence Alignment&lt;/h2&gt;
&lt;p&gt;The amino acid sequences of the coding region from each of the vaccine sequences 
and the reference sequence were used for multiple sequence alignment
via &lt;a href=&quot;https://www.ebi.ac.uk/Tools/msa/clustalo/&quot;&gt;https://www.ebi.ac.uk/Tools/msa/clustalo/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Variants-of-concern were then formatted to be used for annotation on the 
aligned sequences.&lt;/p&gt;

&lt;h2 id=&quot;variants-of-concern&quot;&gt;Variants of concern&lt;/h2&gt;
&lt;p&gt;SARS-CoV-2 Variant Classifications and Definitions were derived from
&lt;a href=&quot;https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-info.html?CDC_AA_refVal=https%3A%2F%2Fwww.cdc.gov%2Fcoronavirus%2F2019-ncov%2Fcases-updates%2Fvariant-surveillance%2Fvariant-info.html&quot;&gt;https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-info.html?CDC_AA_refVal=https%3A%2F%2Fwww.cdc.gov%2Fcoronavirus%2F2019-ncov%2Fcases-updates%2Fvariant-surveillance%2Fvariant-info.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This dataset includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Variants of Interest (VOI)&lt;/li&gt;
  &lt;li&gt;Variants of Concern (VOC)&lt;/li&gt;
  &lt;li&gt;Variants of High Consequence (VOHC)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The reformatted tables are presented in files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern.xlsx&quot;&gt;variants_of_concern.xlsx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern.csv&quot;&gt;variants_of_concern.csv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are currently no VOHC. 
VOC (but not VOI) were presented in the final visualisation.&lt;/p&gt;

&lt;h2 id=&quot;aligned-variants-of-concern-to-vaccine&quot;&gt;Aligned variants-of-concern to vaccine&lt;/h2&gt;

&lt;p&gt;The variants of concern were formatted such that one pseudo-fasta format entry 
contains the amino acid change for each strain. 
This data was then added to the multiple sequence alignment file to allow for
aligned annotations,
as shown in file:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.fa&quot;&gt;variants_of_concern_to_vaccine.fa&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The file contains the list the variants-of-concern for five Sars-CoV-2 strains,
2 reference sequence, and
6 vaccine sequences:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Variants of Concern B.1.1.7&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.351&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.427&lt;/li&gt;
  &lt;li&gt;Variants of Concern B.1.429&lt;/li&gt;
  &lt;li&gt;Variants of Concern P.1&lt;/li&gt;
  &lt;li&gt;Ref QHD43416.1 [MN908947.3]&lt;/li&gt;
  &lt;li&gt;Ref YP_009724390.1 [NC_045512.2]&lt;/li&gt;
  &lt;li&gt;mRNA-1273 vaccine translated&lt;/li&gt;
  &lt;li&gt;BNT-162b2 vaccine translated&lt;/li&gt;
  &lt;li&gt;Ad26.COV2-S vaccine translated&lt;/li&gt;
  &lt;li&gt;NVX-CoV2373 vaccine translated&lt;/li&gt;
  &lt;li&gt;Sputnik V alleged unmodified YP_009724390.1&lt;/li&gt;
  &lt;li&gt;AZD1222 alleged unmodified YP_009724390.1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/coronavirus-cutaway-600.png&quot; width=&quot;20%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Different strains will contain benign variants.
Typically, full sequences are used for alignment. 
However, this can be visually distracting.
Instead, only the variants-of-concern are annotated for the strain sequences.&lt;/p&gt;

&lt;p&gt;The final illustration was made using &lt;a href=&quot;https://www.snapgene.com&quot;&gt;https://www.snapgene.com&lt;/a&gt; software.
The snapgene-software formatted output can be loaded with the file:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.praln&quot;&gt;variants_of_concern_to_vaccine.praln&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The final PDF version is shown in file:
&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.pdf&quot;&gt;Open PDF visualisation&lt;/a&gt;
&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.pdf&quot;&gt;variants_of_concern_to_vaccine.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-files&quot;&gt;Main files&lt;/h2&gt;

&lt;p&gt;The main files that might interst you are listed here together.
Other files that are not listed contain intermediate data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2#readme&quot;&gt;README.md&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_reference_sequence/reference_sequence_NC_045512.2.21563-25384.md&quot;&gt;reference_sequence_NC_045512.2.21563-25384.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_reference_sequence/reference_sequence_MN908947.3.md&quot;&gt;reference_sequence_MN908947.3.md&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_mRNA-1273.md&quot;&gt;sarscov2_vaccine_sequence_translated_mRNA-1273.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_BNT-162b2.md&quot;&gt;sarscov2_vaccine_sequence_translated_BNT-162b2.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_NVX-CoV2373.md&quot;&gt;sarscov2_vaccine_sequence_translated_NVX-CoV2373.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_Ad26.COV2-S.md&quot;&gt;sarscov2_vaccine_sequence_translated_Ad26.COV2-S.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_AZD1222.md&quot;&gt;sarscov2_vaccine_sequence_translated_AZD1222.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_NVX-CoV2373.md&quot;&gt;sarscov2_vaccine_sequence_translated_NVX-CoV2373.md&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/sarscov2_vaccine_sequences_translated/sarscov2_vaccine_sequence_translated_Sputnik-V.md&quot;&gt;sarscov2_vaccine_sequence_translated_Sputnik-V.md&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern.xlsx&quot;&gt;variants_of_concern.xlsx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern.csv&quot;&gt;variants_of_concern.csv&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.fa&quot;&gt;variants_of_concern_to_vaccine.fa&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.praln&quot;&gt;variants_of_concern_to_vaccine.praln&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/blob/master/variants_of_concern_to_vaccine.pdf&quot;&gt;variants_of_concern_to_vaccine.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;pdb/6zox.pdb&quot;&gt;Protein structure, original structure file&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/6zox_voc_20210604_stage.vmd&quot;&gt;Protein structure, VMD visualisation state 6zox_voc_20210604_stage.vmd&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_front.jpg&quot;&gt;Protein structure with variants of concern 6zox_voc_20210604_front.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_side.jpg&quot;&gt;Protein structure with variants of concern 6zox_voc_20210604_side.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DylanLawless/variants_of_concern_to_vaccine_SARS-CoV2/tree/master/pdb/renders/6zox_voc_20210604_top.jpg&quot;&gt;Protein structure with variants of concern 6zox_voc_20210604_top.jpg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other-notes&quot;&gt;Other notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;notes.md&quot;&gt;notes.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/ribosome-600.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Weeknotes</title>
   <link href="https://tom.preston-werner.com/2021/05/31/weeknotes.html"/>
   <updated>2021-05-31T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2021/05/31/weeknotes</id>
   <content type="html">&lt;h1 id=&quot;weeknotes&quot;&gt;Weeknotes&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;31 May 2021&lt;/p&gt;

&lt;h1 id=&quot;work&quot;&gt;Work&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Testing toy code for viral infection data.&lt;/li&gt;
  &lt;li&gt;Testing LD pruning in viral genomes.&lt;/li&gt;
  &lt;li&gt;Writing results on &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&amp;amp;VirusLineage_ss=Human%20orthopneumovirus,%20taxid:11250&quot;&gt;viral association genetics&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;International collaboration call on host-pathogen interaction, hosted in &lt;a href=&quot;https://www.vanderbilt.edu&quot;&gt;Vanderbilt&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;personal&quot;&gt;Personal&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Website CSS building.&lt;/li&gt;
  &lt;li&gt;Implementing Rake for webdev.&lt;/li&gt;
  &lt;li&gt;Tech4Growth &lt;a href=&quot;https://tech4growth.ch&quot;&gt;workshop&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;reading&quot;&gt;Reading&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Honourable_Schoolboy&quot;&gt;The Honourable Schoolboy&lt;/a&gt;, John le Carré.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/34015270/&quot;&gt;Zhang et al., 2021 AJHG&lt;/a&gt;. A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity.&lt;/li&gt;
  &lt;li&gt;Accelerating Genomic Data Generation and Facilitating Genomic Data Access Using Decentralization, Privacy-Preserving Technologies and Equitable Compensation. &lt;a href=&quot;https://nebula.org/blog/wp-content/uploads/2019/05/Accelerating-Genomic-Data-Generation-and-Facilitating-Genomic-Data-Access.pdf&quot;&gt;Nublua, George Church et al&lt;/a&gt;. (See podcast below for related talk on smart contracts).&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;other-media&quot;&gt;Other media&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Sergei Loznitsa’s monumental &lt;a href=&quot;https://www.imdb.com/title/tt10203842/&quot;&gt;State Funeral&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Yazz Ahmed - &lt;a href=&quot;https://www.youtube.com/watch?v=6kKYzuvxsZo&quot;&gt;Polyhymnia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Floating Points, Pharoah Sanders &amp;amp; The London Symphony Orchestra - &lt;a href=&quot;https://www.youtube.com/watch?v=Mn8x0QbN4f8&amp;amp;t=571s&quot;&gt;Promises&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Ana Vidović - &lt;a href=&quot;https://www.youtube.com/watch?v=e26zZ83Oh6Y&quot;&gt;in concert&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Podcast - Lex Fridman Podcast, &lt;a href=&quot;https://lexfridman.com/sergey-nazarov/&quot;&gt;#181 – Sergey Nazarov: Chainlink, Smart Contracts, and Oracle Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Historical review of rare immune pathway analysis</title>
   <link href="https://tom.preston-werner.com/2021/05/28/pathway_analysis.html"/>
   <updated>2021-05-28T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2021/05/28/pathway_analysis</id>
   <content type="html">&lt;h1 id=&quot;historical-review-of-rare-immune-pathway-analysis&quot;&gt;Historical review of rare immune pathway analysis&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;28 May 2021&lt;/p&gt;
&lt;h1 id=&quot;itan--casanova-contributions&quot;&gt;Itan &amp;amp; Casanova contributions&lt;/h1&gt;

&lt;p&gt;We are tackling this problem of protein pathway analysis from the viewpoint of 
rare immune disease and infection.
Historically, several topics in bioinformatic and functional analysis have 
been required before we could achieve our current position of 
statistically-robust genetic discovery for rare disease:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Candidate variant select for individual genomes&lt;/li&gt;
  &lt;li&gt;Compiling reliable cohorts of patients with shared phenotypes&lt;/li&gt;
  &lt;li&gt;Protein-protein interactions&lt;/li&gt;
  &lt;li&gt;Variant collapse&lt;/li&gt;
  &lt;li&gt;Protein pathway analysis&lt;/li&gt;
  &lt;li&gt;Functional validation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Therefore, a historical review of the timeline is beneficial to illustrate the 
technical successes that allow us to reliably produce candidate variants by
genome sequencing and to validate statistically-driven results by &lt;em&gt;“traditional”&lt;/em&gt;
functional validation. 
These steps [1, 2 and 6 in our list] are exemplified by the following 
historical review. 
The complete list of steps 1-6 are touched on, 
but full validation of each step is the culmination of what we are currently 
working on and will be explicitly reviewed when we have completed our study.&lt;/p&gt;

&lt;p&gt;As one of the leaders in this field, Casanova lab has provided a lot of insider
history to the story in a great twitter thread
&lt;a href=&quot;https://twitter.com/casanova_lab/status/1397539593608695808&quot;&gt;https://twitter.com/casanova_lab/status/1397539593608695808&lt;/a&gt;.
The literature for discussion is first listed here to facilitate downloading 
but sources are referenced as usual throughout.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;2013 PNAS. The human gene connectome as a map of short cuts for morbid allele discovery.
&lt;a class=&quot;citation&quot; href=&quot;#itan2013human&quot;&gt;(Itan et al., 2013)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/23509278/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/23509278/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2014 BMC Gen. HGCS: an online tool for prioritizing disease-causing gene variants by biological distance.
&lt;a class=&quot;citation&quot; href=&quot;#itan2014hgcs&quot;&gt;(Itan et al., 2014)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/24694260/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/24694260/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2015 Front. Novel primary immunodeficiency candidate genes predicted by the human gene connectome.
&lt;a class=&quot;citation&quot; href=&quot;#itan2015novel&quot;&gt;(Itan &amp;amp; Casanova, 2015)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/25883595/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/25883595/&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;2015 PNAS. The human gene damage index as a gene-level approach to prioritizing exome variants.
&lt;a class=&quot;citation&quot; href=&quot;#itan2015human&quot;&gt;(Itan et al., 2015)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/26483451/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/26483451/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2016 NatMet. The mutation significance cutoff: gene-level thresholds for variant predictions.
&lt;a class=&quot;citation&quot; href=&quot;#itan2016mutation&quot;&gt;(Itan et al., 2016)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/26820543/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/26820543/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2015 PNAS. Can the impact of human genetic variations be predicted?
&lt;a class=&quot;citation&quot; href=&quot;#itan2015can&quot;&gt;(Itan &amp;amp; Casanova, 2015)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/26351682/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/26351682/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2018 Bioinf. PopViz: a webserver for visualizing minor allele frequencies and damage prediction scores of human genetic variations.
&lt;a class=&quot;citation&quot; href=&quot;#zhang2018popviz&quot;&gt;(Zhang et al., 2018)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/30535305/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/30535305/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2019 PNAS. Blacklisting variants common in private cohorts but not in public databases optimizes human exome analysis.
&lt;a class=&quot;citation&quot; href=&quot;#maffucci2019blacklisting&quot;&gt;(Maffucci et al., 2019)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/30591557/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/30591557/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2019 NAR. SeqTailor: a user-friendly webserver for the extraction of DNA or protein sequences from next-generation sequencing data.
&lt;a class=&quot;citation&quot; href=&quot;#zhang2019seqtailor&quot;&gt;(Zhang et al., 2019)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/31045209/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/31045209/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;2020 Hum Gen. The human genetic determinism of life-threatening infectious diseases: genetic heterogeneity and physiological homogeneity?
&lt;a class=&quot;citation&quot; href=&quot;#casanova2020human&quot;&gt;(Casanova &amp;amp; Abel, 2020)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/32462426/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/32462426/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2021 JCI. Herpes simplex encephalitis in a patient with a distinctive form of inherited IFNAR1 deficiency.
&lt;a class=&quot;citation&quot; href=&quot;#bastard2021herpes&quot;&gt;(Bastard et al., 2021)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/32960813/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/32960813/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2021 JCI. TLR3 controls constitutive IFN-β antiviral immunity in human fibroblasts and cortical neurons.
&lt;a class=&quot;citation&quot; href=&quot;#gao2021tlr3&quot;&gt;(Gao et al., 2021)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/33393505/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/33393505/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2021 AJHG. A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity
&lt;a class=&quot;citation&quot; href=&quot;#zhang2021computational&quot;&gt;(Zhang et al., 2021)&lt;/a&gt;
&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/34015270/&quot;&gt;https://pubmed.ncbi.nlm.nih.gov/34015270/&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To date, the main paper that implements protein pathway analysis for rare 
immune disease is that by
Peng Zhang and 
Yuval Itan &lt;a class=&quot;citation&quot; href=&quot;#zhang2021computational&quot;&gt;(Zhang et al., 2021)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The history begins with determining methods for candidate variant selection - 
the main challenge in human genomics, 
especially for individual patients who can benefit from precision medicine. 
Over the last decade, we have reached a point where we can now reasonably 
discern individual candidate-causal variants from the background noise of 
genomic variability.&lt;/p&gt;

&lt;p&gt;From the authors’ perspective, the project began around 2011 and its first 
step was concluded in 2013 with 
Yuval Itan’s
first “Human Gene Connectome” paper 
while he was a post-doc with Casanova lab. 
&lt;a class=&quot;citation&quot; href=&quot;#itan2013human&quot;&gt;(Itan et al., 2013)&lt;/a&gt;.
This software connected genes like streets in a map, 
based on their physiological relatedness.
It was soon followed by methodological development 
&lt;a class=&quot;citation&quot; href=&quot;#itan2014hgcs&quot;&gt;(Itan et al., 2014)&lt;/a&gt;
and application to inborn errors of immunity 
&lt;a class=&quot;citation&quot; href=&quot;#itan2015novel&quot;&gt;(Itan &amp;amp; Casanova, 2015)&lt;/a&gt;
or both 
&lt;a class=&quot;citation&quot; href=&quot;#itan2015human&quot;&gt;(Itan et al., 2015)&lt;/a&gt;,
and a couple of necessary detours 
&lt;a class=&quot;citation&quot; href=&quot;#itan2016mutation&quot;&gt;(Itan et al., 2016)&lt;/a&gt;
and 
&lt;a class=&quot;citation&quot; href=&quot;#maffucci2019blacklisting&quot;&gt;(Maffucci et al., 2019)&lt;/a&gt;.
A review was also written by two of the main authors during the same period
&lt;a class=&quot;citation&quot; href=&quot;#itan2015can&quot;&gt;(Itan &amp;amp; Casanova, 2015)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When Peng Zhang joined the Casanova lab as post-doc, 
Yuval Itan had started his own lab. 
However, the pair worked together to continue producing the papers on variant
interpretation and data processing
&lt;a class=&quot;citation&quot; href=&quot;#zhang2018popviz&quot;&gt;(Zhang et al., 2018)&lt;/a&gt;
and
&lt;a class=&quot;citation&quot; href=&quot;#zhang2019seqtailor&quot;&gt;(Zhang et al., 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After completing this period of work, 
they renamed “Human Gene Connectome II” the 
“Network-based Heterogeneity Clustering”.
At this point, their aims were defined as being generally indistinguishable 
from ours. 
That is, &lt;em&gt;“the detection of physiological homogeneity in a cohort of patients 
sharing a clinical phenotype but with high genetic heterogeneity - 
a hallmark of severe infectious diseases”&lt;/em&gt; (Casanova via twitter), 
as presented in their next paper on this topic
&lt;a class=&quot;citation&quot; href=&quot;#casanova2020human&quot;&gt;(Casanova &amp;amp; Abel, 2020)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Shen-Ying Zhang came on board as senior author on the next two papers.
With an excellent database of immune disorders and infections, 
the team could gradually build their software.
Exomes from patients with HSV-1 encephalitis were used for testing successive 
versions in
&lt;a class=&quot;citation&quot; href=&quot;#bastard2021herpes&quot;&gt;(Bastard et al., 2021)&lt;/a&gt; 
and 
&lt;a class=&quot;citation&quot; href=&quot;#gao2021tlr3&quot;&gt;(Gao et al., 2021)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Quoting Casanova &lt;em&gt;“When they were capable of detecting the known TLR3-IFN needles in the HSE stack, they installed camp 1, rested a bit and reported to me on the radio, while I was watching them from the basecamp with binoculars. I encouraged them to push for the final ascent and they did.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;With the same goal as our own - 
producing unbiased methods for detection of biologically-connected causal 
genetic variation - 
they found new gene variants that interact via the TLR3-IFN protein pathway,
in individual patients. 
Shen-Ying Zhang found them to be biochemically deleterious, 
an important factor for validation of genetic-first aproaches. 
In this case, Zhang &lt;em&gt;et al&lt;/em&gt; get as close to the &lt;em&gt;“gold-standard”&lt;/em&gt; 
as anyone to date.&lt;/p&gt;

&lt;p&gt;The functional validation of candidate variants in disease then provided a proof-of-principle indication that they could detect physiological homogeneity in the midst of genetic heterogeneity 
&lt;a class=&quot;citation&quot; href=&quot;#zhang2021computational&quot;&gt;(Zhang et al., 2021)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Quoting Casanova 
&lt;em&gt;“A computational approach for detecting physiological homogeneity in the midst of genetic heterogeity.
That was terrific!”&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;An aside on what I call the &lt;em&gt;“gold-standard”&lt;/em&gt; for our field should be:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Unbiased statistical detection of a genetic phenomenon.&lt;/li&gt;
    &lt;li&gt;Validation by functional models under systematic control.&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;Part [1] Depends on patient cohorts that are large enough to detect the effect based on the phenotype strength - difficult for &lt;em&gt;rare disease&lt;/em&gt;.&lt;br /&gt;
Part [2] Depends on independently testing biological mechanisms.&lt;/p&gt;

  &lt;p&gt;This second step generally consists of two hurdles:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;If the same researchers perform (1) genetic stats and (2) functional work, 
there is a bias that is difficult to avoid when trying to functionally 
validate statistically positive results.&lt;/li&gt;
    &lt;li&gt;If the statistical genetic associations happen to contain a false positive 
for something like severe rare immune disease, 
the sensitive functional models may detect a damaging response. 
One might find a truly damaging biological mechanism, 
but if the statistical genetic association is not correct then this 
biological mechanism should not be deemed causal; 
back-tracking at this stage would be very difficult due to self-imposed bias.&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;Ideally, in the future we hope to see a separation of the two steps 
(stat genetics and wet-lab) such that each are performed independently. 
The wet-lab would also ideally focus their routines on a particular protein 
pathway/system with SOPs that improve accuracy and precision 
(e.g. clinical diagnostics labs, clinical trials) rather than setting up 
models for each new study.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;Returning to our historical review, 
we have been producing our protocols similarly in parallel.
With patient cohorts of comparable sizes and phenotypes we will soon 
have a complementary validation of protocols.
However, great care is also being taken to test and select the most reliable 
statistical methods for association testing - 
an improvement to the fine work by
&lt;a class=&quot;citation&quot; href=&quot;#zhang2021computational&quot;&gt;(Zhang et al., 2021)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Best practices in candidate variant selection protocols are basically 
standardised as of 2021, 
so the main remaining task is standardisation of the protein-pathway 
annotation and association testing methods - 
steps which we will soon be ready to publish after peer-review.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;itan2013human&quot;&gt;Itan, Y., Zhang, S.-Y., Vogt, G., Abhyankar, A., Herman, M., Nitschke, P., Fried, D., Quintana-Murci, L., Abel, L., &amp;amp; Casanova, J.-L. (2013). The human gene connectome as a map of short cuts for morbid allele discovery. &lt;i&gt;Proceedings of the National Academy of Sciences&lt;/i&gt;, &lt;i&gt;110&lt;/i&gt;(14), 5558–5563.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;itan2014hgcs&quot;&gt;Itan, Y., Mazel, M., Mazel, B., Abhyankar, A., Nitschke, P., Quintana-Murci, L., Boisson-Dupuis, S., Boisson, B., Abel, L., Zhang, S.-Y., &amp;amp; others. (2014). HGCS: an online tool for prioritizing disease-causing gene variants by biological distance. &lt;i&gt;BMC Genomics&lt;/i&gt;, &lt;i&gt;15&lt;/i&gt;(1), 1–8.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;itan2015novel&quot;&gt;Itan, Y., &amp;amp; Casanova, J.-L. (2015). Novel primary immunodeficiency candidate genes predicted by the human gene connectome. &lt;i&gt;Frontiers in Immunology&lt;/i&gt;, &lt;i&gt;6&lt;/i&gt;, 142.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;itan2015human&quot;&gt;Itan, Y., Shang, L., Boisson, B., Patin, E., Bolze, A., Moncada-Vélez, M., Scott, E., Ciancanelli, M. J., Lafaille, F. G., Markle, J. G., &amp;amp; others. (2015). The human gene damage index as a gene-level approach to prioritizing exome variants. &lt;i&gt;Proceedings of the National Academy of Sciences&lt;/i&gt;, &lt;i&gt;112&lt;/i&gt;(44), 13615–13620.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;itan2016mutation&quot;&gt;Itan, Y., Shang, L., Boisson, B., Ciancanelli, M. J., Markle, J. G., Martinez-Barricarte, R., Scott, E., Shah, I., Stenson, P. D., Gleeson, J., &amp;amp; others. (2016). The mutation significance cutoff: gene-level thresholds for variant predictions. &lt;i&gt;Nature Methods&lt;/i&gt;, &lt;i&gt;13&lt;/i&gt;(2), 109–110.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;itan2015can&quot;&gt;Itan, Y., &amp;amp; Casanova, J.-L. (2015). Can the impact of human genetic variations be predicted? &lt;i&gt;Proceedings of the National Academy of Sciences&lt;/i&gt;, &lt;i&gt;112&lt;/i&gt;(37), 11426–11427.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;zhang2018popviz&quot;&gt;Zhang, P., Bigio, B., Rapaport, F., Zhang, S.-Y., Casanova, J.-L., Abel, L., Boisson, B., &amp;amp; Itan, Y. (2018). PopViz: a webserver for visualizing minor allele frequencies and damage prediction scores of human genetic variations. &lt;i&gt;Bioinformatics&lt;/i&gt;, &lt;i&gt;34&lt;/i&gt;(24), 4307–4309.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;maffucci2019blacklisting&quot;&gt;Maffucci, P., Bigio, B., Rapaport, F., Cobat, A., Borghesi, A., Lopez, M., Patin, E., Bolze, A., Shang, L., Bendavid, M., &amp;amp; others. (2019). Blacklisting variants common in private cohorts but not in public databases optimizes human exome analysis. &lt;i&gt;Proceedings of the National Academy of Sciences&lt;/i&gt;, &lt;i&gt;116&lt;/i&gt;(3), 950–959.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;zhang2019seqtailor&quot;&gt;Zhang, P., Boisson, B., Stenson, P. D., Cooper, D. N., Casanova, J.-L., Abel, L., &amp;amp; Itan, Y. (2019). SeqTailor: a user-friendly webserver for the extraction of DNA or protein sequences from next-generation sequencing data. &lt;i&gt;Nucleic Acids Research&lt;/i&gt;, &lt;i&gt;47&lt;/i&gt;(W1), W623–W631.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;casanova2020human&quot;&gt;Casanova, J.-L., &amp;amp; Abel, L. (2020). &lt;i&gt;The human genetic determinism of life-threatening infectious diseases: genetic heterogeneity and physiological homogeneity?&lt;/i&gt; Springer.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bastard2021herpes&quot;&gt;Bastard, P., Manry, J., Chen, J., Rosain, J., Seeleuthner, Y., AbuZaitun, O., Lorenzo, L., Khan, T., Hasek, M., Hernandez, N., &amp;amp; others. (2021). Herpes simplex encephalitis in a patient with a distinctive form of inherited IFNAR1 deficiency. &lt;i&gt;The Journal of Clinical Investigation&lt;/i&gt;, &lt;i&gt;131&lt;/i&gt;(1).&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;gao2021tlr3&quot;&gt;Gao, D., Ciancanelli, M. J., Zhang, P., Harschnitz, O., Bondet, V., Hasek, M., Chen, J., Mu, X., Itan, Y., Cobat, A., &amp;amp; others. (2021). TLR3 controls constitutive IFN-βantiviral immunity in human fibroblasts and cortical neurons. &lt;i&gt;The Journal of Clinical Investigation&lt;/i&gt;, &lt;i&gt;131&lt;/i&gt;(1).&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;zhang2021computational&quot;&gt;Zhang, P., Cobat, A., Lee, Y.-S., Wu, Y., Bayrak, C. S., Boccon-Gibod, C., Matuozzo, D., Lorenzo, L., Jain, A., Boucherit, S., &amp;amp; others. (2021). A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity. &lt;i&gt;The American Journal of Human Genetics&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Unnecessary complexity in precision medicine</title>
   <link href="https://tom.preston-werner.com/2020/05/05/singhgupta_genes.html"/>
   <updated>2020-05-05T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2020/05/05/singhgupta_genes</id>
   <content type="html">&lt;h1 id=&quot;unnecessary-complexity-in-precision-medicine&quot;&gt;Unnecessary complexity in precision medicine&lt;/h1&gt;
&lt;p class=&quot;meta&quot;&gt;26 Apr 2020&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#unnecessary-complexity-in-precision-medicine&quot; id=&quot;markdown-toc-unnecessary-complexity-in-precision-medicine&quot;&gt;Unnecessary complexity in precision medicine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#abstract&quot; id=&quot;markdown-toc-abstract&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#complexity-in-living-systems&quot; id=&quot;markdown-toc-complexity-in-living-systems&quot;&gt;Complexity in living systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#is-complexity-necessary&quot; id=&quot;markdown-toc-is-complexity-necessary&quot;&gt;Is complexity necessary?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#evolution-of-complexity-genic-genomic-and-developmental&quot; id=&quot;markdown-toc-evolution-of-complexity-genic-genomic-and-developmental&quot;&gt;Evolution of complexity: genic, genomic, and developmental&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unnecessary-complexity-in-precision-medicine-1&quot; id=&quot;markdown-toc-unnecessary-complexity-in-precision-medicine-1&quot;&gt;Unnecessary complexity in precision medicine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unnecessary-complexity-and-the-etiology-of-cancer&quot; id=&quot;markdown-toc-unnecessary-complexity-and-the-etiology-of-cancer&quot;&gt;Unnecessary complexity and the etiology of cancer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unnecessary-complexity-beyond-precision-medicine&quot; id=&quot;markdown-toc-unnecessary-complexity-beyond-precision-medicine&quot;&gt;Unnecessary complexity beyond precision medicine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusions&quot; id=&quot;markdown-toc-conclusions&quot;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br /&gt;
Singh_and_Gupta.2020.GenoMed;&lt;br /&gt;
Singh, R.S., Gupta, B.P. Genes and genomes and unnecessary complexity in precision medicine. npj Genom. Med. 5, 21 (2020). https://doi.org/10.1038/s41525-020-0128-1 Open Access
&lt;a href=&quot;https://doi.org/10.1038/s41525-020-0128-1&quot;&gt;https://doi.org/10.1038/s41525-020-0128-1&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Risk factors, gene to phenotype, are more complex that anticipated in early genomics. 
Genotype - phenotype
Molecular and evolutionary complexity.
Molecular contigency - chance driven mutation, redundancy, molectular pathway cross-over (shared phenotypes).
Necessary complexity versus unnecessary - evolutionary baggage due to molecular constraint and blind evolution.&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;“Two individuals bearing the same set of risk factors may not present (or exhibit the symptoms of) the same disease. This is the kind of problem that precision medicine is expected to overcome.”
From familial studies, we often see that even clear monogenic, dominant disease does not always manifest equally among family members. “The lack of genetic determinism in disease is the result of molecular contingency.”&lt;/p&gt;

&lt;p&gt;An interesting point is made that I haven’t though much about; “Whether evolution is deterministic, i.e., predictable and repeatable, or contingent and unpredictable is an interesting topic in evolutionary biology (ref 1) (for a recent review see ref. 2)”
Although, this is just a smaller version of a question in physics that I do think about frequently: if every irreducibly small particle/force in the universe could be detected with a mapped trajectory, then we could “see” both forward and reverse in time; causal determinism. Since the particle physics answer will not come anytime soon, a discussion on the evolutionary version is reasonable.&lt;/p&gt;

&lt;p&gt;”..phenotypic evolutionary ‘repeatability’ is common when the founding populations are closely related, perhaps resulting from shared genes and developmental pathways, whereas different outcomes become more likely as historical divergences increase.”&lt;/p&gt;

&lt;p&gt;I believe that in some cases we can produces actionable levels of confidence in mutation prediction to make this a worthwhile endeavour. Knowing that a mutation is likely to occur (and be evolutionarily selected against) and result in disease means that we can prepare a treatment / cure for when it does occur naturally. 
For example, each nucleotide within each individual cell will have a particular probability for the energy required to mutate. 
Many factors affect this value; nucleotide type, methylation, DNA/RNA folding, bound proteins, chemical/UV insult, etc. 
Some of these factors can be estimated based on large studies, and some may never be quantifiable in the real world.
However, we can at least quantify some values to produce mutation predictor value X and and response Y and therefore quantify estimate coefficients, and therefore predict that mutation 1 is more likely to occur than mutation 2.&lt;/p&gt;

&lt;p&gt;Reference is made to “‘Evolution and Tinkering,’ Jacob (ref 4)” who compares natural selection to a tinkerer as opposed to an engineer.
Singh and Gupta propose “a theory of molecular complexity, consisting of necessary and unnecessary complexity in living systems”, that “exceedingly high level of unnecessary complexity” is more due to blind evolution rather than randomness of mutation. 
“Unecessary and unnecessary complexity is relevant to current discussions on genomics and precision medicine.”&lt;/p&gt;

&lt;h1 id=&quot;complexity-in-living-systems&quot;&gt;Complexity in living systems&lt;/h1&gt;
&lt;h1 id=&quot;is-complexity-necessary&quot;&gt;Is complexity necessary?&lt;/h1&gt;
&lt;h1 id=&quot;evolution-of-complexity-genic-genomic-and-developmental&quot;&gt;Evolution of complexity: genic, genomic, and developmental&lt;/h1&gt;
&lt;h1 id=&quot;unnecessary-complexity-in-precision-medicine-1&quot;&gt;Unnecessary complexity in precision medicine&lt;/h1&gt;
&lt;h1 id=&quot;unnecessary-complexity-and-the-etiology-of-cancer&quot;&gt;Unnecessary complexity and the etiology of cancer&lt;/h1&gt;
&lt;h1 id=&quot;unnecessary-complexity-beyond-precision-medicine&quot;&gt;Unnecessary complexity beyond precision medicine&lt;/h1&gt;
&lt;h1 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h1&gt;

</content>
 </entry>
 
 <entry>
   <title>Websites for basic genetic variant information</title>
   <link href="https://tom.preston-werner.com/2020/04/27/genetic_mutation_websites.html"/>
   <updated>2020-04-27T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2020/04/27/genetic_mutation_websites</id>
   <content type="html">&lt;h1 id=&quot;websites-for-basic-genetic-variant-information&quot;&gt;Websites for basic genetic variant information&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;26 Apr 2020&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Identifying pathogenic variants with whole genome and whole exome sequencing is not simple.
Determining the correct filtering method can take some time but it is not the most difficult task.
Validating genetic factors is generally the most time consuming part of this type of research. 
Here is a compilation of some of the websites and resources that I use constantly.
I will begin this simply as a list but continue to contribute information on how to use all of these over time.
I use most of the listed resources daily.
There are several steps in assessing if a gene variant is a good candidate to explain a clinical phenotype.
Often a clear story can be made between the genetic mutation and the resulting phenotype.
Other times (usually) a genetic finding (particularly biallelic mutations) seem to have a direct link to the clinical phenotype but it can take  weeks-months to functionally validate such a finding.
 With that in mind, it is good to have some sort of routine way to quickly assess the possible pathogenicity of a mutation by hand.
I will mostly discuss these in the context of rare mutations which are likely to be under selective pressure and occur at very low frequencies in a healthy population.
 Sites and tools for getting basic genetic information For assessing rare variants Ensembl and Exac (now gnomAD) are my bread and butter.
I haven’t done it yet but I need to set up a hotkey to open a browser with both of these sites simultaneously.
To demonstrate how I like to use these we could use an example. Lets say we have NGS results for a patient with immunodeficiency with coding variants in the gene RAG2.
OK, well known gene, important for antibody production as wells as TCR and BCR development.
Looks good so far.
Let’s see if the variants are common SNPs or could they be likely to cause damage if they are not reported (of course this is in your pipeline automatically but it’s good practice and takes less than 60 seconds; valuable if there is a real person affected by your results).
 After a long time getting confused about transcripts and coordinates, I now know how important it is to accurately report coordinates so there is no confusion if collaborating or reporting the mutations etc. Jump over to Exac.
&lt;a href=&quot;http://exac.broadinstitute.org&quot;&gt;Exac.org&lt;/a&gt;
 This is in a nutshell, the exomes of ~ 60,000 individuals which can be used to view how frequently mutations occur in the general population (unfortunately it is mostly just European but there is some global representation). Exac is vital for checking coding variants.
It covers some of the intronic regions (exon intron splice sites) and some of the upstream and downstream regions.
This is typical for anyone who does whole exome sequencing.
 We mentioned confusion about transcripts and coordinates, Exac automatically loads the coverage as shown for the canonical transcript. Stick with this transcript for reporting or at least for your own notes.
When you head over to Ensembl grab the same one in the transcript table. Update! &lt;a href=&quot;http://gnomad.broadinstitute.org/about&quot;&gt;The Genome Aggregation Database (gnomAD) is online&lt;/a&gt;. This data set is the combination of “123,136 exomes and 15,496 genomes from unrelated individuals” which has “removed individuals known to be affected by severe pediatric disease, as well as their first-degree relatives.”
This is n extremely exciting resource. If you are familiar with Exac then you will know the value of this expansion into gnomAD. &lt;a href=&quot;https://youtu.be/_uRuFZv4JaU&quot;&gt;youtube.com&lt;/a&gt; &lt;a href=&quot;http://www.ensembl.org/index.html&quot;&gt;Ensembl&lt;/a&gt; Any good pipeline will have annotation of the details for any coding variants but it can be pretty valuable to go and look at these again by hand.
It doesn’t take long but can end up saving time in the long run.
If you do it often, the first check on Exac take less than 60 seconds.
The next check on Ensemble will only take 2-3 minutes.
In the quick search I plug in the gene name, luckily for my stuff the top hit is always the human gene (sorry Alpaca researchers).
When you get to the gene page first click is always “Show transcript table.”
If you are lucky there is only one coding transcript like for RAG2.
Most of the time there are about 6 transcripts of wildly varying lengths just to confuse matters.
Go for the transcript ID of the canonical transcript which you noted on Exac.
If you do so then life will be easier when you go to check the coordinates. 
On the left hand side in the table “Transcript-based displays” click “cDNA” shown under “Sequence”.
You can then search through to find the variant and amino acid to see if everything lines up.
You see the cDNA position and amino acid positions overlaid. If you were to pick a different transcript then of course the coordinates are likely to be different.
From here I usually go back to the table on the left of the screen to search Exons.
This obviously just lays out the exon sequences  in blocks along with useful information.
Only a small segment of the introns are displayed.
If you want reference sequences of multiple types just find the down load sequence button and chose FASTA and decide which type you want to display. You would likely have the information based on the annotated NGS data but you may want to look at the different transcripts and Ensembl is the best option. So far (in just a couple of minutes) you could have looked up the allele frequencies, affect of mutation on different transcripts and check that everything that should be reported from the NGS output matches up.
My next step is to check if these variants a already reported.
Everyone has their favourite method, searching PubMed etc. For my topics OMIM often produces good results and a quick search. &lt;a href=&quot;https://www.omim.org/&quot;&gt;Online Mendelian Inheritance in Man&lt;/a&gt;
This is a curated database and is generally very good.
Hopefully it continues to grow for a long time into the future.
Depending on how much you already know about your gene it is sometimes helpful to jump straight down to the “Allelic variants” section (if one is present).
You may find a few variants already reported with a similar phenotype being described as your case.
You may find the exact mutations already reported.
If this is the case then it is likely that it would have taken a few minutes longer to find the same cases on one of the other databases.
Whether you have found that there are many mutations reported similar to those that interest you or if you have found nothing reported so far, my next step is always to run through UniProt.
&lt;a href=&quot;http://www.uniprot.org&quot;&gt;UniProt&lt;/a&gt;
UniProt is so rich in information that there is no need to expnad on it here.
If you have never used it then just pick your favourite protein and go look it up now.
There is (usually) a combination of nearly everything you need to get a quick overview of a protein.
Gene function, functional domains, known variants, reported knockouts/mutagenesis studies, protein structures, expression, localisation, the list goes on.
Actually, as much as I love PDB, I find that using UniProt is usually quicker to check for available PDB protein structures before actually going to PDB to download from the source.
With these four websites one would likely be able to decide how confident you are about a candidate mutation/s.
At least if you are just looking coding variants.
Assessing non-coding regions is much messier business.
From here on in validation of a mutation can require a widely variable amount of functional work.
One thing is certain however, Sanger sequencing will be needed to confirm your NGS finding. &lt;a href=&quot;https://www.youtube.com/watch?v=3amsDkyiMu8&quot;&gt;youtube.com&lt;/a&gt; &lt;a href=&quot;https://github.com/gantzgraf/autoprimer3/releases/tag/v3.0.2&quot;&gt;Autoprimer3&lt;/a&gt;
Autoprimer3 is an excellent application that you can use to design primers for a gene of interest.
It is super quick for producing primers to be used on genomic DNA for “any UCSC genome and design PCR/sequencing primers to genes or genome coordinates”.
As an example I timed myself to see how long it takes to get a primer list for all exons of the gene RAG2 and a reference sequence from default genomic coordinates on hg38 while avoiding SNPs based on dbsnp142.
It took me 46 seconds to open the application and produce a primer list and reference sequence.
Less than 1% of the time I may have to go and redesign a primer manually because of an awkward sequence or a patient’s DNA may have some uncommon variant at the primer site. 
Depending on which supplier you order oligos from, Sanger sequencing to confirm a variant by found during NGS can be done within 3 days; about 90 seconds to design and order the oligos, a day or 2 until they are delivered,  and a day to PCR and sequence.
The explanation may be a bit long winded here but this app is excellent.
Just give it a try if you do any routine PCR or sequencing for coding variant.
As the name suggests, it is a simple version of Primer3 but super quick.
&lt;a href=&quot;https://software.broadinstitute.org/gatk/&quot;&gt;Genome Analysis Toolkit: Variant Discovery in High-Throughput Sequencing Data.&lt;/a&gt;
GATK most useful to jump straight to: &lt;a href=&quot;https://software.broadinstitute.org/gatk/documentation/tooldocs/&quot;&gt;Tool Documentation Index&lt;/a&gt; Genome hg38 &lt;a href=&quot;http://genome.ucsc.edu/cgi-bin/das/hg38/dna?segment=chr7:142299011,142813287&quot;&gt;(TCR region as example)&lt;/a&gt;
&lt;a href=&quot;https://gpgtools.org&quot;&gt;GPGtools&lt;/a&gt;
for sending sensitive patient info.
&lt;a href=&quot;https://www.gnupg.org&quot;&gt;GnuPG&lt;/a&gt; is GPL licensed alternative to the PGP suite for sending sensitive patient info.
See also Pretty good privacy for academic data. &lt;a href=&quot;http://www.umd.be/HSF3/HSF.html&quot;&gt;Human splice finder&lt;/a&gt; Illumina-Pipeline-V2 (“Version 2 of Illumina pipeline that incorporates &lt;a href=&quot;https://github.com/nirav99/Illumina-Pipeline-V2/blob/master/IlluminaPipelineCASAVA1_8.pdf&quot;&gt;CASAVA 1.8”)&lt;/a&gt; Sequence Manipulation Suite http://www.coccidia.icb.usp.br/sms2/index.html
Sequence Ontology http://www.sequenceontology.org
UCSC Genome Bioinformatics FAQ https://genome.ucsc.edu/FAQ/FAQformat
UCSC Table Browser https://genome.ucsc.edu/cgi-bin/hgTables
MutScan - https://github.com/OpenGene/MutScan
Detect and visualise target mutations by scanning FastQ files directly. Very useful if you are interested in some certain mutations but saves the time it would take to normally through your pipeline. &lt;/p&gt;
&lt;h2 id=&quot;communities-and-learning&quot;&gt;Communities and learning&lt;/h2&gt;
&lt;p&gt;No need to reinvent the wheel here. Stephen Turner has a better list of resources than I will produce with his post ”Staying Current in Bioinformatics &amp;amp; Genomics: 2017 Edition.” 
http://www.gettinggeneticsdone.com/2017/02/staying-current-in-bioinformatics-genomics-2017.html
Essentially it boils down to the journals, Twitter, some expert blogs, and several genomics communities.
The journals and other sites I like to follow are detailed here. When all directed into a single feed I think it produces an essential resource for most genetics/bioinformatics scientists.
Literature of Interest - In this post I show the use of Feedly to condense all the litereature that I follow into a single source and allow the option to view by category.&lt;/p&gt;

&lt;h2 id=&quot;machine-learning-and-cloud-computing&quot;&gt;Machine learning and cloud computing&lt;/h2&gt;
&lt;p&gt;In this post I have started to gather some of the resources I like to use and topics that I find interesting.
Some other links tagged on at the end:
BioStarts - Bioinformatics academic community https://www.biostars.org
Useful bash Bioinformatics one-liners&lt;br /&gt;
https://github.com/stephenturner/oneliners&lt;br /&gt;
Efficient R programming https://csgillespie.github.io/efficientR/
Cheat sheets for data.   science http://www.datasciencecentral.com/…
RStudio Cheat Sheets  
https://www.rstudio.com/resources/cheatsheets/#515&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Cryptography</title>
   <link href="https://tom.preston-werner.com/2020/04/26/cryptography.html"/>
   <updated>2020-04-26T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2020/04/26/cryptography</id>
   <content type="html">&lt;h1 id=&quot;cryptography&quot;&gt;Cryptography&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;26 Apr 2020&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#breaking&quot;&gt;Breaking crypto&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#aes&quot;&gt;AES is the most important current encryption method&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#quantum&quot;&gt;Quantum computing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot;&gt;Some thoughts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reading&quot;&gt;Reading list on more advanced topics&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Like most of the posts on this blog, this will be a work in progress. Cryptography is a topic which I stumbled upon and really enjoy.
For the reading list skip to the end of this page.
There is a long interesting history which would appeal to a casual reader.
Most people would be familiar with stories about crypto during WWII, particularly because of movies like
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.imdb.com/title/tt2084970/&quot;&gt;The Imitation Game&lt;span id=&quot;titleYear&quot;&gt;(2014).
&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;
Cracking of Enigma falls into the espionage theme along with stories like that of books from  &lt;span class=&quot;author notFaded&quot; style=&quot;color: #0000ff;&quot;&gt;&lt;span class=&quot;a-declarative&quot;&gt;&lt;a href=&quot;https://www.amazon.co.uk/Ben-Macintyre/e/B001H6WAL8/ref=dp_byline_cont_book_1&quot;&gt;Ben Macintyre.&lt;/a&gt; &lt;/span&gt;&lt;/span&gt;One of my favorites is: &lt;span id=&quot;productTitle&quot; class=&quot;a-size-large&quot;&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.amazon.co.uk/d/Books/Operation-Mincemeat-True-Story-Changed-Course-World/1408809214&quot;&gt;Operation Mincemeat&lt;/a&gt;:&lt;/span&gt; The True Spy Story That Changed the Course of World War II. &lt;/span&gt;
Reading so much about the non-fiction side of this topic ultimately led me to the &lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_James_Bond_novels_and_short_stories&quot;&gt;Ian Flemming novels&lt;/a&gt;.&lt;/span&gt; Of course I had seen all the movies as a kid, and like most, loved them. Reading the novels in their order of release ended up being much more fun than I have with most fictional book series perhaps because of Flemming’s true involvements during WWII.&lt;/p&gt;

&lt;p&gt;Gentle brushing against the topic of cryptography with these classical stories  eventually lead me to an interest in modern crypto. Real, crypto! Like most sciences portrayed in popular culture, it really only gets interesting when you get into the technical reading.
Computerphile has several good videos on cryptographic topics. This video describes SHA1 in a way that I find quite interesting. This is just about hashing methods but it is a lovely introduction to crypto.
&lt;a href=&quot;https://www.youtube.com/watch?v=DMtFhACPnTY&quot;&gt;www.youtube.com&lt;/a&gt;
Another video from the series now gets to actual crypto  in the same entertaining way; &lt;a href=&quot;https://www.youtube.com/watch?v=jkV1KEJGKRA&quot;&gt;End to End Encryption (E2EE)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;breaking&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;breaking-crypto&quot;&gt;Breaking crypto&lt;/h1&gt;
&lt;p&gt;Learning the basics of crypto and how it’s broken is best done at the same time. Of course actually breaking the crypto is difficult. But understanding it doesn’t have to be. To learn this you can quickly get the main points about modular arithmetic, exponentiation, and periods in this video.
&lt;a href=&quot;https://www.youtube.com/watch?v=12Q3Mrh03Gk&quot;&gt;Shor’s algorithm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think getting a clear grasp on the topic relies on getting used to modular arithmetic. For example on a clock we use Mod 12. If you get up at 12am and the time is now 1pm well then obviously you have been up for 13 hours. &lt;strong&gt;13 mod 12 = 1&lt;/strong&gt;.
You know just as well that if you get up at 7am and it is now 8pm you have also been up for 13 hours. We can do this in our head very easily, and can do other examples easily too if you get over the initial confusion. &lt;strong&gt;A/B = Q remainder R&lt;/strong&gt;. In some cases we only care about the remainder R. In that case we say: &lt;strong&gt;A modulo B is equal to R&lt;/strong&gt;. Where B is referred to as the modulus (or mod for short).
The only difficulty is when the numbers become quite large.
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.khanacademy.org/computing/computer-science/cryptography/modarithmetic/a/what-is-modular-arithmetic&quot;&gt;Here is a page that describes this very well. &lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This video is summed up with the 4 steps. The reason that RSA works is because Step 2, finding the period, takes a very long time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dylanlawlessblog.files.wordpress.com/2017/02/rsa.png&quot; alt=&quot;rsa&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Quantum computing is expected to dramatically speed up this step.
Another good intro video that has some interesting discussion on Diffie-Hellman key exchange was given at the Chaos Communication Congress:
J. Alex Halderman, Nadia Heninger: Logjam: Diffie-Hellman, discrete logs, the NSA, and you.&lt;/p&gt;

&lt;p&gt;“Earlier this year, we discovered that Diffie-Hellman key exchange – cornerstone of modern cryptography – is less secure in practice than the security community believed. In this talk, we’ll explain how the NSA is likely exploiting this weakness to allow it to decrypt connections to at least 20% of HTTPS websites, 25% of SSH servers, and 66% of IPsec VPNs.”
&lt;a href=&quot;https://www.youtube.com/watch?v=mS8gm-_rJgM&quot;&gt;www.youtube.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Applied Cypto Handbook is a very good technical introduction and probably as far as a general reader will ever want to go.
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://cacr.uwaterloo.ca/hac/&quot;&gt;http://cacr.uwaterloo.ca/hac/&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;aes&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;aes-is-the-most-important-current-encryption-method&quot;&gt;AES is the most important current encryption method&lt;/h1&gt;
&lt;p&gt;This lecture is the perfect intro if you already know what methods are out there.
&lt;a href=&quot;https://www.youtube.com/watch?v=x1v2tX4_dkQ&quot;&gt;www.youtube.com&lt;/a&gt;
The accompanying book is worth the money if you’re looking for a textbook. The table of contents is available on amazon.
&lt;span style=&quot;color: #0000ff;&quot;&gt; &lt;a href=&quot;http://www.crypto-textbook.com&quot;&gt;http://www.crypto-textbook.com.&lt;/a&gt;&lt;/span&gt;
Here is a link to &lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Évariste_Galois#Galois_theory&quot;&gt;Galois’ wiki.&lt;/a&gt;&lt;/span&gt;
This might lead you down a wiki rabbit hole learning about interesting maths.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;quantum&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;quantum-computing&quot;&gt;Quantum computing&lt;/h1&gt;
&lt;p&gt;Here are simply two videos from PBS that will be more entertaining and succinct at discussing this really interesting topic than I.
&lt;a href=&quot;https://www.youtube.com/watch?v=IrbJYsep45E&quot;&gt;How quantum computing works&lt;/a&gt;
How might quantum computing destroy computer security?
&lt;a href=&quot;https://www.youtube.com/watch?v=wUwZZaI5u0c&quot;&gt;By utilising Shor’s algorithm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A fun little topic brought up in this videos is: that quantum Fourier transform uses resonance to amplify the basic state associated with the correct period.
If you’re reading this site then it’s likely that you are a biologist.
If that is the case you may be more familiar with protein structures than quantum mechanics.
I first became introduced to the practical application of Fourier transformation while learning nuclear magnetic resonance (NMR) spectroscopy for protein structuring.
Of course, you don’t actually have to learn it to do NMR.
It happens automatically during data analysis but most people in the field surely would still like to know the details.
Wiki has a great page: &lt;a href=&quot;https://en.wikipedia.org/wiki/Fourier_transform&quot;&gt;https://en.wikipedia.org/wiki/Fourier_transform&lt;/a&gt;
&lt;img src=&quot;https://dylanlawlessblog.files.wordpress.com/2017/02/ft.png&quot; alt=&quot;ft&quot; /&gt;
“In NMR an exponentially shaped free induction decay (FID) signal is acquired in the time domain and Fourier-transformed to a Lorentzian line-shape in the frequency domain.”&lt;/p&gt;

&lt;p&gt;The next main point addressed in this video is: Complex roots of unity.
This is introduced quite well in the video.
If you have never seen anything like this before then I highly recommend the short book by Feynman;
&lt;a href=&quot;https://www.amazon.co.uk/dp/B00BR40XJ6?ref_=k4w_oembed_ICZkE7ckZ2ZUfR&amp;amp;tag=kpembed-20&amp;amp;linkCode=kpd&quot;&gt;QED: The Strange Theory of Light and Matter&lt;/a&gt;
&lt;!--
(https://www.amazon.com/QED-Strange-Princeton-Science-Library/dp/0691164096/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1494067439&amp;sr=1-1&amp;keywords=qed+the+strange+theory+of+light+and+matter)
--&gt;
In no way does this little book talk about quantum computing.
If fact it is pretty old now and is not the kind of thing that professionals will be using for reference.
Why would I suggest this for someone who is new to the topic? Well it is an extremely fun introduction to the topic of QED and lays the foundation of ideas that have become mainstream over the next 30 years.
Understanding some basic ideas will leave you open to recognise more complex applications, especially important if you want to only look at the basics of quantum computing.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;thoughts&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;some-thoughts&quot;&gt;Some thoughts&lt;/h1&gt;
&lt;p&gt;This talk at Google by Peter Warren Singer based on his book,
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Cybersecurity-Cyberwar-Everyone-Needs-Know%C2%AE/dp/0199918112&quot;&gt;Cybersecurity and Cyberwar&lt;/a&gt;&lt;/span&gt;,
may be a pretty interesting watch for anyone into technology security in some way. This is not a technical talk, more of something to get you into the mindset up why this topic may be interesting.
&lt;a href=&quot;https://www.youtube.com/watch?v=h0SXO5KUZIo&quot;&gt;www.youtube.com&lt;/a&gt;
&lt;a href=&quot;https://www.cl.cam.ac.uk/~rja14/book.html&quot;&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;https://www.cl.cam.ac.uk/~rja14/book.html&lt;/span&gt;&lt;/a&gt; Security Engineering — The Book&lt;/p&gt;

&lt;p&gt;The cryptopals crypto challenges are a fun way to learn some hands on application of cryptographic techniques. &lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.cryptopals.com/&quot;&gt;http://www.cryptopals.com/&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Announcing the first SHA1 collision on February 23, 2017.
This was a really big event in the crypto community.
I think many people in the cyber security field assume that experiments and findings in public and academic research are a few years behind government capabilities.
Take from that what you will.
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html&quot;&gt;https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;There are countless reasons why crypto is interesting.
The applications range from the most mundane day to day requirements in the modern world such as banking, personal communication, the use of medical data (which I post about here &lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://dylanlawlessblog.wordpress.com/2017/02/21/pretty-good-privacy-for-academic-data/&quot;&gt;Pretty good privacy for academic data&lt;/a&gt;&lt;/span&gt;) all the way out to the most hypothetical academic applications.
An interesting point to think about is the journey that each data packet makes across the mystical &lt;em&gt;internet&lt;/em&gt;.
Most electronic communications travel across a number of boarders and further distances than most people will travel in their entire life.
Our world would not run very smoothly if all communication was sent in a readable format with no protection.
Here is some basic info on the infrastructure require for modern electronic communication:
&lt;a href=&quot;https://www.youtube.com/watch?v=DKHZKTRyzeg&quot;&gt;www.youtube.com&lt;/a&gt;,
&lt;a href=&quot;https://www.youtube.com/watch?v=0TZwiUwZwIE&quot;&gt;www.youtube.com&lt;/a&gt;
And the &lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.submarinecablemap.com&quot;&gt;Submarine Cable Map&lt;/a&gt;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;While we’re on the topic, I found this video on the Cornwall cable landing station.
The physical infrastructure and engineering requirements of global communication are sometimes easy to forget if one spends more time on computer programming or mathematics
&lt;a href=&quot;https://www.youtube.com/watch?v=K_nnUbX7uuQ&quot;&gt;www.youtube.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;reading&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;reading-list-on-more-advanced-topics&quot;&gt;Reading list on more advanced topics&lt;/h1&gt;
&lt;p&gt;/r/crypto wiki&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.reddit.com/r/crypto/wiki/index&quot;&gt;https://www.reddit.com/r/crypto/wiki/index&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Textbook: An Introduction to Mathematical Cryptography&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5F72903FBACA6DF57799612526CC437F?doi=10.1.1.182.9999&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5F72903FBACA6DF57799612526CC437F?doi=10.1.1.182.9999&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Cryptology ePrint Archive&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://eprint.iacr.org&quot;&gt;http://eprint.iacr.org&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Handbook of Applied Cryptography&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://cacr.uwaterloo.ca/hac/&quot;&gt;http://cacr.uwaterloo.ca/hac/&lt;/a&gt;&lt;/span&gt;
Goldreich: The Foundations of Cryptography&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.wisdom.weizmann.ac.il/%7Eoded/foc-drafts.html&quot;&gt;http://www.wisdom.weizmann.ac.il/%7Eoded/foc-drafts.html&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Handbook of Elliptic and Hyperelliptic Curve Cryptography&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.hyperelliptic.org/HEHCC/&quot;&gt;http://www.hyperelliptic.org/HEHCC/&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
eBACS: ECRYPT Benchmarking of Cryptographic Systems&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://bench.cr.yp.to&quot;&gt;http://bench.cr.yp.to&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Mihir Bellare and Shafi Goldwasser’s Lecture Notes&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://cseweb.ucsd.edu/%7Emihir/papers/gb.pdf&quot;&gt;http://cseweb.ucsd.edu/%7Emihir/papers/gb.pdf&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Charm: A tool for rapid cryptographic prototyping&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.charm-crypto.com/index.html&quot;&gt;http://www.charm-crypto.com/index.html&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
eHash Wiki&lt;br /&gt;
&lt;a href=&quot;http://ehash.iaik.tugraz.at/wiki/The_Hash_Function_Zoo&quot;&gt;Hash Function Zoo&lt;/a&gt;&lt;br /&gt;
and the &lt;a href=&quot;http://ehash.iaik.tugraz.at/wiki/The_SHA-3_Zoo&quot;&gt;SHA-3 Zoo&lt;/a&gt;&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://ehash.iaik.tugraz.at/wiki/The_eHash_Main_Page&quot;&gt;http://ehash.iaik.tugraz.at/wiki/The_eHash_Main_Page&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Cryptology ePrint Archive&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://eprint.iacr.org&quot;&gt;http://eprint.iacr.org&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
IACR Conferences (Crypto, Eurocrypt, Asiacrypt)&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.iacr.org/conferences/&quot;&gt;http://www.iacr.org/conferences/&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
IEEE Symposium on Security and Privacy (There are loads of papers and talks on YouTube under Program of past events)&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.ieee-security.org/TC/SP2017/past.html&quot;&gt;https://www.ieee-security.org/TC/SP2017/past.html&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Crypto Stack Exchange&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://crypto.stackexchange.com&quot;&gt;https://crypto.stackexchange.com&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Blogpost so-you-want-to-crypto&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.seancassidy.me/so-you-want-to-crypto.html&quot;&gt;https://www.seancassidy.me/so-you-want-to-crypto.html&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Authenticated Encryption Zoo&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://aezoo.compute.dtu.dk/doku.php?id=AE%20Zoo&quot;&gt;https://aezoo.compute.dtu.dk/doku.php?id=AE%20Zoo&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Helger Lipmaa Cryptology Pointers&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://kodu.ut.ee/~lipmaa/crypto/&quot;&gt;http://kodu.ut.ee/~lipmaa/crypto/&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Free Course: Applied Cryptography&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.udacity.com/course/applied-cryptography--cs387&quot;&gt;https://www.udacity.com/course/applied-cryptography–cs387&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Kerckhoffs’s principle&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle&quot;&gt;https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Schneier’s Law&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://www.schneier.com/blog/archives/2011/04/schneiers_law.html&quot;&gt;https://www.schneier.com/blog/archives/2011/04/schneiers_law.html&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
crypto blogs from David Wong’s github&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;https://github.com/mimoo/crypto_blogs&quot;&gt;https://github.com/mimoo/crypto_blogs&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
Shor in Haskell The Quantum IO Monad&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.cs.nott.ac.uk/%7Epsztxa/publ/qio.pdf&quot;&gt;http://www.cs.nott.ac.uk/%7Epsztxa/publ/qio.pdf&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;
The Quipper Language: programming language for quantum computing&lt;br /&gt;
&lt;span style=&quot;color: #0000ff;&quot;&gt;&lt;a href=&quot;http://www.mathstat.dal.ca/%7Eselinger/quipper/&quot;&gt;http://www.mathstat.dal.ca/%7Eselinger/quipper/&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;!-- 
![encrpytdata](https://i.imgur.com/UubXs0H.gif)
--&gt;
</content>
 </entry>
 
 <entry>
   <title>The devil is in the detail</title>
   <link href="https://tom.preston-werner.com/2019/08/19/devil_in_detail.html"/>
   <updated>2019-08-19T00:00:00+02:00</updated>
   <id>https://tom.preston-werner.com/2019/08/19/devil_in_detail</id>
   <content type="html">&lt;h1 id=&quot;the-devil-is-in-the-detail&quot;&gt;The devil is in the detail&lt;/h1&gt;

&lt;p class=&quot;meta&quot;&gt;19 Aug 2019&lt;/p&gt;
&lt;p&gt;I was learning some &lt;a href=&quot;https://en.wikipedia.org/wiki/Steganography&quot;&gt;steganography&lt;/a&gt; methods for a security project. 
At the same time, I was writing up a paper with some friends 
(&lt;a href=&quot;https://link.springer.com/content/pdf/11.1007%2Fs10875-019-00670-z.pdf&quot;&gt;https://link.springer.com/content/pdf/11.1007%2Fs10875-019-00670-z.pdf&lt;/a&gt;) 
and decided to hide a little message in one of the figures.
The goal was to encode some hidden data and see could we get it back out 
the other side, after publication.&lt;/p&gt;

&lt;p&gt;It would be a lot of trouble for a master of espionage to have to publish a 
paper every time a secret message needed to be encoded for public transmission, 
but maybe it could be done!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/editor_paper_rag.png&quot; width=&quot;101%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The secret message was imported into &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt; from plain text. 
It was encoded into a png file that was to be a supplemental figure in our paper 
From experience, supplemental figures usually get uploaded to a repository and
stored in the same format for later downloaded after publication, 
until main-text figures which are often converted in one way or another by the publisher. 
Once the figure was released, anyone with the correct decoding algorithm 
could get back the secret message.&lt;/p&gt;

&lt;p&gt;In this case, I used the 
&lt;a href=&quot;https://github.com/richfitz/stegasaur&quot;&gt;richfitz/stegasaur&lt;/a&gt; package, 
innocently offered with “The aim is to be able to encode arbitrary R objects in cat pictures.” 
The inforation was hidden within the data that makes up the image, 
and is imperceivable to the naked eye. 
Even better, the file size was slightly &lt;em&gt;SMALLER&lt;/em&gt; than the original 
(1.9MB to 1.7MB) without a noticeable difference in quality. 
After peer review of the paper, publisher proceessing and publication, 
the secret message was successfully decoded from the protein structure figure 
“F_E4_Structure.png” and was printed to the console:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/r_steg_decode.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This exercise looks like a bit of fun, 
but was done to demonstrate the unavoidable 
risks that exist in sensitive data research.&lt;sup id=&quot;fnref:foot&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:foot&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
Today, protected data enclaves are used for processing sensitive data 
and usually allow summary results or figures to be exported.
These are therefore basically a trust based system and are otherwise only security theatre.&lt;/p&gt;

&lt;p&gt;Here’s an idea, &lt;a href=&quot;https://patents.google.com/patent/US8527779&quot;&gt;steganographic message blocks&lt;/a&gt; 
seperated across a career worth of publications, 
that can only be deciphered once all blocks are collected! 
Who would go to that trouble? 
Go see what you can find in one Supplementary material png file. 
&lt;a href=&quot;https://link.springer.com/article/10.1007%2Fs10875-019-00670-z&quot;&gt;https://link.springer.com/article/10.1007%2Fs10875-019-00670-z&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;r-script&quot;&gt;R script &lt;/h1&gt;
&lt;p&gt;Try it yourself.
Find the paper and get Figure E4.
Download
&lt;a href=&quot;https://link.springer.com/article/10.1007%2Fs10875-019-00670-z#SupplementaryMaterial&quot;&gt;10875_2019_670_MOESM5_ESM&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; install.packages(&quot;devtools&quot;)
&amp;gt; install_github(&quot;richfitz/stegasaur&quot;)
&amp;gt; library(&quot;devtools&quot;)
&amp;gt; library(ggplot2) 
&amp;gt; Decode message &amp;lt;- 
&amp;gt;		stegasaur::decode(&quot;~/10875_2019_670_MOESM5_ESM.png&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;footnote&quot;&gt;Footnote&lt;/h1&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:foot&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;/topic/medical-espionage&quot;&gt;Medical espionage&lt;/a&gt;. &lt;a href=&quot;#fnref:foot&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 

 <!--
 
  <h2> - </h2>
  <p><h1 id="cryptography">Cryptography</h1>
<p class="meta">28 Apr 2020</p>

<ul id="markdown-toc">
  <li><a href="#cryptography" id="markdown-toc-cryptography">Cryptography</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#breaking-crypto" id="markdown-toc-breaking-crypto">Breaking crypto</a></li>
  <li><a href="#aes-is-the-most-important-current-encryption-method" id="markdown-toc-aes-is-the-most-important-current-encryption-method">AES is the most important current encryption method</a></li>
  <li><a href="#quantum-computing" id="markdown-toc-quantum-computing">Quantum computing</a></li>
  <li><a href="#some-thoughts" id="markdown-toc-some-thoughts">Some thoughts</a></li>
  <li><a href="#reading-list-on-more-advanced-topics" id="markdown-toc-reading-list-on-more-advanced-topics">Reading list on more advanced topics</a></li>
</ul>

<!--
cross link and label
1. [Introduction](#introduction)
<a name="introduction"></a>
-->
<h1 id="introduction">Introduction</h1>
<p>Like most of the posts on this blog, this will be a work in progress. Cryptography is a topic which I stumbled upon and really enjoy.
For the reading list skip to the end of this page.
There is a long interesting history which would appeal to a casual reader.
Most people would be familiar with stories about crypto during WWII, particularly because of movies like
<span style="color: #0000ff;"><a href="http://www.imdb.com/title/tt2084970/">The Imitation Game<span id="titleYear">(2014).
</span></a></span>
Cracking of Enigma falls into the espionage theme along with stories like that of books from  <span class="author notFaded" style="color: #0000ff;"><span class="a-declarative"><a href="https://www.amazon.co.uk/Ben-Macintyre/e/B001H6WAL8/ref=dp_byline_cont_book_1">Ben Macintyre.</a> </span></span>One of my favorites is: <span id="productTitle" class="a-size-large"><span style="color: #0000ff;"><a href="https://www.amazon.co.uk/d/Books/Operation-Mincemeat-True-Story-Changed-Course-World/1408809214">Operation Mincemeat</a>:</span> The True Spy Story That Changed the Course of World War II. </span>
Reading so much about the non-fiction side of this topic ultimately led me to the <span style="color: #0000ff;"><a href="https://en.wikipedia.org/wiki/List_of_James_Bond_novels_and_short_stories">Ian Flemming novels</a>.</span> Of course I had seen all the movies as a kid, and like most, loved them. Reading the novels in their order of release ended up being much more fun than I have with most fictional book series perhaps because of Flemming’s true involvements during WWII.</p>

<p>Gentle brushing against the topic of cryptography with these classical stories  eventually lead me to an interest in modern crypto. Real, crypto! Like most sciences portrayed in popular culture, it really only gets interesting when you get into the technical reading.
Computerphile has several good videos on cryptographic topics. This video describes SHA1 in a way that I find quite interesting. This is just about hashing methods but it is a lovely introduction to crypto.
<a href="https://www.youtube.com/watch?v=DMtFhACPnTY">www.youtube.com</a>
Another video from the series now gets to actual crypto  in the same entertaining way; <a href="https://www.youtube.com/watch?v=jkV1KEJGKRA">End to End Encryption (E2EE)</a>.</p>

<p><a name="breaking"></a></p>
<h1 id="breaking-crypto">Breaking crypto</h1>
<p>Learning the basics of crypto and how it’s broken is best done at the same time. Of course actually breaking the crypto is difficult. But understanding it doesn’t have to be. To learn this you can quickly get the main points about modular arithmetic, exponentiation, and periods in this video.
<a href="https://www.youtube.com/watch?v=12Q3Mrh03Gk">Shor’s algorithm</a></p>

<p>I think getting a clear grasp on the topic relies on getting used to modular arithmetic. For example on a clock we use Mod 12. If you get up at 12am and the time is now 1pm well then obviously you have been up for 13 hours. <strong>13 mod 12 = 1</strong>.
You know just as well that if you get up at 7am and it is now 8pm you have also been up for 13 hours. We can do this in our head very easily, and can do other examples easily too if you get over the initial confusion. <strong>A/B = Q remainder R</strong>. In some cases we only care about the remainder R. In that case we say: <strong>A modulo B is equal to R</strong>. Where B is referred to as the modulus (or mod for short).
The only difficulty is when the numbers become quite large.
<span style="color: #0000ff;"><a href="https://www.khanacademy.org/computing/computer-science/cryptography/modarithmetic/a/what-is-modular-arithmetic">Here is a page that describes this very well. </a></span></p>

<p>This video is summed up with the 4 steps. The reason that RSA works is because Step 2, finding the period, takes a very long time:</p>

<!-- ![rsa](https://dylanlawlessblog.files.wordpress.com/2017/02/rsa.png) -->
<p><img src="https://dylanlawlessblog.files.wordpress.com/2017/02/rsa.png" width="40%" /></p>

<p>Quantum computing is expected to dramatically speed up this step.
Another good intro video that has some interesting discussion on Diffie-Hellman key exchange was given at the Chaos Communication Congress:
J. Alex Halderman, Nadia Heninger: Logjam: Diffie-Hellman, discrete logs, the NSA, and you.</p>

<p>“Earlier this year, we discovered that Diffie-Hellman key exchange – cornerstone of modern cryptography – is less secure in practice than the security community believed. In this talk, we’ll explain how the NSA is likely exploiting this weakness to allow it to decrypt connections to at least 20% of HTTPS websites, 25% of SSH servers, and 66% of IPsec VPNs.”
<a href="https://www.youtube.com/watch?v=mS8gm-_rJgM">www.youtube.com</a></p>

<p>Applied Cypto Handbook is a very good technical introduction and probably as far as a general reader will ever want to go.
<span style="color: #0000ff;"><a href="http://cacr.uwaterloo.ca/hac/">http://cacr.uwaterloo.ca/hac/</a></span></p>

<p><a name="aes"></a></p>
<h1 id="aes-is-the-most-important-current-encryption-method">AES is the most important current encryption method</h1>
<p>This lecture is the perfect intro if you already know what methods are out there.
<a href="https://www.youtube.com/watch?v=x1v2tX4_dkQ">www.youtube.com</a>
The accompanying book is worth the money if you’re looking for a textbook. The table of contents is available on amazon.
<span style="color: #0000ff;"> <a href="http://www.crypto-textbook.com">http://www.crypto-textbook.com.</a></span>
Here is a link to <span style="color: #0000ff;"><a href="https://en.wikipedia.org/wiki/Évariste_Galois#Galois_theory">Galois’ wiki.</a></span>
This might lead you down a wiki rabbit hole learning about interesting maths.</p>

<p><a name="quantum"></a></p>
<h1 id="quantum-computing">Quantum computing</h1>
<p>Here are simply two videos from PBS that will be more entertaining and succinct at discussing this really interesting topic than I.
<a href="https://www.youtube.com/watch?v=IrbJYsep45E">How quantum computing works</a>
How might quantum computing destroy computer security?
<a href="https://www.youtube.com/watch?v=wUwZZaI5u0c">By utilising Shor’s algorithm</a></p>

<p>A fun little topic brought up in this videos is: that quantum Fourier transform uses resonance to amplify the basic state associated with the correct period.
If you’re reading this site then it’s likely that you are a biologist.
If that is the case you may be more familiar with protein structures than quantum mechanics.
I first became introduced to the practical application of Fourier transformation while learning nuclear magnetic resonance (NMR) spectroscopy for protein structuring.
Of course, you don’t actually have to learn it to do NMR.
It happens automatically during data analysis but most people in the field surely would still like to know the details.
Wiki has a great page: <a href="https://en.wikipedia.org/wiki/Fourier_transform">https://en.wikipedia.org/wiki/Fourier_transform</a></p>

<p><img src="https://dylanlawlessblog.files.wordpress.com/2017/02/ft.png" width="50%" /><br />
“In NMR an exponentially shaped free induction decay (FID) signal is acquired in the time domain and Fourier-transformed to a Lorentzian line-shape in the frequency domain.”</p>

<p>The next main point addressed in this video is: Complex roots of unity.
This is introduced quite well in the video.
If you have never seen anything like this before then I highly recommend the short book by Feynman;
<a href="https://www.amazon.co.uk/dp/B00BR40XJ6?ref_=k4w_oembed_ICZkE7ckZ2ZUfR&amp;tag=kpembed-20&amp;linkCode=kpd">QED: The Strange Theory of Light and Matter</a>
<!--
(https://www.amazon.com/QED-Strange-Princeton-Science-Library/dp/0691164096/ref=sr_1_1?s=books&ie=UTF8&qid=1494067439&sr=1-1&keywords=qed+the+strange+theory+of+light+and+matter)
-->
In no way does this little book talk about quantum computing.
If fact it is pretty old now and is not the kind of thing that professionals will be using for reference.
Why would I suggest this for someone who is new to the topic? Well it is an extremely fun introduction to the topic of QED and lays the foundation of ideas that have become mainstream over the next 30 years.
Understanding some basic ideas will leave you open to recognise more complex applications, especially important if you want to only look at the basics of quantum computing.</p>

<p><a name="thoughts"></a></p>
<h1 id="some-thoughts">Some thoughts</h1>
<p>This talk at Google by Peter Warren Singer based on his book,
<span style="color: #0000ff;"><a href="https://www.amazon.com/Cybersecurity-Cyberwar-Everyone-Needs-Know%C2%AE/dp/0199918112">Cybersecurity and Cyberwar</a></span>,
may be a pretty interesting watch for anyone into technology security in some way. This is not a technical talk, more of something to get you into the mindset up why this topic may be interesting.
<a href="https://www.youtube.com/watch?v=h0SXO5KUZIo">www.youtube.com</a>
<a href="https://www.cl.cam.ac.uk/~rja14/book.html"><span style="color: #0000ff;">https://www.cl.cam.ac.uk/~rja14/book.html</span></a> Security Engineering — The Book</p>

<p>The cryptopals crypto challenges are a fun way to learn some hands on application of cryptographic techniques. <span style="color: #0000ff;"><a href="http://www.cryptopals.com/">http://www.cryptopals.com/</a></span></p>

<p>Announcing the first SHA1 collision on February 23, 2017.
This was a really big event in the crypto community.
I think many people in the cyber security field assume that experiments and findings in public and academic research are a few years behind government capabilities.
Take from that what you will.
<span style="color: #0000ff;"><a href="https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html">https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html</a></span></p>

<p>There are countless reasons why crypto is interesting.
The applications range from the most mundane day to day requirements in the modern world such as banking, personal communication, the use of medical data (which I post about here <span style="color: #0000ff;"><a href="https://dylanlawlessblog.wordpress.com/2017/02/21/pretty-good-privacy-for-academic-data/">Pretty good privacy for academic data</a></span>) all the way out to the most hypothetical academic applications.
An interesting point to think about is the journey that each data packet makes across the mystical <em>internet</em>.
Most electronic communications travel across a number of boarders and further distances than most people will travel in their entire life.
Our world would not run very smoothly if all communication was sent in a readable format with no protection.
Here is some basic info on the infrastructure require for modern electronic communication:
<a href="https://www.youtube.com/watch?v=DKHZKTRyzeg">www.youtube.com</a>,
<a href="https://www.youtube.com/watch?v=0TZwiUwZwIE">www.youtube.com</a>
And the <span style="color: #0000ff;"><a href="http://www.submarinecablemap.com">Submarine Cable Map</a></span>.</p>

<p>While we’re on the topic, I found this video on the Cornwall cable landing station.
The physical infrastructure and engineering requirements of global communication are sometimes easy to forget if one spends more time on computer programming or mathematics
<a href="https://www.youtube.com/watch?v=K_nnUbX7uuQ">www.youtube.com</a>.</p>

<p><a name="reading"></a></p>
<h1 id="reading-list-on-more-advanced-topics">Reading list on more advanced topics</h1>
<p>/r/crypto wiki<br />
<span style="color: #0000ff;"><a href="https://www.reddit.com/r/crypto/wiki/index">https://www.reddit.com/r/crypto/wiki/index</a></span><br />
Textbook: An Introduction to Mathematical Cryptography<br />
<span style="color: #0000ff;"><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5F72903FBACA6DF57799612526CC437F?doi=10.1.1.182.9999&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5F72903FBACA6DF57799612526CC437F?doi=10.1.1.182.9999&amp;rep=rep1&amp;type=pdf</a></span><br />
Cryptology ePrint Archive<br />
<span style="color: #0000ff;"><a href="http://eprint.iacr.org">http://eprint.iacr.org</a></span><br />
Handbook of Applied Cryptography<br />
<span style="color: #0000ff;"><a href="http://cacr.uwaterloo.ca/hac/">http://cacr.uwaterloo.ca/hac/</a></span>
Goldreich: The Foundations of Cryptography<br />
<span style="color: #0000ff;"><a href="http://www.wisdom.weizmann.ac.il/%7Eoded/foc-drafts.html">http://www.wisdom.weizmann.ac.il/%7Eoded/foc-drafts.html</a></span><br />
Handbook of Elliptic and Hyperelliptic Curve Cryptography<br />
<span style="color: #0000ff;"><a href="http://www.hyperelliptic.org/HEHCC/">http://www.hyperelliptic.org/HEHCC/</a></span><br />
eBACS: ECRYPT Benchmarking of Cryptographic Systems<br />
<span style="color: #0000ff;"><a href="http://bench.cr.yp.to">http://bench.cr.yp.to</a></span><br />
Mihir Bellare and Shafi Goldwasser’s Lecture Notes<br />
<span style="color: #0000ff;"><a href="http://cseweb.ucsd.edu/%7Emihir/papers/gb.pdf">http://cseweb.ucsd.edu/%7Emihir/papers/gb.pdf</a></span><br />
Charm: A tool for rapid cryptographic prototyping<br />
<span style="color: #0000ff;"><a href="http://www.charm-crypto.com/index.html">http://www.charm-crypto.com/index.html</a></span><br />
eHash Wiki<br />
<a href="http://ehash.iaik.tugraz.at/wiki/The_Hash_Function_Zoo">Hash Function Zoo</a><br />
and the <a href="http://ehash.iaik.tugraz.at/wiki/The_SHA-3_Zoo">SHA-3 Zoo</a><br />
<span style="color: #0000ff;"><a href="http://ehash.iaik.tugraz.at/wiki/The_eHash_Main_Page">http://ehash.iaik.tugraz.at/wiki/The_eHash_Main_Page</a></span><br />
Cryptology ePrint Archive<br />
<span style="color: #0000ff;"><a href="http://eprint.iacr.org">http://eprint.iacr.org</a></span><br />
IACR Conferences (Crypto, Eurocrypt, Asiacrypt)<br />
<span style="color: #0000ff;"><a href="http://www.iacr.org/conferences/">http://www.iacr.org/conferences/</a></span><br />
IEEE Symposium on Security and Privacy (There are loads of papers and talks on YouTube under Program of past events)<br />
<span style="color: #0000ff;"><a href="https://www.ieee-security.org/TC/SP2017/past.html">https://www.ieee-security.org/TC/SP2017/past.html</a></span><br />
Crypto Stack Exchange<br />
<span style="color: #0000ff;"><a href="https://crypto.stackexchange.com">https://crypto.stackexchange.com</a></span><br />
Blogpost so-you-want-to-crypto<br />
<span style="color: #0000ff;"><a href="https://www.seancassidy.me/so-you-want-to-crypto.html">https://www.seancassidy.me/so-you-want-to-crypto.html</a></span><br />
Authenticated Encryption Zoo<br />
<span style="color: #0000ff;"><a href="https://aezoo.compute.dtu.dk/doku.php?id=AE%20Zoo">https://aezoo.compute.dtu.dk/doku.php?id=AE%20Zoo</a></span><br />
Helger Lipmaa Cryptology Pointers<br />
<span style="color: #0000ff;"><a href="http://kodu.ut.ee/~lipmaa/crypto/">http://kodu.ut.ee/~lipmaa/crypto/</a></span><br />
Free Course: Applied Cryptography<br />
<span style="color: #0000ff;"><a href="https://www.udacity.com/course/applied-cryptography--cs387">https://www.udacity.com/course/applied-cryptography–cs387</a></span><br />
Kerckhoffs’s principle<br />
<span style="color: #0000ff;"><a href="https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle">https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle</a></span><br />
Schneier’s Law<br />
<span style="color: #0000ff;"><a href="https://www.schneier.com/blog/archives/2011/04/schneiers_law.html">https://www.schneier.com/blog/archives/2011/04/schneiers_law.html</a></span><br />
crypto blogs from David Wong’s github<br />
<span style="color: #0000ff;"><a href="https://github.com/mimoo/crypto_blogs">https://github.com/mimoo/crypto_blogs</a></span><br />
Shor in Haskell The Quantum IO Monad<br />
<span style="color: #0000ff;"><a href="http://www.cs.nott.ac.uk/%7Epsztxa/publ/qio.pdf">http://www.cs.nott.ac.uk/%7Epsztxa/publ/qio.pdf</a></span><br />
The Quipper Language: programming language for quantum computing<br />
<span style="color: #0000ff;"><a href="http://www.mathstat.dal.ca/%7Eselinger/quipper/">http://www.mathstat.dal.ca/%7Eselinger/quipper/</a></span></p>

<!-- 
![encrpytdata](https://i.imgur.com/UubXs0H.gif)
-->
<p><small></small></p>

<p>&lt;/small&gt;</p>
</p>

  <h2> - </h2>
  <p><h1 id="medical-espionage">Medical espionage</h1>
<p class="meta">13 Feb 2021</p>

<ul id="markdown-toc">
  <li><a href="#medical-espionage" id="markdown-toc-medical-espionage">Medical espionage</a></li>
  <li><a href="#the-prospect-of-genomic-medical-espionage" id="markdown-toc-the-prospect-of-genomic-medical-espionage">The prospect of genomic medical espionage</a></li>
  <li><a href="#ransomware" id="markdown-toc-ransomware">Ransomware</a></li>
  <li><a href="#legal-safeguard" id="markdown-toc-legal-safeguard">Legal safeguard</a></li>
  <li><a href="#metadata" id="markdown-toc-metadata">Metadata</a></li>
  <li><a href="#disinformation" id="markdown-toc-disinformation">Disinformation</a></li>
  <li><a href="#data-pollution" id="markdown-toc-data-pollution">Data pollution</a></li>
  <li><a href="#in-the-media" id="markdown-toc-in-the-media">In the media</a></li>
  <li><a href="#protecting-data-and-promoting-open-source-access" id="markdown-toc-protecting-data-and-promoting-open-source-access">Protecting data and promoting open-source access</a>    <ul>
      <li><a href="#projects-focused-on-safe-access" id="markdown-toc-projects-focused-on-safe-access">Projects focused on safe access</a></li>
      <li><a href="#obstacles-to-data-privacy" id="markdown-toc-obstacles-to-data-privacy">Obstacles to data privacy</a></li>
      <li><a href="#future-methods" id="markdown-toc-future-methods">Future methods</a></li>
    </ul>
  </li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
  <li><a href="#footnotes" id="markdown-toc-footnotes">Footnotes</a></li>
</ul>

<!--
cross link and label
1. [Introduction](#introduction)
<a name="introduction"></a>
-->

<h1 id="the-prospect-of-genomic-medical-espionage">The prospect of genomic medical espionage</h1>
<p>In the heyday of human source intelligence - think late Cold War - international espionage was relatively easy to understand.
This consisted of finding people willing to gather information from the enemy and deliver it to you.
The recruited individuals could be sympathetic to your cause and volunteer, or they could be coerced and remain secret in fear of punishment by the enemy.
Any reader of Le Carre will immediately envision the tangled web that this can ultimately produce; 
running agents, dead drops, double agents proving chicken-feed information to handlers to gain their trust! 
All very dramatic and palpable.
The other examples of intelligence data collection may be less tangible without experience; 
geospatial,
measurement and signature,
open-source,
signals,
technical,
cyber,
or financial.
The information gathered can be powerful but each is a “one-hit”. 
If the target changes, then the old data may not be useful again.
Now think of genetic data. 
Once gathered, it never changes. 
It only becomes more powerful when metadata is added.</p>

<p>Consider another distinction from the era of Cold War espionage.
It was essentially one side versus the other.
In the year 2021, most nations don’t have a direct enemy.
Therefore, today it is difficult to even summarise data collection in terms of “from whom” or “against what”.
Between 2013 and today, the revelation of global communications interception has shown that the easiest approach for intelligence data collection is just to gather everything and then figure out who the enemy is later.
I don’t have a clear example of how this relates to medical or genomic data, but I do keep in mind that the data holder can decide at any time in the future what genotypes they determine are of interest.
Policy makers will be very slow to recognise that an <em>a priori</em> usage plan is paramount to genomic data protection.</p>

<p>I heard about a meeting between two national intelligence groups (e.g. nation A and nation B).
Nation A wanted to discuss corporate espionage.
Nation B put it off as long as possible until finally explaining that in nation A, yes, national espionage is commendable to protect their country while corporate espionage is frowned upon.
However, for nation B any kind of intelligence that benefits the country is heroic.
Nation B freely acknowledges that anything worth stealing from A, will be stolen.
One cannot complain about the rules defined in the game, however those rules should not be forgotten just because nation A does not recognise them as readily.
We should keep in mind that our genomic data handlers may unexpectedly decide to share the data with others outside of our control.
GDPR won’t be of much use.
This anecdote illustrates a pertinent fact for human genomic medicine.
Unlike most personal data (email address, phone number, physical address, interests, EMEI),
you only have one genome sequence.
Once the online medical database gets leaked, you cannot request a new genome sequence via email.
Once it is out, it is out.</p>

<p>In a lecture by NSA technical director of the <a href="https://www.nsa.gov/what-we-do/cybersecurity/">information assurance directorate</a>, Richard George stated that credit card data is worth very little today on <em>“the market”</em>; 
health information is the new target of interest, 
because with that information comes an individuals’ identity and the potential to order drugs in their name.
With a little more imagination, one can envision the potential for genomic data. 
Some of the most powerful analysis techniques are still being developed today and we may see a big leap in genomic interpretation in the next decade. 
Once the analysis protocols are complete, whoever has the biggest database will be the most powerful (and for entrepreneurs, the most profitable, if their focus is on the correct questions in human health, etc).</p>

<p>Genomic data is most readily applicable to health. 
However, it could stretch much further.
Everyone knows about Google and Facebook - 
our daily activities categorise us into advertisement groups: 
Male age 25-30, interests, dislikes, how much are we willing to spend, etc.
It boils down do “how much advertisement costs are required to sell one unit of product?”.
In genomics and health this equates to effect size - what are the odds of disease given the genotype?
How about “given the genotype, how risk aversion are we, how impulsive, will we travel abroad or should we see ads for local entertainment”?
With greater and greater complexity, subtlety, and granularity, this may be possible as long as we can quantify the heritability of complex traits at very low effect sizes. 
Advertising and insurance risk calculations depend on relatively simple statistical formulas that just need enough data to remain profitable.
It is almost certain that much more esoteric applications are on the way.
It is extremely unlikely that legal protections on genomic data will be available before the open market dictates the trajectory.</p>

<p>Will there even be a need for medical espionage when Illunima, Google, BGI, etc. start offering free genome sequencing?
Will it be good or bad once every child gets genome sequencing along with their birth certificate?
Predicting the balance of world order is folly, but as they say “history repeats itslef”.
We can detach from our virtual identities; online presence, daily routines, but we cannot detach from our genetic identity.
Unlike fingerprinting, or retinal scan, are we prepared to provide a biometric identity with so much information?</p>

<h1 id="ransomware">Ransomware</h1>
<p>There have been several ransomware attacks on the health industry in recent years.
These have included public and private research and innovation institutions.
However, the worst examples of this type of crime were seen during the 2017 WannaCry attack;</p>
<blockquote>
  <p>“One of the largest agencies struck by the attack was the National Health Service hospitals in England and Scotland, 
and up to 70,000 devices – 
including computers, MRI scanners, blood-storage refrigerators and theatre equipment – 
may have been affected.” [1].</p>
</blockquote>

<h1 id="legal-safeguard">Legal safeguard</h1>
<p>With the major risks to life caused by attacks on medical institutions, 
the COVID-19 crisis has prompted a clear messages via
<em>the Oxford Statement on the International Law Protections Against Cyber Operations Targeting the Health Care Sector</em>, 
and a second statement on <em>Safeguarding Vaccine Research</em> during May and August 2020, respectively [2, 3].</p>

<p>International humanitarian law requires that medical care is respected and protected. 
COVID-19 illustrates that primary research is just as critical and should have the same protections.
In general, publicly funded research should be open and freely accessible to all (while respecting the privacy of human health data and personal data).
However, the long and complex process of primary research means that publication or open-sourcing can take a long time. 
Furthermore, the researchers depend on recognition of their work and are unlikely to publish intermediate results.</p>

<h1 id="metadata">Metadata</h1>
<p>It is understandable that nations who might be more interested 
in privately succeeding will be interested in stealing any information available.
Or more likely, this could be seen from private companies 
that are willing to steal intellectual property (IP).
For example, for a specific pathogen like SARS-CoV-2 just knowing what 
amino acid residues your competitor is most interested in can give you immediate 
insight that might have taken months to produce. 
Research project datasets tend to start out broad and move linearly towards a final result. 
If the actual documentation and code can be read then these critical results will be obvious. 
However, even just metadata like filenames can provide the key information.
It is not unreasonable to assume that the researchers will simply name datasets incrementally with the key process used. 
As an example, in a database you might see files with ascending date stamps:</p>
<ul>
  <li>data_group1.csv</li>
  <li>data_group1_pruned.csv</li>
  <li>data_group1_pruned_significant_hits.csv</li>
  <li>data_group1_pruned_significant_hits_pR127L.csv</li>
</ul>

<p>Anyone working on the same problem will understand the routine protocols and know that focusing their research on amino acid p.R127L will give them an advantage. 
Tackling this problem is one for IP law.
If it was for something like vaccine research then one might argue about applied ethics - 
“is it wrong to steal that which should be free information?” - 
but that weak argument is quickly disarmed by the fact that we would want our vaccine to come from the primary researcher, 
not the thief who is willing to cut corners.</p>

<p>It is obvious that protection should be implemented to prevent theft of <em>public IP</em>.
Furthermore, publicly funded health research results usually reside alongside private health information that deserves to have strong protections.</p>

<h1 id="disinformation">Disinformation</h1>
<p>Disinformation, <em>dezinformatsiya</em>, includes the leaking of information that 
seems valuable but is either a dead-end, or worse, intentionally harmful.
It is critical to ban the use of disinformation in any research affecting 
human health or publicly funded research.
It would be better to have instances of valid IP theft than risk any harm.</p>

<h1 id="data-pollution">Data pollution</h1>
<p>Conversely, data pollution is another potential risk factor.
Large scale genomics relies on careful curation. 
Importing incorrect data will pollute analysis and 
potentially mask true positive results from being found. 
In the last few years, some commercial genomic services have allowed users to 
upload their own genomic and personal phenotypic information.
While most users are just interested in their own results, this has a reasonable large potential for risk - 
a targeted data submission, randomly shuffling input phenotypic information 
would weaken the database for association analysis.</p>

<h1 id="in-the-media">In the media</h1>
<p>I notice that reports of medical espionage in public media are not always accurately defined. 
The news story of a former University Of Florida researcher 
indicted for scheme to defraud has, 
in other places, 
been framed more like someone working under cover for China 
rather than the more accurate description of 
someone committing fraud for failing to report overseas funding sources [4].
There are examples of stolen research IP for personal gain, 
such as the “hospital researcher sentenced to prison for conspiring to steal trade secrets, sell them in China” [5].
In this case, after ten years in the field the researcher was accused of 
“stealing exosome-related trade secrets concerning the research, 
identification and treatment of a range of pediatric medical conditions” 
and then “creating and selling exosome isolation kits” for sale via her company in China [5].
Unlike these examples of personal gain, there have been reports of national medical espionage during to the COVD-19 crisis.</p>

<p><a href="https://www.bbc.com/news/technology-54936886">The BBC reported in November 2020</a> 
[6] that</p>
<blockquote>
  <p>“Microsoft said at least nine health organisations including Pfizer had been targeted by state-backed organisations in North Korea and Russia”.</p>
</blockquote>

<p>In Feb 2021, 
a <a href="https://en.yna.co.kr/view/AEN20210216008451315">claim without source by Yonhap news</a> 
[7] 
and repeated by the BBC [8] 
says that the South Korean</p>

<blockquote>
  <p>“National Intelligence Service (NIS) unveiled information during a closed-door 
session of the National Assembly’s intelligence committee stating that
North Korea has attempted to hack the servers of a local drug manufacturer 
to obtain technology information on the company’s coronavirus vaccine and treatment.”</p>
</blockquote>

<p>Reports like this rarely include published evidence
and may be nothing but fantasy dreamed up by <em>The Tailor of Panama</em> type reporters.
Regardless, targeted theft is very likely and one would assume it to be happening
even when specific reports are unsubstantiated.</p>

<p>Remaining discussion to be added…</p>

<h1 id="protecting-data-and-promoting-open-source-access">Protecting data and promoting open-source access</h1>
<h2 id="projects-focused-on-safe-access">Projects focused on safe access</h2>
<p>The Global Alliance for Genomics and Health (GA4GH) is leading the effort in
safe data access.</p>
<blockquote>
  <p>“GA4GH is a policy-framing and technical standards-setting organization, 
seeking to enable responsible genomic data sharing within a human rights framework.
Enabling responsible genomic data sharing for the benefit of human health. “</p>
</blockquote>

<p>The <a href="https://www.ga4gh.org/how-we-work/driver-projects/">driver projects promoted by GA4GH</a> 
are the some of the best real world examples
today.
These include projects such as</p>
<ul>
  <li><a href="https://www.matchmakerexchange.org">Matchmaker Exchange</a>
    <ul>
      <li>as a tool to find genetic causes for patients with rare disease.</li>
    </ul>
  </li>
  <li><a href="https://www.nhlbiwgs.org">TOPMed program</a>
    <ul>
      <li>very large scale genome sequence data.</li>
    </ul>
  </li>
  <li><a href="https://www.genomicsengland.co.uk">Genomics England</a>
    <ul>
      <li>very large scale genome sequencing for patients in the UK.</li>
    </ul>
  </li>
</ul>

<p>All of the projects play an extremely important role in human health and research.
There are also many other similar initiatives outside of GA4GH which are promoting 
science collaboration.</p>

<h2 id="obstacles-to-data-privacy">Obstacles to data privacy</h2>
<p>Attending the GA4GH meetings and working as part of some of these projects,
I am struck by the fact that genomic privacy generally depends on a user trust system,
and data protection is focused on the end-user stage. 
I can exemplify the problem with the following simple example:</p>

<p>Every subject relying on genomic analysis must submit a DNA sample along with 
genetic consent, and the data is prepared in several stages;</p>
<ol>
  <li>Sample collection</li>
  <li>Sample preparation</li>
  <li>Sequencing</li>
  <li>Data processing</li>
  <li>Data submission</li>
  <li>Data access</li>
  <li>Reporting</li>
</ol>

<p><em>Problem level [1]</em><br />
The best systems today use a tracking system where the sample collection will
produce an anonymised ID in step 1.
All subsequent steps will therefore be detached from the subject’s personal information.
However, the personal information is not necessarily the valuable info, 
the genome sequence is (even if anonymised).
Anyone who has access to the DNA sample can easily sequence the genome for less than 
$500 US.</p>

<p><em>Problem level [2-3]</em><br />
The sample preparation and sequencing has identical risk as step 1. 
However, the sample is now likely out of the hands of the primary person responsible.
It will most likely be in a large scale sequence facility.</p>

<p><em>Problem level [4]</em><br />
Data processing will become more routine over time.
The large scale sequencing projects all follow a strict analysis pipeline,
but since a large majority of processing today is for clinical diagnosis, 
it means that at some stage a researcher will be required to do custom analysis
on an individual sample. 
This person is likely to have unrestricted access to all database samples.</p>

<p><em>Problem level [5]</em><br />
The data submission level will consist of anonymous subject IDs again, 
however it will contain whole genome sequences (or processed variant called datasets).</p>

<p><em>Problem level [6]</em><br />
Data access is the step in which nearly every genomic data protection process is
focused. 
It is a logical starting position since this is the stage in which researchers 
will require permissions for accessing large amounts of data for research purposes.
It has the addition risk in that other medical data is usually also present, 
typically clinical phenotype data.</p>

<p><em>Problem level [7]</em><br />
Once a candidate genomic determinant for clinical diagnosis is established,
the researcher is going to complete a reporting procedure.
One would imagine that this is a clean, automated, process. 
However, it is very common for researchers and clinicians to simply email back and
forth about very sensitive information.
This is understandable and often a patient’s life could be saved with a rapid diagnosis.</p>

<p>However, the facts should be clearly stated. 
Plain text emails, SMS, and other types of communications are collected routinely 
via national surveillance.
<a href="https://en.wikipedia.org/wiki/List_of_government_mass_surveillance_projects">Not to be dismissed as conspiracy theory</a>, 
it is a fact that your private information may be collected without your consent,
<em>but</em> you <em>will</em> get more expertise in your medical treatment when physicians can communicate with their colleagues via email, etc.</p>

<p><em>Problem summary:</em><br />
Nearly all privacy protocols today are focused on step 6.
Anyone interested in large scale medical espionage will focus on any of the 
other, much more readily available, steps 1-5.
Furthermore, data access at step 6 can be restricted to trusted researchers, 
but there should be no confusion - humans can always find methods for 
exporting data from protected access portals <sup id="fnref:foot" role="doc-noteref"><a href="#fn:foot" class="footnote" rel="footnote">1</a></sup>.
While the privilege of data access is restricted, 
it is essentially based on trust and 
recruited patient participants should not be lead to believe otherwise.
Some very sophisticated methods allow for data analysis of encrypted data, 
but these are not widely used today and will not be able to replace all of the 
required methods in the near future.</p>

<h2 id="future-methods">Future methods</h2>
<p>In addition to the highly commendable initiatives for genomic data sharing today,
there are several options that can be implemented in the future.</p>

<p>To be finished..</p>

<p>One may argue that the proposed danger is hyperbolic; 
that it is a subject for intellectual property rather than political.
When once ineptly accused of making a topic political,
Christopher Hitchens extemporaneously rebutted with an apt simile to the nuclear threat at the time (1984), 
arguing that some topics they are explicitly political whether or not others lack a recognition of facts:</p>

<blockquote>
  <p>“As we sit here, everyone is this room has been made into a front-line soldier; 
the nuclear age means that we are all conscripted; we don’t have the right to conscientious objection anymore. 
We are on the front-line while the soldiers are in the bunkers.
That is being done to us whether we like it or not. 
We can’t then complain of those that are objecting to it that they are politicising it. 
The politicisation has been done. 
We are all conscripted. 
We might as well be sitting here in uniform.” [9]</p>
</blockquote>

<p>While the comparison to a nuclear détente is an exaggeration, 
this problem is not simply a matter of consumer choice. 
How difficult it is, even to quantify the dangers amongst <em>experts</em> in human genomics. 
Not even the unit of measurement is known to quantify the declination of risk.</p>

<h1 id="references">References</h1>
<hr />

<p>[1] WannaCry ransomware attack, wikipedia.org<br />
<a href="https://en.wikipedia.org/wiki/WannaCry_ransomware_attack#Impact">https://en.wikipedia.org/wiki/WannaCry_ransomware_attack#Impact</a><br />
<br />
[2] The Oxford Statement on the International Law Protections Against Cyber Operations Targeting the Health Care Sector<br />
<a href="https://www.elac.ox.ac.uk/the-oxford-statement-on-the-international-law-protections-against-cyber-operations-targeting-the-hea">https://www.elac.ox.ac.uk/the-oxford-statement-on-the-international-law-protections-against-cyber-operations-targeting-the-hea</a><br />
<br />
[3] The Second Oxford Statement on International Law Protections of the Healthcare Sector During Covid-19: Safeguarding Vaccine Research<br />
<a href="https://www.elac.ox.ac.uk/article/the-second-oxford-statement">https://www.elac.ox.ac.uk/article/the-second-oxford-statement</a><br />
<br />
[4] Former University Of Florida Researcher Indicted For Scheme To Defraud National Institutes Of Health And University Of Florida<br />
<a href="http://crweworld.com/fl/trendingnow/news/1871206/former-university-of-florida-researcher-indicted-for-scheme-to-defraud-national-institutes-of-health-and-university-of-florida">http://crweworld.com/fl/trendingnow/news/1871206/former-university-of-florida-researcher-indicted-for-scheme-to-defraud-national-institutes-of-health-and-university-of-florida</a><br />
<br />
[5] Hospital researcher sentenced to prison for conspiring to steal trade secrets, sell them in China<br />
<a href="http://crweworld.com/oh/trendingnow/news/1867620/hospital-researcher-sentenced-to-prison-for-conspiring-to-steal-trade-secrets-sell-them-in-china">http://crweworld.com/oh/trendingnow/news/1867620/hospital-researcher-sentenced-to-prison-for-conspiring-to-steal-trade-secrets-sell-them-in-china</a><br />
<br />
[6] Coronavirus: North Korea and Russia hackers ‘targeting vaccine’.<br />
<a href="https://www.bbc.com/news/technology-54936886">https://www.bbc.com/news/technology-54936886</a><br />
<br />
[7]
N. Korea attempted to steal COVID-19 vaccine, treatment technology via hacking: NIS<br />
<a href="https://en.yna.co.kr/view/AEN20210216008451315">https://en.yna.co.kr/view/AEN20210216008451315</a><br />
<br />
[8] North Korea accused of hacking Pfizer for Covid-19 vaccine data.<br />
<a href="https://www.bbc.com/news/technology-56084575">https://www.bbc.com/news/technology-56084575</a><br />
<br />
[9] Firing line Episode S0629, Recorded on December 11, 1984. Guests: R. (Robert Emmett) Emmett Tyrrell Jr., Christopher Hitchens.<br />
<br />
Coronavirus: Cyber-spies hunt Covid-19 research, US and UK warn<br />
<a href="https://www.bbc.com/news/technology-52551023">https://www.bbc.com/news/technology-52551023</a><br />
<br />
The Cyber Side of Vaccine Nationalism<br />
<a href="https://www.cfr.org/blog/cyber-side-vaccine-nationalism">https://www.cfr.org/blog/cyber-side-vaccine-nationalism</a><br />
<br />
Race for Coronavirus Vaccine Pits Spy Against Spy<br />
<a href="https://www.nytimes.com/2020/09/05/us/politics/coronavirus-vaccine-espionage.html?referringSource=articleShare">https://www.nytimes.com/2020/09/05/us/politics/coronavirus-vaccine-espionage.html?referringSource=articleShare</a></p>

<h1 id="footnotes">Footnotes</h1>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:foot" role="doc-endnote">
      <p><a href="/2019/08/19/devil_in_detail.html">A trivial example of data export by hiding data within a “results figure”</a>. <a href="#fnref:foot" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</p>

  <h2> - </h2>
  <p><h1 id="rag">RAG</h1>
<ul id="markdown-toc">
  <li><a href="#rag" id="markdown-toc-rag">RAG</a></li>
  <li><a href="#abstract" id="markdown-toc-abstract">Abstract</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#methods" id="markdown-toc-methods">Methods</a>    <ul>
      <li><a href="#population-genetics-and-data-sources" id="markdown-toc-population-genetics-and-data-sources">Population genetics and data sources</a></li>
      <li><a href="#data-processing" id="markdown-toc-data-processing">Data processing</a></li>
      <li><a href="#raw-data-availability-and-analysis-script" id="markdown-toc-raw-data-availability-and-analysis-script">Raw data availability and analysis script</a></li>
      <li><a href="#data-visualisation" id="markdown-toc-data-visualisation">Data visualisation</a></li>
      <li><a href="#validation-of-mrf-against-functional-data" id="markdown-toc-validation-of-mrf-against-functional-data">Validation of MRF against functional data</a></li>
    </ul>
  </li>
  <li><a href="#results" id="markdown-toc-results">Results</a>    <ul>
      <li><a href="#rag1-and-rag2-conservation-and-mutation-rate-residue-frequency" id="markdown-toc-rag1-and-rag2-conservation-and-mutation-rate-residue-frequency">RAG1 and RAG2 conservation and mutation rate residue frequency</a></li>
      <li><a href="#mrf-scores-select-for-confirmed-variants-in-human-disease" id="markdown-toc-mrf-scores-select-for-confirmed-variants-in-human-disease">MRF scores select for confirmed variants in human disease</a></li>
      <li><a href="#top-candidate-variants-require-validation" id="markdown-toc-top-candidate-variants-require-validation">Top candidate variants require validation</a></li>
      <li><a href="#false-positives-in-transib-domains-do-not-negatively-impact-prediction" id="markdown-toc-false-positives-in-transib-domains-do-not-negatively-impact-prediction">False positives in <em>Transib</em> domains do not negatively impact prediction</a></li>
      <li><a href="#mrf-predicts-rag-deficiency-amongst-pid-patients-harbouring-rare-variants" id="markdown-toc-mrf-predicts-rag-deficiency-amongst-pid-patients-harbouring-rare-variants">MRF predicts RAG deficiency amongst PID patients harbouring rare variants</a></li>
      <li><a href="#mrf-supplements-pathogenicity-prediction-tools-for-translational-research" id="markdown-toc-mrf-supplements-pathogenicity-prediction-tools-for-translational-research">MRF supplements pathogenicity prediction tools for translational research</a></li>
      <li><a href="#figure" id="markdown-toc-figure">Figure</a></li>
    </ul>
  </li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a>    <ul>
      <li><a href="#main-supplemental-data-table" id="markdown-toc-main-supplemental-data-table">Main supplemental data table</a></li>
      <li><a href="#clinical-relevance-of-top-candidates" id="markdown-toc-clinical-relevance-of-top-candidates">Clinical relevance of top candidates</a></li>
      <li><a href="#supplemental-analysis-tables" id="markdown-toc-supplemental-analysis-tables">Supplemental analysis tables</a></li>
      <li><a href="#protein-structure-application" id="markdown-toc-protein-structure-application">Protein structure application</a></li>
      <li><a href="#median-cadd-score-per-residue" id="markdown-toc-median-cadd-score-per-residue">Median CADD score per residue</a></li>
      <li><a href="#supplemental-file" id="markdown-toc-supplemental-file">Supplemental file</a></li>
      <li><a href="#genome-wide-and-disease-specific-application" id="markdown-toc-genome-wide-and-disease-specific-application">Genome-wide and disease-specific application</a></li>
      <li><a href="#bayesian-probability" id="markdown-toc-bayesian-probability">Bayesian probability</a></li>
    </ul>
  </li>
</ul>

<h1 id="abstract">Abstract</h1>
<p>While widespread genome sequencing ushers in a new era of preventive medicine, the tools for predictive genomics are still lacking.
Time and resource limitations mean that human diseases remain uncharacterised because of an inability to predict clinically relevant genetic variants.
A strategy of targeting highly conserved protein regions is used commonly in functional studies. 
However, this benefit is lost for rare diseases where the attributable genes are mostly conserved. 
An immunological disorder exemplifying this challenge occurs through damaging mutations in <em>RAG1</em> and <em>RAG2</em> which presents at an early age with a distinct phenotype of life-threatening immunodeficiency or autoimmunity. 
Many tools exist for variant pathogenicity prediction but these cannot account for the probability of variant occurrence. 
Here, we present a method that predicts the likelihood of mutation for every amino acid residue in the RAG1 and RAG2 proteins. 
Population genetics data from approximately 146,000 individuals was used for rare variant
analysis. 
Forty-four known pathogenic variants reported in patients and recombination activity measurements from 110 RAG1/2 mutants were used to
validate calculated scores. 
Probabilities were compared with 98
currently known human cases of disease. 
A genome sequence dataset of 558
patients who have primary immunodeficiency but that are negative for RAG
deficiency were also used as validation controls. 
We compared the
difference between mutation likelihood and pathogenicity prediction. 
Our
method builds a map of most probable mutations allowing pre-emptive
functional analysis. 
This method may be applied to other diseases with
hopes of improving preparedness for clinical diagnosis.</p>

<p>Authors:
Dylan Lawless,
Hana Lango Allen,
James Thaventhiran,
‘NIHR BioResource–Rare Diseases Consortium’,
Flavia Hodel,
Rashida Anwar,
Jacques Fellay,
Jolan E. Walter’,
Sinisa Savic.</p>

<h4 id="ethics-statement">Ethics statement</h4>

<p>The study was performed in accordance with the Declaration of Helsinki.
The NIHR BioResource projects were approved by Research Ethics
Committees in the UK and appropriate national ethics authorities in
non-UK enrolment centres.</p>

<h4 id="abbreviations">Abbreviations</h4>

<p>BCR (B-cell receptor), CADD (combined annotation dependent depletion),
CID-G/A (combined immunodeficiency with granuloma and/or autoimmunity),
GWAS (genome-wide association studies), HGMD (human gene mutation
database), \({M}_{r}\) (mutation rate), MRF (mutation rate residue
frequency), PID (primary immunodeficiency), pLI (probability of being
loss-of-function intolerant), <em>RAG1</em> (recombination activating gene 1),
\({R}_{f}\) (residue frequency), RNH (RNase H), RSS (recombination signal
sequence), SCID (severe combined immunodeficiency), TCR (T-cell
receptor).</p>

<h1 id="introduction">Introduction</h1>

<p>Costs associated with genomic investigations continue to reduce [payne2018cost] while the richness of data generated increases.
Globally, the adoption of wide scale genome sequencing implies that all new-born infants may receive screening for pathogenic genetic variants
in an asymptomatic stage, pre-emptively  [kwan2014newborn]. 
The one dimensionality of individual genomes is now being expanded by the possibility of massive parallel sequencing for somatic variant analysis and by single-cell or lineage-specific genotyping; culminating in a genotype spectrum. 
In whole blood, virtually every nucleotide position may be mutated across \(10^5\) cells 
[Liggett208066]. 
Mapping one’s genotype across multiple cell types and at several periods during a person’s life may soon be feasible 
[clark2018scnmt]. 
Such genotype snapshots might allow for prediction and tracking of somatic, epigenetic, and transcriptomic profiling.</p>

<p>The predictive value of genomic screening highly depends on the computation tools used for data analysis and its correlation with functional assays or prior clinical experience. 
Interpretation of that data is especially challenging for rare human genetic disorders;
candidate disease-causing variants that are predicted as pathogenic
often require complex functional investigations to confirm their significance. 
There is a need for predictive genomic modelling with aims to provide a reliable guidance for therapeutic intervention for patients harbouring genetic defects for life-threatening disease before the illness becomes clinically significant.</p>

<p>The study of predictive genomics is exemplified by consideration of gene essentiality, accomplished by observing intolerance to loss-of-function variants. 
Several gene essentiality scoring methods are available for both the coding and non-coding genome  [bartha2017human]. 
Approximately 3,000 human genes cannot tolerate the loss of one allele
[bartha2017human]. 
The greatest hurdle in monogenic disease is the interpretation of variants of unknown significance while functional validation is a major time and cost investment for laboratories investigating rare disease.</p>

<p>Severe, life-threatening immune diseases are caused by genetic
variations in almost 300 genes
[picard2018international conley2014discovery] however, only a small percentage of disease causing variants have been characterised using functional studies. 
Several robust tools are in common usage for predicting variant pathogenicity.  Compared to methods for pathogenicity prediction, a void remains for predicting mutation probability, essential for efficient pre-emptive validation. 
Our investigation aims to apply predictive genomics as a tool to identify genetic variants that are most likely to be seen in patient cohorts.</p>

<p>We present the first application of our novel approach of predictive genomics using Recombination activating gene 1 (RAG1) and RAG2 deficiency as a model for a rare primary immunodeficiency (PID) caused by autosomal recessive variants. 
<em>RAG1</em> and <em>RAG2</em> encode lymphoid-specific proteins that are essential for V(D)J recombination.
This genetic recombination mechanism is essential for a robust immune response by diversification the T and B cell repertoire in the thymus and bone marrow, respectively  [schatz1989v oettinger1990rag].
Deficiency of RAG1  [mombaerts1992rag] and RAG2  [shinkai1992rag] in mice causes inhibition of B and T cell development. 
[schwarz1996rag ]
formed the first publication reporting that RAG mutations in humans causes severe combined immunodeficiency (SCID), and deficiency in peripheral B and T cells. 
Patient studies identified a form of immune dysregulation known as Omenn syndrome
[de1991restricted rieux1998highly]. 
The patient phenotype includes multi-organ infiltration with oligoclonal, activated T cells. 
The first reported cases of Omenn syndrome identified infants with hypomophic RAG variants which retained partial recombination activity
[villa1998partial]. 
RAG deficiency can be measured by in vitro quantification of recombination activity
[lawless2018prevalence lee2014systematic tirosh2018recombination].
Hypomorphic <em>RAG1</em> and <em>RAG2</em> mutations, responsible for residual V(D)J recombination activity (on average 5-30%), result in a distinct phenotype of combined immunodeficiency with granuloma and/or autoimmunity (CID-G/A)
[kwan2014newborn walter2015broad schuetz2008immunodeficiency].</p>

<p>Human RAG deficiency has traditionally been identified at very early ages due to the rapid drop of maternally-acquired antibody in the first six months of life. 
A loss of adequate lymphocyte development quickly results in compromised immune responses. 
More recently, we have found that RAG deficiency is also found for some adults living with PID
[lawless2018prevalence].</p>

<p><em>RAG1</em> and <em>RAG2</em> are highly conserved genes but disease is only reported with autosomal recessive inheritance. 
Only 44% of amino acids in RAG1 and RAG2 are reported as mutated on GnomAD and functional validation of candidate variants is difficult 
[lek2016analysis].
Pre-emptive selection of residues for functional validation is a major challenge; 
a selection based on low allele frequency alone is infeasible since the majority of each gene is highly conserved. 
A shortened time between genetic analysis and diagnosis means that treatments may be delivered earlier. 
RAG deficiency may present with diverse phenotypes and treatment strategies vary. 
With such tools, early intervention may be prompted. 
Some patients could benefit from hematopoietic stem cell transplant  [john2016unrelated] when necessary while others may be provided mechanism-based treatment  [casanova2014guidelines]. 
Here, we provide a new method for predictive scoring that was validated against
groups of functional assay values, human disease cases, and population genetics data. 
We present the list of variants most likely seen as future determinants of RAG deficiency, meriting functional investigation.</p>

<h1 id="methods">Methods</h1>
<h2 id="population-genetics-and-data-sources">Population genetics and data sources</h2>

<p>GnomAD (version r2.0.2)  [lek2016analysis] was queried for the canonical transcripts of <em>RAG1</em> and <em>RAG2</em> from population genetics data of approximately 146,000 individuals; ENST00000299440 (<em>RAG1</em>) 1586 variants, GRCh37 11:36532259-36614706 and ENST00000311485 (<em>RAG2</em>) 831 variants, GRCh37 11:36597124 - 36619829. 
Data was filtered to contain the variant effect identifiers: frameshift, inframe deletion, inframe
insertion, missense, stop lost, or stop gained. 
Reference transcripts were sourced from Ensembl in the FASTA format amino acid sequence for transcript RAG1-201 ENST00000299440.5 HGNC:9831 and transcript RAG2-201 ENST00000311485.7 HGNC:9832.
These sequences were converted to their three-letter code format using <em>One to Three</em> from the Sequence Manipulation Suite (SMS2) 
[stothard2000sequence]. 
Combined Annotation Dependent Depletion (CADD) scores were sourced from (Nov 2018) and are reported by 
[kircher2014general ]. 
The dataset used was “All possibleSNVs” from whole genome data, from which we extracted the data for coding regions of <em>RAG1</em> and <em>RAG2</em>. 
We used the Human Gene Mutation Database (HGMD) from the Institute of Medical Genetics in Cardiff as a pre-defined source of known RAG deficiency cases (Feb 2019, free access
version to NM_000448.2.) 
[stenson2014human]. 
Data was formatted into CSV and imported into R for combined analysis with PHRED-scaled CADD scores and the main dataframe. 
The crystal structure render of DNA bound RAG complex was produced with data from RCSB Protein Data Bank
(3jbw.pdb)  [ru2015molecular]. 
Structures were visualised using the software VMD from the Theoretical and Computational Biophysics Group
[Humphrey1996vmd], imaged with Tachyon rendering 
[Stone1998Ane], and colour mapped using our scoring method.</p>

<h2 id="data-processing">Data processing</h2>

<p>The population genetics input dataset used GnomAD variant allele frequencies and reference sequences processed as CSV files, cleaned and sorted to contain only amino acid codes, residue numbers, alternate residues, alternate allele frequencies, and a score of 0 or 1 to indicate presence or absence of variants where 1 represented none reported. 
An annotation column was also provided to label where multiple alternate variants existed. 
Statistics and calculation steps are listed in order in Supplemental Tables E3-E8.</p>

<p>The percentage of conserved residues was calculated (55.99% of amino acids contained no reported variants in RAG1, 55.98% in RAG2 (
Table E4). 
Basic protein statistics were generated using canonical reference transcript sequences of <em>RAG1</em> and <em>RAG2</em> with the SMS2 tool <em>Protein Stats</em> 
[stothard2000sequence]. 
The resulting pattern percentage value was converted to a frequency (decimal 0-1) based on the number of residues per protein to generate the residue frequency
(\({R}_{f}\)). 
The \({R}_{f}\) values were found for both proteins as shown in <strong>Table E5</strong> and summarised in <strong>Table E6</strong>.</p>

<p>The count of variants per residue were found for both proteins and the mutation rates (\({M}_{r}\)) per residue were calculated as shown in
** Table E7**. 
\({M}_{r}\) was found by counting the number of mutations per residue in a window, sized to contain each protein
individually. 
For genome-wide application the window size may be increased or decreased. 
In this case the window consisted of only the coding regions. 
The \({M}_{r}\) values were then converted to the frequencies based on the number of residues per protein. 
Separate, and overlapping windows could also be used based on genome phase data and regions of linkage disequilibrium to account for non-random association of alleles at different loci; this might be particularly important for disorders with multiple genetic determinants.</p>

<p>The \({M}_{r}\) and \({R}_{f}\) multiply to give the raw mutation rate residue frequency (MRF) value (**Table E8
). 
This value is also shown in **Tables mrf.assay] and 
Table:1
. 
Our investigation used a Boolean score \(C\) to account for the presence or absence of a mutation in the general population; 0 for any variant existing in the population and 1 for conserved residues.
\(C \times {M}_{r} \times {R}_{f}\), in our case, produced the MRF score for conserved residues. 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a></p>

<p>(ii)** illustrates the raw MRF as a histogram and the MRF, after applying \(C\), as a heatmap.</p>

<p>An important consideration for future application is whether to use this Boolean score or instead use a discrete variable which accounts for the
true allele frequency in the general population.<br />
In the clinical setting, the likelihood of <em>de novo</em> mutations and inherited mutations have different impacts when considering recessive and dominant diseases.
A patient is more likely to inherit a variant that exists even at a very low frequency than to acquire a random <em>de novo</em> mutation. 
Therefore, a value representing an allele frequency may be used to replace \(C\) in many investigations, particularity when considering variants that exist
at low rates. 
PRHED-scaled CADD score data consisted of nucleotide level values. 
For comparison with MRF, the median CADD scores were averaged per codon as demonstrated in text. 
A summary of data processing and analysis is illustrated in 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">method_map</a>.</p>

<h2 id="raw-data-availability-and-analysis-script">Raw data availability and analysis script</h2>

<p>The supplemental files 
<em>“Raw_data_R_analysis_for_figures”</em> 
contains all raw data and analysis methods used to produce figures (except illustrations in Figures 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>\ and 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 6</a>).
<em>“data_analysis.R”</em> 
is an R script that contains the methods used to produce figures. 
Each of the input data CSV files are explained on first usage within the analysis script. 
Running 
<em>“data_analysis.R”</em> 
from within the same directory as the associated input data CSV files will replicate analysis.</p>

<h2 id="data-visualisation">Data visualisation</h2>

<p>For our visualisation of MRF scores, small clusters of high MRF values were of more appealing than individual highly conserved residues.
Therefore, we applied a 1% average filter where values were averaged over a sliding window of N number of residues (10 in the case of RAG1, 6
in the case of RAG2). 
For a clear distinction of MRF clusters, a cut-off threshold was applied at the 75\(^{th}\) percentile (e.g. 
0.0168 in RAG1) as shown in heatmaps in  FIGURE
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
(iii)** and</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 6</a>. 
The gene heatmaps for coding regions in <em>RAG1</em>
and <em>RAG2</em> (Fig. 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a> 
) were populated with (i)
Boolean \(C\) score from population genetics data, (ii) raw MRF scores, and (iii) MRF clusters with 1% average and cut-off threshold. 
GraphPad Prism was used for heatmaps. 
The data used for heatmaps is available in
TABLE Table:1
and in the supplemental R source to allow for alternative visualisations. 
An example of alternative output for non-R users is shown in
&lt;FIGURE RAG_MRF_map. 
Adobe Illustrator and Photoshop were used for protein domain illustrations in Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
(iv).</p>

<h2 id="validation-of-mrf-against-functional-data">Validation of MRF against functional data</h2>

<p>The recombination activity of RAG1 and RAG2 was previously measured on known or candidate pathogenic variants
[lee2014systematic lawless2018prevalence tirosh2018recombination].
Briefly, the pathogenicity of variants in <em>RAG1</em> and <em>RAG2</em> was measured functionally <em>in vitro</em> by either expression of RAG1 and RAG2 in
combination with a recombination substrate plasmid containing recombination signal sequence (RSS) sites which are targeted by RAG complex during normal V(D)J recombination, or Abelson virus-transformed Rag2-/- pro-B cells with an RSS-flanked inverted GFP cassette.
Recombination events were assessed by quantitative real-time PCR using comparative CT or expression of GFP evaluated by flow cytometry,
respectively. 
The inverse score of recombination activity (0-100%) was used to quantify pathogenicity of variants in our study. 
Comparison between known pathogenicity scores and MRF was done by scaling MRF scores from 0-100% (100% being highest probability of occurring as
damaging). 
A data and analysis is summarised in Figure
FIGURE 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">method_map</a></p>

<h1 id="results">Results</h1>
<h2 id="rag1-and-rag2-conservation-and-mutation-rate-residue-frequency">RAG1 and RAG2 conservation and mutation rate residue frequency</h2>

<p>Variant probability prediction is dependent on population genetics data.
Our study queried GnomAD 
[lek2016analysis] 
to identify conserved residues using a Boolean score \(C\) of 0 (present in population) or 1 (conserved). 
The gene-specific mutation rate \({M}_{r}\) of each residue was calculated from allele frequencies. 
The gene-specific residue frequency \({R}_{f}\) represented the frequency of a residue occurring per gene, acquired by converting gene residue percentage (from the SMS2 tool
<em>Protein stats</em>) to a frequency (decimal 0-1) 
[stothard2000sequence].
Together the values were used to calculate the most probable disease-causing variants which have not yet been identified in patients.
We termed the resulting score a mutation rate residue frequency, where \(MRF = {C} \times {M}_{r} \times {R}_f\). 
This score represents the likelihood that a clinically relevant mutation will occur.</p>

<p>Figure 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a> 
presents the most probable unidentified
disease-causing variants in <em>RAG1/2</em>. 
Variants with a low MRF may still be damaging but resources for functional validation are best spent on
gene regions with high MRF. 
Clusters of conserved residues are shown in
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
 (i)** and are generally considered important for protein structure or function. 
However, these clusters do not predict the likelihood of mutation. 
Raw MRF scores are presented in
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
(ii)
Histograms illustrates the MRF without Boolean scoring applied and 
FIGURE
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
(iii) provides a clearer illustration of top MRF score clusters. 
For visualisation, a noise reduction method was applied; a sliding window was used to find the average MRF per 1% interval of each gene. 
The resulting scores displayed in 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 1</a>
(iii)**
contain a cut-off threshold to highlight the top scoring residues (using
the 75\(^{th}\) percentile). 
Variant sites most likely to present in disease cases are identified by high MRF scoring. 
This model may be expanded by the addition of phenotypic or epigenetic data
(<strong>Supplemental;</strong> ).</p>

<p>![RAG1 (red, left) and RAG2 (blue, right) conservation and mutation rate
residue frequency. 
(i) Gene conservation score; non-conserved 0 and
conserved 1. 
Colour indicates no known mutations in humans. 
(ii)
Histogram; raw MRF score. 
Heatmap; MRF prediction for conserved residues, graded 0 to 0.05 (scale of increasing mutation likelihood with human disease). 
(iii) Coloured bars indicate most likely clinically relevant variant clusters. 
MRF score averaged with 1% intervals for each gene and cut-off below 75th percentile, graded 0 to 0.03 (noise
reduction method). 
(iv) Gene structure with functional domains. 
Full list of residues and scores available in 
TABLE Table:1
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure_main</a></p>

<p>Table [Table:1
 provides all MRF scores for both proteins. 
Raw data used for calculations and the list of validated residues of RAG1 and RAG2 are available in 
TABLE **Tables E3 - E8
. 
shows the MRF mutation likelihood score for mutations that have also been reported as tested for recombination activity in functional assays.
The likelihood of mutation does not correlate with pathogenicity;</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a>
and
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 4</a>
show that most mutations tested had severe loss of protein function, while the likelihood each mutation occurring in humans varied significantly. 
Analysis-ready files are also available in Supplemental data along with the associated R source file to allow for alternative visualisations as shown in **Figure
FIGURE RAG_MRF_map
.</p>

<p>TABLE ref</p>

<h2 id="mrf-scores-select-for-confirmed-variants-in-human-disease">MRF scores select for confirmed variants in human disease</h2>

<p>We have applied MRF scores to known damaging mutations from other extensive reports in cases of human disease
[schuetz2008immunodeficiency lee2014systematic villa2001v abolhassani2014hypomorphic kutukculer2012novel sobacchi2006rag villa1998partial noordzij2002immunophenotypic crestani2014rag1 dalal2005evolution kuijpers2011idiopathic gruber2009clinical de2010hypomorphic buchbinder2015identification felgentreff2011clinical schwarz1996rag reiff2013exome corneo2001identical asai2011analysis kato2015rag1 yu2014human de2005novel zhang2005novel henderson2013expanding avila2010highly riccetto2014compound walter2015broad gomez2000mutations chou2012novel]
[originally compiled by [notarangelo2016human ]]. 
This dataset compares a total of 44 variants. 
We expected that functionally damaging variants (resulting in low recombination activity in vitro) that have the highest probability of occurrence would be identified with high MRF scores. 
MRF prediction correctly identified clinically relevant mutations in <em>RAG1</em> and <em>RAG2</em>
(Fig. 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Human_cases</a>
(i)).
Variants reported on GnomAD which are clinically found to cause disease had significantly higher MRF scores than variants which have not been
reported to cause disease. 
We observed that rare and likely mutations provided high scores while rare but unlikely or common variants had low scores
(Fig. 
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Human_cases</a>
(i)).</p>

<p>![RAG1 and RAG2 MRF score predict the likelihood of mutations that are clinically relevant. 
(i) Known damaging variants (clinically diagnosed with genetic confirmation) reported on GnomAD have significantly higher
MRF scores than unreported variants. 
(ii) GnomAD rare variant allele frequency &lt;0.0001. 
No significant difference in allele frequency is found between known damaging and non-clinically reported variants.
Unpaired t-test. 
RAG1 P-value 0.002** RAG2 P-value 0.0339*. 
MRF; mutation rate residue frequency, ns; non-significant.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 2</a></p>

<p>Allele frequency is generally the single most important filtering method for rare disease in whole genome (and exome) sequencing experiments.
Variants under pressure from purifying selection are more likely to cause disease than common variants. 
However, most RAG mutations are rare. 
Therefore, allele frequencies of rare variants reported on GnomAD cannot differentially predict the likelihood of causing disease 
(<strong>Fig.
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Human_cases</a>
(ii)</strong>). 
As such, we found no significant difference between known damaging variants and those that have not yet
been reported as disease-causing. 
The comparison between 
<strong>Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Human_cases</a>
(i) and (ii)</strong> 
illustrates the reasoning for the
design of our method.</p>

<p>Many non-clinically-reported rare variants may cause disease; the MRF score identifies the top clinically relevant candidates. 
Based on the frequency of protein-truncating variants in the general population, 
<em>RAG1</em> and <em>RAG2</em> are considered to be tolerant to the loss of one allele, as indicated by their low probability of being loss-of-function
intolerant (pLI) scores of 0.00 and 0.01, respectively 
[lek2016analysis]. 
This is particularly important for recessive diseases such as RAG deficiency where most new missense variants will be of unknown significance until functionally validated.</p>

<h2 id="top-candidate-variants-require-validation">Top candidate variants require validation</h2>

<p>Functionally characterising protein activity is both costly and time consuming. 
RAG1 and RAG2 have now been investigated by multiple functional assays for at least 110 coding variants
[lee2014systematic tirosh2018recombination lawless2018prevalence].
In each case, researchers selected variants in <em>RAG1</em> and <em>RAG2</em> that were potentially damaging or were identified from PID patients as the
most probable genetic determinant of disease. 
Functional assays for RAG deficiency in those cases, and generally, measured a loss of recombination activity as a percentage of wild type function (0-100%).</p>

<p>Pre-emptively performing functional variant studies benefits those who will be identified with the same variants in the future, before the
onset of disease complications. 
While more than 100 variants have been assayed in vitro, we calculated that only one-quarter of them are most
probable candidates for clinical presentation. 
<em>*Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a>
 illustrates that while functional work targeted “hand picked” variants that were ultimately
confirmed as damaging, many of them may be unlikely to arise based on population genetics data. 
**Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a>
 presents, in increasing order, the number of potential variants based on likelihood of presentation and
stacked by the number of variants per score category. 
Variants that have been measured for their loss of protein activity are coloured by
severity. 
Potential variants that remain untested are coloured in grey.
Only 21 of the top 66 most probable clinically relevant variants have been assayed in *RAG1</em>.</p>

<p>![RAG1 and RAG2 MRF score categories and variants assayed to date.
Protein residues are ranked and stacked into categories based on their MRF score. 
High scores (0.043 and 0.038 in RAG1 and RAG2, respectively) represent a greater mutation likelihood. 
Functional assays have measured recombination activity (as its inverse; % loss of activity) in a total
of 110 mutants. 
The severity of protein loss of function is represented by a red gradient. 
Residues that have not been functionally tested are shown in grey. 
While many protein residues are critical to protein function, their mutation is less probable than many of the top MRF
candidates. 
Data further expanded in Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 4</a>. 
MRF; mutation rate residue
frequency.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a></p>

<p>Supplemental Figure **
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 4</a>
 further
illustrates the individual variants which have been tested functionally (the coloured <em>recombination activity</em> subset of Fig</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a>]). 
We compared predicted MRF scores to assay measurements for 71 <em>RAG1</em> and 39 <em>RAG2</em> mutants. 
Most mutations tested showed severe loss of protein function (bottom panel of
Supplemental Figure **
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 4</a>
), while the likelihood each mutation occurring in humans varied significantly (top panels).</p>

<p>If MRF scoring was used in the same cases pre-emptively, the loss of investment would be minimal; only 8 variants out of 71 mutants tested
had an above-average MRF score while being measured as functionally benign (a rate of 11.27%). 
RAG2 had only 3 out of 39 variants (7.69%) with an above-average MRF score while functionally benign. 
For the expended resources, approximately 30% more top candidates would have been tested in place of unlikely and functionally non-damaging
mutations. 
However, the true measurement of accuracy is limited in that very few of the most likely clinically relevant variants predicted by
MRF scoring have been tested to date.</p>

<h2 id="false-positives-in-transib-domains-do-not-negatively-impact-prediction">False positives in <em>Transib</em> domains do not negatively impact prediction</h2>

<p>Adaptive immunity is considered to have evolved through jawed vertebrates after integration of the RAG transposon into an ancestral
antigen receptor gene  [agrawal1998transposition hiom1998dna]. 
The <em>Transib</em> transposon is a 600 amino acid core region of RAG1 that targets RSS-like sequences in many invertebrates. 
A linked <em>RAG1/RAG2</em> was shown in the lower dueterosome (sea urchin), indicating an earlier common ancestor than the invertebrate  [fugmann2006ancient], and more
recently, a recombinatorially active RAG transposon (ProtoRAG) was found in the lower chordate amphioxus (or lancelet); the most basal extant
chordate and a “living fossil of RAG”  [huang2016discovery].</p>

<p>![False positives in <em>Transib</em> domains do not worsen probability prediction. 
The <em>Transib</em> domains contain critical conserved protein residues. 
(i) False positives were simulated by scoring <em>Transib</em> domain MRF without omitting Boolean conservation weight \(C=0\). 
(ii) Allele frequencies on GnomAD had conservation levels inversely proportional to
simulated false-positive MRF scoring. 
(iii) When testing for all Boolean component \(C&gt;0\) after MRF calculation the effect of false positives remained non-significant, illustrating the non-negative impact of MRF for prediciting the mutation. 
Unpaired t-test, * P = 0.0195, *** P
&lt; 0.0001. 
MRF; mutation rate residue frequency, ns; non-significant.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 4</a></p>

<p>A set of conserved motifs in core <em>RAG1</em> are shared with the <em>Transib</em> transposase, including the critical DDE residue catalytic triad
(residues 603, 711, and 965)  [kapitonov2005rag1]. 
Ten <em>RAG1</em> core motifs are conserved amongst a set of diverse species including human
[kapitonov2005rag1]. 
This evolutionarily conserved region is considered as most important to protein function. 
Therefore, we chose this region to determine if MRF scoring would have a negative impact if mutations were falsely predicted as clinically important. 
To assess the influence of a false positive effect on prediction, the MRF scores for conserved residues in this group were compared to GnomAD allele frequencies.
Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">False_positives_in_Transip_does_not_worsen_probability</a>
(i) 
plots the MRF (without omitting the Boolean component \(C=0\)) for conserved <em>Transib</em> motif residues, non-conserved <em>Transib</em> motif
residues, and non-<em>Transib</em> residues. 
<strong>Figure
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">False_positives_in_Transip_does_not_worsen_probability</a>
(ii)</strong> 
shows the percentage of these which were reported as mutated on GnomAD. 
By accounting for unreported variants by applying \(C&gt;0\), the resulting effect on incorrectly scoring MRF in the conserved <em>Transib</em>
motifs remained neutral.</p>

<h2 id="mrf-predicts-rag-deficiency-amongst-pid-patients-harbouring-rare-variants">MRF predicts RAG deficiency amongst PID patients harbouring rare variants</h2>

<p>We have previously measured the recombination activity of RAG1 and RAG2
disease-causing variants in several patients  [lawless2018prevalence].
We have compiled our own and other functional assay data from
@lee2014systematic and @tirosh2018recombination to produce a panel of
recombination activity measurements for coding variants in both <em>RAG1</em>
and <em>RAG2</em>.</p>

<p>RAG deficiency was measured as the level of recombination potential produced by the protein complex. 
Each method of investigation simulated the efficiency of wild-type or mutant proteins expressed by patients for their ability to produce a diverse repertoire of T-cell receptor (TCR) and B-cell receptor (BCR) and coding for immunoglobulins.
In functional experiments, mutant proteins were assayed for their ability to perform recombination on a substrate which mimics the RSS of TCR and BCR in comparison to wild-type protein complex (as % SEM).</p>

<p>By gathering confirmed RAG deficiency cases, we compiled the MRF scores for 43 damaging <em>RAG1</em> variants in 77 PID cases and 14 damaging <em>RAG2</em> variants in 21 PID cases (MRF scores spanning over 22 categories). 
To test our method against a strong control group, we identified coding variants in patients with PID where RAG deficiency due to coding variants has been ruled out as the cause of disease. 
We obtained <em>RAG1/2</em> variants in 558 PID patients who had their genomes sequenced as part of the NIHR BioResource - Rare Diseases study
[lawless2018prevalence]. 
Filtering initially identified 32 variants in 166 people. 
This set was trimmed to contain only rare variants; 29 variants over 26 MRF scoring categories from 72 cases of
non-RAG-deficient PID. 
The scatterplot in Figure 5 shows that most PID cases had damaging variants with a high MRF score, while PID cases carried benign variants in RAG1/2 with lower MRF scores; i.e. 
an MRF &gt;0.04 was seen for 31 cases of a damaging variant and only 2 cases of a non-damaging variant. 
Linear regression on this control group produced negative or near-zero slopes for <em>RAG1</em> and <em>RAG2</em>, respectively. 
The same analysis for known-damaging mutations in disease cases had a
significant prediction accuracy for <em>RAG1</em>. 
Analysis for <em>RAG2</em> was not significant. 
However, the sample size to date may be too small to significantly measure <em>RAG2</em> MRF scoring although a positive correlation
was inferred in  FIGURE
FIGURE <a href="RAG\_mrf\_linear\_regression">RAG_mrf_linear_regression</a></p>

<p>[altman1995statistics]. 
R source and raw data can be found in supplemental material.</p>

<p>![A linear regression model of RAG1/2 MRF scoring in cases of primary
immune deficiency. 
MRF prediction correlates with clinical presentation.
Damaging variants identified in confirmed RAG deficiency cases.
Non-damaging variants sourced from cases of PID with rare variants but not responsible for disease. 
An MRF &gt;0.04 was seen for 31 cases of a damaging RAG1 variants. 
(Slopes of RAG1: Damaging: 0.0008* (\(\pm\)
0.0004) P&lt;0.05, intercept 5.82e-05 ***, Non-damaging: -0.0007
(\(\pm\) 0.001). 
Slopes of RAG2; Damaging: 0.0023 (\(\pm\) 0.0018), intercept 0.0312 *, Non-damaging 0.0001 (\(\pm\) 0.0008). 
Source data and script in supplemental material).
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 5</a></p>

<h2 id="mrf-supplements-pathogenicity-prediction-tools-for-translational-research">MRF supplements pathogenicity prediction tools for translational research</h2>

<p>CADD scoring  [kircher2014general] is an important bioinformatics tool that exemplifies pathogenicity prediction. 
While CADD is a valuable scoring method, its purpose is not to predict likelihood of variation.
Similarly, MRF scoring is not a measure of pathogenicity. 
MRF scoring may be complemented by tools for scoring variant deleteriousness. 
We compare MRF to the PHRED-scaled CADD scores for all possible SNV positions in <em>RAG1</em> (**Fig.</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 6</a>
) illustrating that pathogenicity prediction cannot account for mutation probability.
Combining both methods allows researchers to identify highly probable mutations before querying predicted pathogenicity.</p>

<p>![<em>RAG1</em> PHRED-scaled CADD score versus GnomAD conservation rate and MRF score. 
Allele frequency conservation rate (<strong>top</strong>) is vastly important for identifying critical structural and functional protein regions. 
The impact of mutation in one of these conserved regions is often estimated using CADD scoring (<strong>middle</strong>). 
CADD score heatmap is aligned by codon and separated into three layers for individual nucleotide positions. 
The MRF score (<strong>bottom</strong>)(visualised using the 75\(^{th}\) percentile with 1% averaging) highlights protein regions which are most likely to present
clinically and may require pre-emptive functional investigation.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 6</a></p>

<p>To further develop this concept, we first annotated variants with MRF likelihood scores and pathogenic prediction PHRED-scaled CADD scores
( FIGURE FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>
), and secondly, performed a manual investigation of the clinical relevance of top candidates
(<strong>Table hgmd_data
). 
We used HGMD as an unbiased source of known RAG deficiency cases in both instances. 
CADD score was very successful at predicting the pathogenicity of a variant, (a high-density cluster of variants with CADD scores &gt;25) as shown in **red</strong> in</p>
<h2 id="figure">Figure</h2>
<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>
(i)<strong>. 
At about the same rate, CADD score also predicted variants as pathogenic that are, to date,
unreported (as **pink</strong> in **Fig.</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>]
(i)<strong>). 
Indeed, those unreported variants may very well be pathogenic.
However, the likelihood of each mutation varies. 
As such, we developed the MRF score to account for that likelihood. 
As expected, the likelihood of mutations occurring that were unreported was low according
to MRF (</strong>Fig.</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>
(ii)<strong>, **pink</strong>), while the mutations which did occur were highly enriched in at high MRF scores
(**Fig.</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>
(ii)<strong>, **red</strong> high-density cluster &gt;0.043). 
Combining mutation prediction (MRF) with pathogenicity prediction (tools like CADD) increases the accuracy of pre-emptively targeting clinically relevant variants. 
**Figure</p>

<p>FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a>
(iii)** shows that while the number of variants presented to date is relatively small, they already account for 36% of the top MRF score candidates.</p>

<p>![<em>RAG1</em> PHRED-scaled CADD score versus MRF score against HGMD data. 
(i)
A high CADD score is a predictor of deleteriousness. 
Both reported (red) and non-reported residues (pink) have a high density of high CADD score.
(ii) MRF scores only show a high-density cluster for high-likelihood variants, reflected by the high MRF score observed for known RAG
deficiency variants. 
The number of pathogenic variants is outweighed by conserved residues; (i-ii) shows density of scores to normalise between
groups. 
AUC overlap difference in CADD score of 21.43% and MRF score of 74.28% (above intersects &gt;22.84 and &gt;0.0409, in <em>(i-ii)</em>
respectively). 
(iii) The number of residues per MRF category shows that disease reported on HGMD accounts for 36% of top MRF candidates. 
AUC;
area under curve, CADD; Combined Annotation Dependent Depletion, HGMD;
Human Gene Mutation Database.<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 7</a></p>

<h1 id="discussion">Discussion</h1>

<p>Determining disease-causing variants for functional analysis typically aims to target conserved gene regions. 
On GnomAD 56% of <em>RAG1</em> (approx. 246,000 alleles) is conserved with no reported variants. 
Functional validation of unknown variants in genes with this level purifying selection is generally infeasible. 
Furthermore, we saw that a vast number of candidates are “predicted pathogenic” by commonly used pathogenicity tools, which may indeed be damaging but unlikely to occur.
To overcome the challenge of manual selection we quantified the likelihood of mutation for each candidate variant.</p>

<p>Targeting clearly defined regions with high MRF scores allows for functional validation studies tailored to the most clinically relevant
protein regions. 
An example of high MRF score clustering occurred in the RAG1 catalytic RNase H (RNH) domain at p.Ser638-Leu658 which is also
considered a conserved <em>Transib</em> motif.</p>

<p>While many hypothetical variants with low MRF scores may be uncovered as functionally damaging, our findings suggest that human genomic studies
will benefit by first targeting variants with the highest probability of occurrence (gene regions with high MRF). 
**Table 
Table:1
 lists the values for calculated MRFs for RAG1 and RAG2.</p>

<p>We have presented a basic application of MRF scoring for RAG deficiency.
The method can be applied genome-wide. 
This can include phenotypically derived weights to target candidate genes or tissue-specific epigenetic features. 
In the state presented here, MRF scores are used for pre-clinical studies. 
A more advanced development may allow for use in single cases. 
During clinical investigations using personalised analysis of patient data, further scoring methods may be applied based on disease features. 
A patient phenotype can contribute a weight based on known genotype correlations separating primary immunodeficiencies or
autoinflammatory diseases  [picard2018international]. 
For example, a patient with autoinflammatory features may require a selection that favors genes associated with proinflammatory disease such as <em>MEFV</em> and
<em>TNFAIP3</em>, whereas a patient with mainly immunodeficiency may have preferential scoring for genes such as <em>BTK</em> and <em>DOCK8</em>. 
In this way, a check-list of most likely candidates can be confirmed or excluded by whole genome or panel sequencing. 
However, validation of these expanded implementations requires a deeper consolidation of functional studies than is currently available.</p>

<p>[Havrilla220814 ]
have recently developed a method with similar possible applications for human health mapping constrained coding regions. 
Their study employed a method that included weighting by sequencing depth.
Similarly, genome-wide scoring may benefit from mutation significance cut-off, which is applied for tools such as CADD, PolyPhen-2, and SIFT
[itan2016mutation]. 
We have not included an adjustment method as our analysis was gene-specific but implementation is advised when calculating genome-wide MRF scores.</p>

<p>The MRF score was developed to identify the top most probable variants that have the potential to cause disease. 
It is not a predictor of pathogenicity. 
However, MRF may contribute to disease prediction; a clinician may ask for the likelihood of RAG deficiency (or any other
Mendelian disease of interest) prior to examination (<em>**</em>).</p>

<p>Predicting the likelihood of discovering novel mutations has implications in genome-wide association studies (GWAS). 
Variants with low minor allele frequencies have a low discovery rate and low probability of disease association  [kido2018minor], an important
consideration for rare diseases such as RAG deficiency. 
An analysis of the NHGRI-EBI catalogue data highlighted diseases whose average risk allele frequency was low  [kido2018minor]. 
Autoimmune diseases had risk allele frequencies considered low at approximately 0.4. 
Without a method to rank most probable novel disease-causing variants, it is unlikely that GWAS will identify very rare disease alleles (with frequencies
&lt;0.001). 
It is conceivable that a number of rare immune diseases are attributable to polygenic rare variants. 
However, evidence for low-frequency polygenic compounding mutations will not be available until large, accessible genetics databases are available, exemplified by
the NIHR BioResource Rare Diseases study  [lawless2018prevalence]. 
An interesting consideration when predicting probabilities of variant frequency, is that of protective mutations. 
Disease risk variants are quelled at low frequency by negative selection, while protective variants may drift at higher allele frequencies  [chan2014excess].</p>

<p>The cost-effectiveness of genomic diagnostic tests is already outperforming traditional, targeted sequencing  [payne2018cost]. 
Even with substantial increases in data sharing capabilities and adoption of clinical genomics, rare diseases due to variants of unknown significance
and low allele frequencies will remain non-actionable until reliable predictive genomics practices are developed. 
Bioinformatics as a whole has made staggering advances in the field of genetics 
[libbrecht2015machine]. 
Challenges that remain unsolved, hindering the benefit of national or global genomics databases, include DNA data storage and random access retrieval  [Organick114553], data privacy management 
[Huang:224980], 
and predictive genomics analysis methods.
Variant filtration in rare disease is based on reference allele frequency, yet the result is not clinically actionable in many cases.
Development of predictive genomics tools may provide a critical role for single patient studies and timely diagnosis 
[casanova2014guidelines].</p>

<h1 id="conclusion">Conclusion</h1>
<p>We provide a list of amino acid residues for RAG1 and RAG2 that have not been reported to date, but are most likely to present clinically as RAG
deficiency.<br />
This method may be applied to other diseases with hopes of improving preparedness for clinical diagnosis.</p>

<p>Supplemental
sec:Supplemental_text</p>

<p>![Data analysis summary map. 
Raw data and analysis scripts are provided in the supplemental. 
Analysis steps and data sources for each procedure described in <em>methods</em>. 
MRF; mutation rate residue frequency, PID;
primary immunodeficiency.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 2</a></p>

<p>![An alternative visualisation of MRF scores for RAG1 and RAG2 proteins.
The data from Table 
Table:1
in column “Average over 1%” is displayed on both the y-axis and colour scale. 
An analysis-friendly long form CSV of the Table 
Table:1
data is also provided in the compressed supplemental R data
“mrf.csv”.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 3</a></p>

<p>![MRF likelihood score versus known functional activity. 
We compiled all variants that we know to have been assayed for protein function to date.
The inverse of functional assay measurements were used, where 0% activity represents 100% loss of activity. 
MRF scores are presented as a percentage of the maximum score per gene (i.e., for RAG1 \(MRF_{max} = 0.043\) (100%) and \(MRF_{min} = 0.0048\) (0%)). 
Top panels show how likely each mutation is predicted to occur in humans.
Bottom panels show the loss of protein activity as a percentage compared to wild-type (% SEM); most mutations tested produced severe loss of protein function, regardless of their mutation likelihood.
Subset of <em>Recombination activity</em> data from Figure</p>

<p>FIGURE [Figure 3](https://link.springer.com/article/10.1007/s10875-019-00670-z}.
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 4</a></p>

<h2 id="main-supplemental-data-table">Main supplemental data table</h2>

<h2 id="clinical-relevance-of-top-candidates">Clinical relevance of top candidates</h2>

<p>The top scoring candidates in RAG1 were assessed for potential clinical relevance (**Table hgmd_data
). 
HGMD was chosen as a reliable, curated source of identifying pathogenic variants. 
45% of RAG1 variants reported on HGMD (23 of 51) were predicted by our model as the most likely candidates seen clinically (the top scoring MRF group of had
66 residues total). 
The remaining variants in the top MRF group, which were not reported by HGMD (43 of 66), were assessed manually for their likelihood as potentially disease causing. 
21 (49%) were highly conserved, not reported on GnomAD, and would be considered probable RAG deficiency on presentation as homozygous or compound heterozygous with a
second damaging variant. 
The remainder had allele frequencies &lt;0.0006, were only found as low frequency heterozygous in the general population, and justify functional validation. 
We expect that none of the top candidate mutations are benign.</p>

<p><strong>Number variants</strong>
Top MRF score candidates total 66%
(i) Of which are reported on HGMD 23%
(ii) Not reported on HGMD to date 43%</p>

<p><strong>Number variants</strong> <strong>Unreported top candidate (%)</strong>%
<strong>GnomAD allele frequency</strong>%
Not found 21 of 43 49% 0%
Very rare 15 of 43 35% 0.00002*
Very rare 7 of 43 16% 0.00006**</p>

<h2 id="supplemental-analysis-tables">Supplemental analysis tables</h2>

<h2 id="protein-structure-application">Protein structure application</h2>

<p>With the availability of a structured protein complex, modelling can be carried out prior to functional assays. 
Residues with the highest MRF for both RAG1 and RAG2 were mapped in  FIGURE
FIGURE Structure
.</p>

<p>![The RAG1 (blue) and RAG2 (grey) protein structure with top candidate MRF scores. 
(i) Protein dimers and (ii=iv) monomers illustrating the three highest category MRF scores for predicted clinically relevant
variants. 
Increasing in score the top three MRF categories (illustrated in  FIGURE
FIGURE <a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">Figure 3</a>
) for each protein are highlighted; yellow, orange, red. 
DNA (green) is bound by the RAG protein complex at recombination signal sequences (PDB:3jbw).
<a href="https://link.springer.com/article/10.1007/s10875-019-00670-z">ESM 5</a></p>

<h2 id="median-cadd-score-per-residue">Median CADD score per residue</h2>

<p>The sourced PHRED-scaled CADD score data consisted of nucleotide level values. 
We were interested in CADD scores averaged per codon.<br />
For every nucleotide position there were three alternative variants to consider,
e.g.</p>

<p>Chrom Pos Ref Alt1 Alt2
Alt3 PHRED1 PHRED2 PHRED3
11 36594855 A C G T 22.3
18.81 22.4</p>

<p>The PHRED-scaled scores are listed here; raw CADD scores are also
included in the original database. 
To produce a working input we used
the median score per codon, that is three scores per nucleotide and
three nucleotides per codon. 
This produced median PHRED-scaled score per
codon / residue, e.g.:</p>

<p>Chrom   Pos PHRED1  PHRED2 PHRED3 <br />
11 36594855 22.3 18.81 22.4
11 36594856 25.3 23.6 24.6
11 36594857 24.8 24.3 24.5</p>

<p>Median PHRED = 24.3\</p>
<h2 id="supplemental-file">Supplemental file</h2>
<p>** <em>‘RAG1.cadd.amino.csv’</em> within the analysis data <em>‘Raw_data_R_analysis_for_figures’</em> contains the median values over
a three-nucleotide window, starting at nucleotide 1 to produce input data with the correct reading frame. 
The “PHRED-scaled” values are used as a normalised and externally comparable unit of analysis, rather than
raw CADD scores. 
The area under the curve was calculated for density plots to quantify the difference between pathogenic and unreported variants with high scores, above the intersects &gt;0.0409 and &gt;22.84 for MRF and CADD, respectively, using score value (\(x\)) versus density (\(y\)) (Fig. 
 (i-ii)) with
\(\int_a^b \! f(x) \, \mathrm{d}x \approx\ \left(b-a\right) \left[\frac{f\left(a\right)\ + f\left(b\right)}{2}\right].\)</p>

<h2 id="genome-wide-and-disease-specific-application">Genome-wide and disease-specific application</h2>

<p>Weighting data can also be applied to the MRF score model to amplify the selectivity. 
The mutation rate can be applied genome wide with a process common in the study of information retrieval; term frequency, inverse document frequency (\(tf-idf\)). 
In this case the “term” and “document” are replaced by amino acid residue \(r\) and gene \(g\) , respectively such that,</p>

<p>[{rf-igf}<em>{r,g} ={rf}</em>{r,g} \times {igf}_r]</p>

<p>We may view each gene as a vector with one component corresponding to each residue mutation in the gene, together with a weight for each component that is given by (1).
Therefore, we can find the overlap score measure with the \({rf-igf}\) weight of each term in \(g\), for a query \(q\);</p>

<p>[\mbox{Score}(q,g)=\sum_{r\in q} \mbox{rf-igf}_{r,g}.]</p>

<p>In respect to MRF scoring, this information retrieval method might be applied as follows; the \({rf-igf}\) weight of a term is the product of
its \(rf\) weight and its \(igf\) weight (\({W}_{r,g}={rf}_{r,g} \times \log \frac{N}{{gf}_{r}}\)) or
(
\({W}_{r,g}=(1 + \log {rf}_{r,g}) \times \log \frac{N}{{gf}_{r}}\)
).
That is, firstly, the number of times a residue mutates in a gene
(
\(rf={rf}_{r,g}\)
) and secondly, the rarity of the mutation genome-wide in \(N\) number of genes (\(igf=N/{gf}_{r}\)). 
Finally, ranking the score of genes for a mutation query \(q\) by;
\(\mbox{Score}(q,g)=\sum_{r\in q\cap g} \mbox{rf-igf}_{r,g}\) The score of the query (Score(\(q,g\))) equals the mutations (terms) that appear in
both the query and the gene (\(r\in q\cap g\)). 
Working out the \(rf-igf\) weight for each of those variants (\({rf.igf}_{r,g}\)) and then summing them (\(\sum\)) to give the score for the specific gene with respect to the query.</p>

<h2 id="bayesian-probability">Bayesian probability</h2>

<p>MRF score may provide a limiting component required for applying Bayesian probability to disease prediction. 
A clinician may ask for the likelihood of RAG deficiency (or any Mendelian disease of interest) for a patient given a set of gene variants \(P(H|E)\) using Bayes’ theorem,
\(P(H|E) = \frac{P(E|H) P(H)}{P(E)}\) where \(P(H)\) is the probability of a patient having RAG deficiency, \(P(E | H)\) is the probability of RAG
deficiency due to a set of variants that have been pre-emptively assayed, and \(P(E)\) is the probability of having a set of gene variants.</p>

<p>\(P(H)\) is known since the rate of RAG deficiency is estimated at an incidence of 1:181,000  [kumanovics2017estimated], SCID at a rate of 1:330,000  [kwan2014newborn], and we also recently show the rate of RAG deficiency in adults with PID  [lawless2018prevalence]. 
Being a recessive disease, \(P(E)\) must account for biallelic variants and is the most difficult value to determine. 
This may be found from population genetics data for (i) the rate of two separate, compound heterozygous variants, (ii) the rate of a homozygous variant or potential consanguinity, or (iii) the rate of de novo variation
[lek2016analysis]. 
\(P(E|H)\) would be identified where all variants are functionally validated. 
This requires a major investment, however the MRF score provides a good approximation.</p>

</p>

  <h2> - </h2>
  <p><h1 id="immunogenomics">Immunogenomics</h1>
<p class="meta">20 Feb 2021</p>

<ul id="markdown-toc">
  <li><a href="#immunogenomics" id="markdown-toc-immunogenomics">Immunogenomics</a></li>
  <li><a href="#the-study-of-rare-immune-disorders" id="markdown-toc-the-study-of-rare-immune-disorders">The study of rare immune disorders.</a></li>
  <li><a href="#genomic-analysis-protocol" id="markdown-toc-genomic-analysis-protocol">Genomic analysis protocol</a></li>
  <li><a href="#immune-disorder-genes" id="markdown-toc-immune-disorder-genes">Immune disorder genes</a></li>
  <li><a href="#primary-immunodeficiency-pid-genes" id="markdown-toc-primary-immunodeficiency-pid-genes">Primary Immunodeficiency (PID) genes</a></li>
  <li><a href="#autoinflammatory-disease-genes" id="markdown-toc-autoinflammatory-disease-genes">Autoinflammatory disease genes</a></li>
</ul>

<h1 id="the-study-of-rare-immune-disorders">The study of rare immune disorders.</h1>
<p><em>Note: in genomic analysis cohort studies a purely statistical approach 
is preferrable to prevent bias in the initial discovery phase.
The following pertains to rare disease or single case studies where 
traditional statistical based assocciations are impossible detect.
A link to new statistical based approaches for rare disease will also be provided shortly.</em></p>

<p>Our goal is the discovery of rare variants in primary immune deficiency 
diseases and autoinflammatory disease. 
There is a long history of advancements in the field of immunology 
by investigating rare diseases. 
In a very broad sense immunology can be approached in two ways;</p>
<ol>
  <li>Categorically define each protein and signalling mechanism in a pathway or</li>
  <li>Identify monogenic or complex genetic causes for immune disorders to identify new or known protein functions.</li>
</ol>

<p>Both of these approaches require <em>a priori</em> knowledge;
i.e. 
“what functional experiment will demonstrate the mechanism of the system 
or protein of interest, 
and how does a genetic variant explain the phenotype demonstrated by a patient”
The second method is <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4203950/">discussed carefully by Casanova and Notarangelo</a>.</p>

<p>Novel discovery of rare mutations in immune genes has some hurdles.</p>
<ul>
  <li>The patients included for sequencing must be selected carefully.
The majority of disease-causing mutations identified will be known variants, 
those that are obviously damaging, etc. and have defined treatments. 
These must be identified quickly to focus on more significant discoveries.</li>
  <li>Novel discoveries require functional experimentation to prove mechanism. 
This can require a major investment for complex studies and therefore ends 
up itself taking investigation approach number 1 mentioned above.</li>
</ul>

<p>There are two options for the approach:</p>
<ul>
  <li>Small single-case studies that require some functional work along with clinical investigation.
    <ul>
      <li>This first option can have very dramatic consequences for understanding 
protein function - when the phenotype is extremely strong it is easier to identify.</li>
    </ul>
  </li>
  <li>Cohort studies on larger groups of affected patients where the phenotype 
is not as profound as rare single cases disorders.
    <ul>
      <li>This second option is more statistically reliable but the effect sizes tend to 
be much smaller. Sample sizes are usually also small for rare diseases.</li>
    </ul>
  </li>
</ul>

<h1 id="genomic-analysis-protocol">Genomic analysis protocol</h1>
<p>The best-practice methods for genomic analysis are discussed in other posts 
including <a href="/topic/bioinformatics">“Genomic analysis for rare disease”</a>.
These methods are generally a routine protocol that is performed for every sample, 
and dependant on the technology used; 
i.e. genome sequencing with
illumina short reads, 10x Genomics long reads, RNAseq, Hi-C, etc.</p>

<p>The disease-specific subtleties still often require a highly tailored analysis
protocol to correctly identify a genetic determinant of disease.
A simple explanation is seen with disease genes where knowledge about 
protein function is used for annotation of candidate disease variants</p>

<h1 id="immune-disorder-genes">Immune disorder genes</h1>
<p>The genes which are most often identified in immune disorders can be separated 
into those of Primary Immunodeficiency (PID) and Autoinflammatory diseases. 
Of course there is overlap as many proteins have multiple functions 
(inhibitory, activation, autoinhibition, etc.). 
The analysis protcols use several stages of best-practice clinical genetic 
annotations accounting for numerous diagnosis criteria including variant consequence, 
gene ontology, inheritance, protein domain function, transcription editing, 
translation modification, etc. 
A reliable example of a disease gene list can be found on the 
<a href="https://panelapp.genomicsengland.co.uk/panels/398/">Genomics England panel app Primary immunodeficiency</a>.</p>

<p><img src="/images/ge_panel_app.png" width="100%" /></p>

<p>The (simplified) list that I try to keep updated and close to hand when 
doing tailored bioinformatic analysis is exemplified in the following table. 
The analysis pipeline uses a curated and reliable sources to provide
a data-rich annotation process for candidate variant detection. 
However, as a repository of whole genome annotation, the information is 
difficult to illustrate here in a small image. 
Instead, the included table is a <em>very</em> simplified example of candidate genes in immunogenomics. 
<em>Note that candidate gene approaches are not recommended, this list is an example 
of known functions that are applied to results after unbiased significance testing.</em></p>

<hr />

<h1 id="primary-immunodeficiency-pid-genes">Primary Immunodeficiency (PID) genes</h1>

<table>
  <thead>
    <tr>
      <th>PID genes</th>
      <th>Disorder</th>
      <th>inheritance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ACP5</td>
      <td>Spondyloenchondrodysplasia with immune dysregulation</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ACTB</td>
      <td>Baraitser-Winter syndrome 1</td>
      <td> </td>
    </tr>
    <tr>
      <td>ADA</td>
      <td>Adenosine deaminase (ADA) deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ADAR</td>
      <td>Aicardi-Goutieres syndrome 6</td>
      <td> </td>
    </tr>
    <tr>
      <td>AICDA</td>
      <td>Immunodeficiency with hyper-IgM, type 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>AIRE</td>
      <td>Autoimmune polyendocrinopathy syndrome , type I, with or without reversible metaphyseal dysplasia (APECED)</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>AK2</td>
      <td>Reticular dysgenesis, AK2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>AP3B1</td>
      <td>Hermansky-Pudlak syndrome 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>APOL1</td>
      <td>Trypanosomiasis, susceptibility to</td>
      <td> </td>
    </tr>
    <tr>
      <td>ARVCF</td>
      <td>DiGeorge syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATM</td>
      <td>Ataxia-telangiectasia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>BCL10</td>
      <td>combined immunodeficiency with B cell, T cell, and fibroblast defects</td>
      <td> </td>
    </tr>
    <tr>
      <td>BLM</td>
      <td>Bloom syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>BLNK</td>
      <td>Agammaglobulinemia 4</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>BTK</td>
      <td>Agammaglobulinemia, X-linked 1 (XLA)</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>C1QA</td>
      <td>C1q deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C1QB</td>
      <td>C1q deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C1QC</td>
      <td>C1q deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C1R</td>
      <td>C1r/C1s deficiency, combined</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C1S</td>
      <td>C1s deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C2</td>
      <td>C2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C3</td>
      <td>C3 deficiency</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>C4A</td>
      <td>C4a deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C4B</td>
      <td>C4B deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C5</td>
      <td>C5 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>C6</td>
      <td>C6 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C7</td>
      <td>C7 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>C8A</td>
      <td>C8 deficiency, type I</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C8B</td>
      <td>C8 deficiency, type II</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C8G</td>
      <td>Complement factor 8 defect</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>C9</td>
      <td>C9 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CA2</td>
      <td>Osteopetrosis, autosomal recessive 3, with renal tubular acidosis</td>
      <td> </td>
    </tr>
    <tr>
      <td>CARD11</td>
      <td>Immunodeficiency 11/ CARD11 deficiency; Persistent polyclonal B-cell lymphocytosis</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CARD14</td>
      <td>Pityriasis rubra pilaris</td>
      <td> </td>
    </tr>
    <tr>
      <td>CARD9</td>
      <td>Candidiasis, familial, 2, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CASP10</td>
      <td>Autoimmune lymphoproliferative syndrome, type II</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CASP8</td>
      <td>Immunodeficiency due to CASP8 deficiency</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CCBE1</td>
      <td>Hennekam lymphangiectasia-lymphedema syndrome 1</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD19</td>
      <td>Immunodeficiency, common variable, 3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD247</td>
      <td>Immunodeficiency 25</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD27</td>
      <td>Lymphoproliferative syndrome 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD28</td>
      <td>combined immunodeficiency T cell</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD3D</td>
      <td>CD3d deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD3E</td>
      <td>CD3e deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD3G</td>
      <td>CD3g deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD4</td>
      <td>OKT4 epitope deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD40</td>
      <td>CD40 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD40LG</td>
      <td>CD40 ligand deficiency</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>CD46</td>
      <td>Hemolytic uremic syndrome, atypical, susceptibility to, 2</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD55</td>
      <td>Hemolysis syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD59</td>
      <td>Hemolytic anemia, CD59-mediated, with or without immune-mediated polyneuropathy</td>
      <td> </td>
    </tr>
    <tr>
      <td>CD79A</td>
      <td>Agammaglobulinemia 3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD79B</td>
      <td>Agammaglobulinemia 6</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD81</td>
      <td>Immunodeficiency, common variable, 6</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CD8A</td>
      <td>CD8 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CDKN2A</td>
      <td>Neutropenia, severe congenital</td>
      <td> </td>
    </tr>
    <tr>
      <td>CEBPE</td>
      <td>Specific granule deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CECR1</td>
      <td>ADA2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CFB</td>
      <td>Complement factor B deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CFD</td>
      <td>Complement factor D deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CFH</td>
      <td>Complement factor H deficiency</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>CFHR1</td>
      <td>Hemolytic uremic syndrome, atypical, susceptibility to</td>
      <td> </td>
    </tr>
    <tr>
      <td>CFHR3</td>
      <td>Hemolytic uremic syndrome, atypical, susceptibility to</td>
      <td> </td>
    </tr>
    <tr>
      <td>CFI</td>
      <td>Complement factor I deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CFP</td>
      <td>Properdin deficiency, X-linked</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>CHD7</td>
      <td>Charge syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CIITA</td>
      <td>Bare lymphocyte syndrome, type II, complementation group A</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CLCN7</td>
      <td>Osteopetrosis, autosomal recessive</td>
      <td> </td>
    </tr>
    <tr>
      <td>CLEC7A</td>
      <td>Candidiasis, familial, 4, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CNBP</td>
      <td>Myotonic dystrophy 2</td>
      <td> </td>
    </tr>
    <tr>
      <td>COLEC11</td>
      <td>3MC syndrome 2</td>
      <td> </td>
    </tr>
    <tr>
      <td>COMT</td>
      <td>DiGeorge syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CORO1A</td>
      <td>Coronin-1A deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CR2</td>
      <td>Immunodeficiency, common variable, 7</td>
      <td> </td>
    </tr>
    <tr>
      <td>CSF2RA</td>
      <td>Surfactant metabolism dysfunction, pulmonary, 4</td>
      <td> </td>
    </tr>
    <tr>
      <td>CSF3R</td>
      <td>Severe congenital neutropenia</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CTLA4</td>
      <td>Common variable immunodeficiency - Autosomal dominant immune dysregulation syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CTPS1</td>
      <td>Immunodeficiency 24</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CTSC</td>
      <td>Papillon-Lefevre syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>CXCR4</td>
      <td>WHIM syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>CYBA</td>
      <td>Chronic granulomatous disease, autosomal, due to deficiency of CYBA</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>CYBB</td>
      <td>Chronic granulomatous disease, X-linked</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>DCLRE1B</td>
      <td>Hoyeraal-Hreidarsson syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>DCLRE1C</td>
      <td>DCLRE1C (Artemis) deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>DKC1</td>
      <td>Dyskeratosis congenita, X-linked</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>DNASE1</td>
      <td>Systemic lupus erythematosus</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>DNMT3B</td>
      <td>Immunodeficiency-centromeric instability-facial anomalies syndrome 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>DOCK8</td>
      <td>Hyper-IgE recurrent infection syndrome, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ELANE</td>
      <td>Neutropenia, severe congenital 1, autosomal dominant</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>ELF4</td>
      <td>undetermined</td>
      <td> </td>
    </tr>
    <tr>
      <td>F12</td>
      <td>Angioedema, Hereditary, Type III</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>FADD</td>
      <td>Infections, recurrent, with encephalopathy, hepatic dysfunction, and cardiovasuclar malformations</td>
      <td> </td>
    </tr>
    <tr>
      <td>FAS</td>
      <td>Autoimmune lymphoproliferative syndrome, type IA (ALPS-FAS)</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>FASLG</td>
      <td>Autoimmune lymphoproliferative syndrome, type IB (ALPS-FASG)</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>FCGR1A</td>
      <td>IgG receptor I, phagocytic, familial deficiency of</td>
      <td> </td>
    </tr>
    <tr>
      <td>FCGR2A</td>
      <td>Pseudomonas aeruginosa, susceptibility to chronic infection by, in cystic fibrosis</td>
      <td> </td>
    </tr>
    <tr>
      <td>FCGR2B</td>
      <td>Malaria, resistance to</td>
      <td> </td>
    </tr>
    <tr>
      <td>FCGR3A</td>
      <td>Immunodeficiency 20</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>FCGR3B</td>
      <td>Neutropenia, alloimmune neonatal</td>
      <td> </td>
    </tr>
    <tr>
      <td>FCGRT</td>
      <td>none reported</td>
      <td> </td>
    </tr>
    <tr>
      <td>FCN3</td>
      <td>Immunodeficiency due to ficolin 3 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>FERMT3</td>
      <td>Leukocyte adhesion deficiency, type III</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>FOXN1</td>
      <td>T-cell immunodeficiency, congenital alopecia, and nail dystrophy</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>FOXP3</td>
      <td>Immunodysregulation, polyendocrinopathy, and enteropathy, X-linked (IPEX)</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>FPR1</td>
      <td>Periodontitis</td>
      <td> </td>
    </tr>
    <tr>
      <td>G6PC3</td>
      <td>Neutropenia, severe congenital 4, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>G6PD</td>
      <td>Chronic Granulomatous Disease</td>
      <td>x-linked</td>
    </tr>
    <tr>
      <td>GATA2</td>
      <td>Immunodeficiency 21</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>GFI1</td>
      <td>Neutropenia, severe congenital 2, autosomal dominant</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>GP1BB</td>
      <td>DiGeorge syndrome/Bernard Soulier syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>HAX1</td>
      <td>Neutropenia, severe congenital 3, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>HIRA</td>
      <td>DiGeorge syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>ICOS</td>
      <td>Immunodeficiency, common variable, 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IFIH1</td>
      <td>Aicardi-Goutieres syndrome 7</td>
      <td> </td>
    </tr>
    <tr>
      <td>IFNGR1</td>
      <td>Immunodeficiency 27A, mycobacteriosis, AR; Immunodeficiency 27B, mycobacteriosis, AD</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>IFNGR2</td>
      <td>Immunodeficiency 28, mycobacteriosis</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IGAD1</td>
      <td>Immunoglobulin A deficiency</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>IGHM</td>
      <td>Agammaglobulinemia 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IGKC</td>
      <td>Kappa light chain deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IGLL1</td>
      <td>Agammaglobulinemia 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IKBKB</td>
      <td>Immunodeficiency 15</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IKBKG</td>
      <td>Ectodermal dysplasia, hypohidrotic, with immune deficiency; Ectodermal, dysplasia, anhidrotic, lymphedema and immunodeficiency; Immunodeficiency 33; Immunodeficiency, isolated; Invasive pneumococcal disease, recurrent isolated, 2</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>IKZF1</td>
      <td>Leukemia, acute lymphoblastic</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL10</td>
      <td>Early onset inflammatory bowel disease</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL10RA</td>
      <td>Inflammatory bowel disease 28, early onset, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL10RB</td>
      <td>Inflammatory bowel disease 25, early onset, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL12B</td>
      <td>Immunodeficiency 29, mycobacteriosis</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL12RB1</td>
      <td>Immunodeficiency 30</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL12RB2</td>
      <td>Mendelian susceptibility to mycobacterial disease</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL17F</td>
      <td>Candidiasis, familial, 6, autosomal dominant</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>IL17RA</td>
      <td>Candidiasis, familial, 5, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL17RC</td>
      <td>Chronic Mucocutaneous Candidiasis (CMC)</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL18</td>
      <td>Defects with susceptibility to mycobacterial infection (MSMD)</td>
      <td> </td>
    </tr>
    <tr>
      <td>IL1RN</td>
      <td>Interleukin 1 receptor antagonist deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>IL21</td>
      <td>Immunodeficiency, common variable, 11</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL21R</td>
      <td>Immunodeficiency, primary, autosomal recessive, IL21R-related</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL23A</td>
      <td>Defects with susceptibility to mycobacterial infection (MSMD)</td>
      <td> </td>
    </tr>
    <tr>
      <td>IL2RA</td>
      <td>Interleukin-2 receptor, alpha chain, deficiency of</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL2RG</td>
      <td>SCID (x-linked)</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>IL36RN</td>
      <td>Psoriasis, generalized pustular</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IL7R</td>
      <td>IL7Ra deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IRAK4</td>
      <td>IRAK4 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>IRF3</td>
      <td>susceptibility to herpes simplex encephalitis</td>
      <td> </td>
    </tr>
    <tr>
      <td>IRF7</td>
      <td>IRF7 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>IRF8</td>
      <td>Immunodeficiency 32A, mycobacteriosis, autosomal dominant</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>ISG15</td>
      <td>susceptibility to mycobacterial infection, enhanced IFN-?/? immunity</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ITCH</td>
      <td>Autoimmune disease, multisystem, with facial dysmorphism</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ITGB2</td>
      <td>Leukocyte adhesion deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ITK</td>
      <td>Lymphoproliferative syndrome 1 (LPFS1)</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>JAGN1</td>
      <td>severe congeital neutropenia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>JAK3</td>
      <td>JAK3 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>KRAS</td>
      <td>Ras associated lymphoproliferative disease (RALD)</td>
      <td>AR and somatic</td>
    </tr>
    <tr>
      <td>LAMTOR2</td>
      <td>Immunodeficiency due to defect in MAPBP-interacting protein</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LCK</td>
      <td>Immunodeficiency 22/ LCK deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LIG1</td>
      <td>DNA ligase I deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LIG4</td>
      <td>LIG4 syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LPIN2</td>
      <td>Majeed syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LRBA</td>
      <td>Immunodeficiency, common variable, 8, with autoimmunity</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>LRRC8A</td>
      <td>Agammaglobulinemia 5</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>LYST</td>
      <td>Chediak-Higashi syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MAGT1</td>
      <td>Immunodeficiency, X-linked, with magnesium defect, Epstein-Barr virus infection and neoplasia (XMEN)</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>MALT1</td>
      <td>Immunodeficiency 12/ MALT1 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MASP1</td>
      <td>3MC syndrome 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MASP2</td>
      <td>MASP2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MBL2</td>
      <td>Chronic infections, due to MBL deficiency</td>
      <td>AR/het</td>
    </tr>
    <tr>
      <td>MCM4</td>
      <td>Natural killer cell and glucocorticoid deficiency with DNA repair defect</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MEFV</td>
      <td>Familial Mediterranean fever, AR; Familial Mediterranean fever, AD</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MKL1</td>
      <td>immunodeficiency, phagocyte function</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MLPH</td>
      <td>Griscelli syndrome, type 3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MPO</td>
      <td>Myeloperoxidase deficiency</td>
      <td>AR/het</td>
    </tr>
    <tr>
      <td>MRE11A</td>
      <td>Ataxia-telangiectasia-like disorder</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MS4A1</td>
      <td>Immunodeficiency, common variable, 5</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MTHFD1</td>
      <td>Severe combined immunodeficiency, defect in folate metabolism</td>
      <td> </td>
    </tr>
    <tr>
      <td>MVK</td>
      <td>Hyper-IgD syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MYD88</td>
      <td>Pyogenic bacterial infections, recurrent, due to MYD88 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>MYO5A</td>
      <td>Griscelli syndrome, type 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NBN</td>
      <td>Nijmegen breakage syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NCF1</td>
      <td>Chronic granulomatous disease due to deficiency of NCF-1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NCF2</td>
      <td>Chronic granulomatous disease due to deficiency of NCF-2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NCF4</td>
      <td>Granulomatous disease, chronic, autosomal recessive, cytochrome b-positive, type III</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NFKB1</td>
      <td>Common variable immunodeficiency (CVID)</td>
      <td> </td>
    </tr>
    <tr>
      <td>NFKB2</td>
      <td>Immunodeficiency, common variable, 10</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>NFKBIA</td>
      <td>Ectodermal dysplasia, anhidrotic, with T-cell immunodeficiency</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>NHEJ1</td>
      <td>Severe combined immunodeficiency with microcephaly, growth retardation, and sensitivity to ionizing radiation</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NHP2</td>
      <td>Dyskeratosis congenita, autosomal recessive 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NLRP12</td>
      <td>Familial cold autoinflammatory syndrome 2</td>
      <td>het</td>
    </tr>
    <tr>
      <td>NLRP3</td>
      <td>CINCA syndrome; Muckle-Wells syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NOD2</td>
      <td>Blau syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>NOP10</td>
      <td>Dyskeratosis congenita, autosomal recessive 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>NRAS</td>
      <td>Autoimmune lymphoproliferative syndrome type IV</td>
      <td> </td>
    </tr>
    <tr>
      <td>ORAI1</td>
      <td>Immunodeficiency 9</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>OSTM1</td>
      <td>Osteopetrosis, autosomal recessive 5</td>
      <td> </td>
    </tr>
    <tr>
      <td>PGM3</td>
      <td>Immunodeficiency 23</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PIK3CD</td>
      <td>Immunodeficiency 14</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>PIK3R1</td>
      <td>Agammaglobulinemia 7, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PLCG2</td>
      <td>Autoinflammation, antibody deficiency, and immune dysregulation syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>PMS2</td>
      <td>Mismatch repair cancer syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>PNP</td>
      <td>Immunodeficiency due to purine nucleoside phosphorylase deficiency; Purine nucleoside phosphorylase (PNP) deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>POLE</td>
      <td>FILS syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PRF1</td>
      <td>Hemophagocytic lymphohistiocytosis, familial, 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PRKCD</td>
      <td>Immunodeficiency, common variable, 9; ALPS3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PRKDC</td>
      <td>DNA Pkcs deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PSMB8</td>
      <td>Autoinflammation, lipodystrophy, and dermatosis syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>PSTPIP1</td>
      <td>Pyogenic sterile arthritis, pyoderma gangrenosum, and acne</td>
      <td> </td>
    </tr>
    <tr>
      <td>PTPRC</td>
      <td>CD45 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RAB27A</td>
      <td>Griscelli syndrome, type 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RAC2</td>
      <td>Neutrophil immunodeficiency syndrome</td>
      <td> </td>
    </tr>
    <tr>
      <td>RAG1</td>
      <td>RAG1 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RAG2</td>
      <td>RAG2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RBCK1</td>
      <td>Polyglucosan body myopathy, early-onset, with or without immunodeficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RECQL4</td>
      <td>Rothmund-Thomson syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RFX5</td>
      <td>Bare lymphocyte syndrome, type II, complementation group C</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RFXANK</td>
      <td>MHC class II deficiency, complementation group B</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RFXAP</td>
      <td>Bare lymphocyte syndrome, type II, complementation group D</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RHOH</td>
      <td>RhoH deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RMRP</td>
      <td>Cartilage-hair hypoplasia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RNASEH2A</td>
      <td>Aicardi-Goutieres syndrome 4</td>
      <td> </td>
    </tr>
    <tr>
      <td>RNASEH2B</td>
      <td>Aicardi-Goutieres syndrome 2</td>
      <td> </td>
    </tr>
    <tr>
      <td>RNASEH2C</td>
      <td>Aicardi-Goutieres syndrome 3</td>
      <td> </td>
    </tr>
    <tr>
      <td>RNF168</td>
      <td>RIDDLE syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RORC</td>
      <td>Susceptibility to candidasis &amp; Mycobacterial infection</td>
      <td> </td>
    </tr>
    <tr>
      <td>RPSA</td>
      <td>Isolated congential asplenia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>RTEL1</td>
      <td>Hoyeraal-Hreidarsson syndrome/ Dyskeratosis congenita, autosomal dominant 4; Dyskeratosis congenita, autosomal recessive 5</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>SAMHD1</td>
      <td>Aicardi-Goutieres syndrome 5</td>
      <td> </td>
    </tr>
    <tr>
      <td>SBDS</td>
      <td>Shwachman-Bodian-Diamond syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>SEMA3E</td>
      <td>Charge syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>SERPING1</td>
      <td>Angioedema, hereditary, types I and II</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>SH2D1A</td>
      <td>Lymphoproliferative syndrome, X-linked, 1 (XLP1)</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>SH3BP2</td>
      <td>Cherubism</td>
      <td> </td>
    </tr>
    <tr>
      <td>SLC11A1</td>
      <td>Mycobacterium tuberculosis, susceptibility to infection by</td>
      <td> </td>
    </tr>
    <tr>
      <td>SLC29A3</td>
      <td>Histiocytosis-lymphadenopathy plus syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>SLC35C1</td>
      <td>Congenital disorder of glycosylation, type IIc</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>SLC37A4</td>
      <td>Glycogen storage disease Ib</td>
      <td> </td>
    </tr>
    <tr>
      <td>SLC46A1</td>
      <td>Folate malabsorption, hereditary</td>
      <td> </td>
    </tr>
    <tr>
      <td>SMARCAL1</td>
      <td>Schimke immunoosseous dysplasia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>SP110</td>
      <td>Hepatic venoocclusive disease with immunodeficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>SPINK5</td>
      <td>Netherton syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STAT1</td>
      <td>Immunodeficiency 31A, mycobacteriosis, autosomal dominant; Candidiasis, familial, 7</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>STAT2</td>
      <td>STAT2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STAT3</td>
      <td>Hyper-IgE recurrent infection syndrome; Autoimmune disease, multisystem, infantile-onset</td>
      <td>AR/AD</td>
    </tr>
    <tr>
      <td>STAT5A</td>
      <td>Growth hormone insensitivity with immunodeficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>STAT5B</td>
      <td>Growth hormone insensitivity with immunodeficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STIM1</td>
      <td>Immunodeficiency 10</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STK4</td>
      <td>T-cell immunodeficiency, recurrent infections, autoimmunity, and cardiac malformations</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STX11</td>
      <td>Hemophagocytic lymphohistiocytosis, familial, 4</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>STXBP2</td>
      <td>Hemophagocytic lymphohistiocytosis, familial, 5</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TAP1</td>
      <td>Bare lymphocyte syndrome, type I</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TAP2</td>
      <td>Bare lymphocyte syndrome, type I, due to TAP2 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TAPBP</td>
      <td>Bare lymphocyte syndrome, type I</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TAZ</td>
      <td>Barth syndrome</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>TBK1</td>
      <td>Herpes simplex encephalitis, susceptibility to,</td>
      <td> </td>
    </tr>
    <tr>
      <td>TBX1</td>
      <td>Di George syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>TCF3</td>
      <td>E47 TF deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>TCIRG1</td>
      <td>Osteopetrosis, autosomal recessive 1</td>
      <td> </td>
    </tr>
    <tr>
      <td>TCN2</td>
      <td>Transcobalamin-2 precursor</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TERC</td>
      <td>Dyskeratosis congenita, autosomal dominant 1</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>TERT</td>
      <td>Dyskeratosis congenita, autosomal dominant 2, Dyskeratosis congenita, autosomal recessive 4</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>THBD</td>
      <td>Hemolytic uremic syndrome, atypical, susceptibility to, 6</td>
      <td> </td>
    </tr>
    <tr>
      <td>TICAM1</td>
      <td>Encephalopathy, acute, infection-induced, susceptibility to, 6</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>TINF2</td>
      <td>Dyskeratosis congenita, autosomal dominant 3</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>TIRAP</td>
      <td>Pneumococcal disease, invasive, protection against</td>
      <td> </td>
    </tr>
    <tr>
      <td>TLR3</td>
      <td>Herpes simplex encephalitis, susceptibility to, 2</td>
      <td> </td>
    </tr>
    <tr>
      <td>TMC6</td>
      <td>Epidermodysplasia verruciformis</td>
      <td> </td>
    </tr>
    <tr>
      <td>TMC8</td>
      <td>Epidermodysplasia verruciformis</td>
      <td> </td>
    </tr>
    <tr>
      <td>TMEM173</td>
      <td>STING-associated vasculopathy, infantile-onset</td>
      <td> </td>
    </tr>
    <tr>
      <td>TNFRSF11A</td>
      <td>Osteolysis, familial expansile ; Osteopetrosis, autosomal recessive 7</td>
      <td> </td>
    </tr>
    <tr>
      <td>TNFRSF13B</td>
      <td>Immunodeficiency, common variable, 2</td>
      <td>AR and AD</td>
    </tr>
    <tr>
      <td>TNFRSF13C</td>
      <td>Immunodeficiency, common variable, 4</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TNFRSF1A</td>
      <td>Periodic fever, familial</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>TNFRSF4</td>
      <td>Immunodeficiency 16/ OX40 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TNFSF12</td>
      <td>Immunodeficiency, common variable with lack of anti-pneumococcal antibody</td>
      <td> </td>
    </tr>
    <tr>
      <td>TPP2</td>
      <td>TPP2 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>TRAC</td>
      <td>Immunodeficiency 7, TCR-alpha/beta deficient</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TRAF3</td>
      <td>Herpes simplex encephalitis, susceptibility to, 3</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>TRAF3IP2</td>
      <td>Candidiasis, familial, 8</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TREX1</td>
      <td>Aicardi-Goutieres syndrome 1, dominant and recessive</td>
      <td> </td>
    </tr>
    <tr>
      <td>TRNT1</td>
      <td>congenital sideroblastic anemia with immunodeficiency, fevers, and developmental delay (SIFD)</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TTC37</td>
      <td>Trichohepatoenteric syndrome 1</td>
      <td> </td>
    </tr>
    <tr>
      <td>TTC7A</td>
      <td>Multiple intestinal atresia and severe combined immunodeficiency (MINAT)</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>TYK2</td>
      <td>Immunodeficiency 35</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>UFD1L</td>
      <td>DiGeorge syndrome</td>
      <td>AD</td>
    </tr>
    <tr>
      <td>UNC119</td>
      <td>Immunodeficiency 13/ UNC119 deficiency</td>
      <td> </td>
    </tr>
    <tr>
      <td>UNC13D</td>
      <td>Hemophagocytic lymphohistiocytosis, familial, 3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>UNC93B1</td>
      <td>Herpes simplex encephalitis, susceptibility to, 1</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>UNG</td>
      <td>Immunodeficiency with hyper IgM, type 5</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>USB1</td>
      <td>Poikiloderma with neutropenia</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>VPS13B</td>
      <td>Cohen syndrome</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>VPS45</td>
      <td>Neutropenia, severe congenital, 5, autosomal recessive</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>WAS</td>
      <td>Wiskott-Aldrich syndrome</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>WIPF1</td>
      <td>Wiskott-Aldrich syndrome 2</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>WRAP53</td>
      <td>Dyskeratosis congenita, autosomal recessive 3</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>XIAP</td>
      <td>Lymphoproliferative syndrome, X-linked, 2 (XLP2)</td>
      <td>X-Linked</td>
    </tr>
    <tr>
      <td>XRCC4</td>
      <td>none reported</td>
      <td> </td>
    </tr>
    <tr>
      <td>ZAP70</td>
      <td>Zap-70 deficiency</td>
      <td>AR</td>
    </tr>
    <tr>
      <td>ZBTB24</td>
      <td>Immunodeficiency-centromeric instability-facial anomalies syndrome-2</td>
      <td>AR</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="autoinflammatory-disease-genes">Autoinflammatory disease genes</h1>

<table>
  <thead>
    <tr>
      <th>Autoinflammatory genes</th>
      <th>Disorder</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ACP5</td>
      <td>Spondyloenchondrodysplasi a with immune dysregulation</td>
    </tr>
    <tr>
      <td>ACP5</td>
      <td>Spondyloenchondrodysplasia with immune dysregulation</td>
    </tr>
    <tr>
      <td>ADAR</td>
      <td>Dyschromatosis symmetrica hereditaria, Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>Aicardi</td>
      <td> Goutieres syndromes (AGS) TREX1 (AGS1), RNASEH2B (AGS2), RNASEH2C (AGS3), RNASEH2A (AGS4), SAMHD1 (AGS5), ADAR (AGS6), and IFIH1 (AGS7)</td>
    </tr>
    <tr>
      <td>AP1S3</td>
      <td>Pustular psoriasis (PSORS15)</td>
    </tr>
    <tr>
      <td>CARD14</td>
      <td>Familial Psoriasis (PSORS2)</td>
    </tr>
    <tr>
      <td>CECR1</td>
      <td>Deficiency of Adenosine Deaminase 2 (DADA2) aka Fever with Early Onset Stroke (FEOS)</td>
    </tr>
    <tr>
      <td>DDX58</td>
      <td>Singleton-Merten syndrome</td>
    </tr>
    <tr>
      <td>ELANE</td>
      <td>Cyclic Neutropenia</td>
    </tr>
    <tr>
      <td>FOXP3</td>
      <td>IPEX syndrome</td>
    </tr>
    <tr>
      <td>GCH1</td>
      <td>Dopa responsive dystonia, Tetrahydrobiopterin deficiency</td>
    </tr>
    <tr>
      <td>Gene</td>
      <td>Associated phenotypes</td>
    </tr>
    <tr>
      <td>HAX1</td>
      <td>Severe Congenital Neutropenia</td>
    </tr>
    <tr>
      <td>HTR1A</td>
      <td>Periodic fever, menstrual cycle</td>
    </tr>
    <tr>
      <td>IFIH1</td>
      <td>Singleton-Merten syndrome</td>
    </tr>
    <tr>
      <td>IL10</td>
      <td>Early Onset Inflammatory Bowel Disease (EoIBD25, EOIBD28, and EOIBD with Il10 deficiency)</td>
    </tr>
    <tr>
      <td>IL10RA</td>
      <td>Early Onset Inflammatory Bowel Disease (EoIBD25, EOIBD28, and EOIBD with Il10 deficiency)</td>
    </tr>
    <tr>
      <td>IL10RB</td>
      <td>Early Onset Inflammatory Bowel Disease (EoIBD25, EOIBD28, and EOIBD with Il10 deficiency)</td>
    </tr>
    <tr>
      <td>IL1RN</td>
      <td>Deficiency of Interleukin 1ß (IL1ß) Receptor Antagonist (DIRA) . Osteomyelitis, sterile multifocal, with periostitis and pustulosis</td>
    </tr>
    <tr>
      <td>IL36RN</td>
      <td>Pustular psoriasis, generalized  - Deficiency of Interleukin 36Receptor Antagonist (DITRA)</td>
    </tr>
    <tr>
      <td>ISG15</td>
      <td>Immunodeficiency 38 with basal ganglia calcification (IMD38)</td>
    </tr>
    <tr>
      <td>LPIN2</td>
      <td>Majeed syndrome</td>
    </tr>
    <tr>
      <td>MEFV</td>
      <td>Familial Mediterranean Fever (FMF)</td>
    </tr>
    <tr>
      <td>MVK</td>
      <td>Mevalonate Kinase Deficiencies (MKD): Hyper-IgD syndrome (HIDS) and MA</td>
    </tr>
    <tr>
      <td>NEFL</td>
      <td>Charcot Marie</td>
    </tr>
    <tr>
      <td>NLRC4</td>
      <td>NLRC4 Macrophage Activation</td>
    </tr>
    <tr>
      <td>NLRP12</td>
      <td>Familial Cold Autoinflammatory Syndrome 2 (FCAS2)</td>
    </tr>
    <tr>
      <td>NLRP3</td>
      <td>Cryopyrin Associated Periodic Syndromes (CAPS): MWS, FCAS, CINCA and NOMID</td>
    </tr>
    <tr>
      <td>NLRP7</td>
      <td>Recurrent hydatidiform mole</td>
    </tr>
    <tr>
      <td>NOD2</td>
      <td>Blau syndrome, Sarcoidosis, early-onset</td>
    </tr>
    <tr>
      <td>ORAI1</td>
      <td>Myopathy, tubular aggregate, 2 (TAM2), Immunodeficiency 9 (IMD9)</td>
    </tr>
    <tr>
      <td>PLCG2</td>
      <td>PLCG2associated Antibody Deficiency &amp; Immune Dysregulation (PLAID) or Familial Atypical Cold Urticaria (FACU) or FCAS3 and APLAID</td>
    </tr>
    <tr>
      <td>PSMB8</td>
      <td>Chronic Atypical Neutrophilic Dermatosis with Lipodystrophy and Elevated Temperature Syndrome (CANDLE), Nakajo-Nishimura syndrome, Chronic atypical neutrophilic dermatosis with lipodystrophy and elevated temperature syndrome, Autoinflammation, lipodystrophy, and dermatosis syndrome, Joint contractures, muscular atrophy, microcytic anemia, and panniculitis-induced lipodystrophy syndrome</td>
    </tr>
    <tr>
      <td>PSTPIP1</td>
      <td>Pyogenic Sterile Arthritis, Pyoderma Gangrenosum, and Acne Syndrome (PAPA)</td>
    </tr>
    <tr>
      <td>RBCK1</td>
      <td>Polyglucosan body myopathy 1 with or without immunodeficiency (PGBM1)</td>
    </tr>
    <tr>
      <td>RNASEH2A</td>
      <td>Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>RNASEH2B</td>
      <td>Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>RNASEH2C</td>
      <td>Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>SAMHD1</td>
      <td>Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>SCO2</td>
      <td>Myopia 6 (MYP6), Cardioencephalomyopathy, fatal infantile, due to cytochrome c oxidase deficiency 1 (CEMCOX1)</td>
    </tr>
    <tr>
      <td>SH3BP2</td>
      <td>Cherubism</td>
    </tr>
    <tr>
      <td>SLC19A3</td>
      <td>biotin thiamine responsive basal ganglia disease</td>
    </tr>
    <tr>
      <td>SLC25A19</td>
      <td>Amish lethal microcephaly</td>
    </tr>
    <tr>
      <td>SLC29A3</td>
      <td>SLC29A3 Spectrum Disorder, aka H. syndrome; Pigmented Hypertrichosis with Insulin dependent Diabetes Mellitus (IDDM)</td>
    </tr>
    <tr>
      <td>TLR3</td>
      <td>Human immunodeficiency virus type 1, susceptibility to</td>
    </tr>
    <tr>
      <td>TMEM173</td>
      <td>STING-associated vasculopathy, infantile-onsent (SAVI)</td>
    </tr>
    <tr>
      <td>TNFAIP3</td>
      <td>Haploinsufficiency of A20 (HA20), aka Behcet</td>
    </tr>
    <tr>
      <td>TNFRSF11A</td>
      <td>TNFRSF11A associated hereditary fever disease (TRAPS11)</td>
    </tr>
    <tr>
      <td>TNFRSF1A</td>
      <td>Periodic fever (Tumor Necrosis Factor (TNF) Associated Periodic Syndrome (TRAPS))</td>
    </tr>
    <tr>
      <td>TPK1</td>
      <td>Thiamine metabolism dysfunction syndrome 5, episodic encephalopathy type (THMD5)</td>
    </tr>
    <tr>
      <td>TRAF3</td>
      <td>Herpes simplex encephalitis, susceptibility to</td>
    </tr>
    <tr>
      <td>TREX1</td>
      <td>Vasculopathy, retinal, with cerebral leukodystrophy, Chilblain lupus, Aicardi-Goutières syndrome</td>
    </tr>
    <tr>
      <td>TRNT1</td>
      <td>Sideroblastic anemia with B cell immunodeficiency, periodic fevers, and developmental delay (SIFD)</td>
    </tr>
  </tbody>
</table>
</p>

  <h2> - </h2>
  <p><h1 id="conferences">Conferences</h1>

<p>Public conferences attending or participating in:</p>

<p><a href="https://2020.eshg.org">The European Society of Human Genetics (ESHG)</a> - 2020 Berlin</p>

<p><img src="/images/meetings/berlin.jpg" width="80%" /></p>

<p><a href="https://www.epfl.ch/schools/sv/ghi/">Functional genomics seminar series EPFL</a> - 2020 Lausanne</p>

<p><img src="/images/meetings/epfl.jpg" width="80%" /></p>

<p><a href="https://2019.eshg.org">The European Society of Human Genetics (ESHG)</a> - 2019 Sweden</p>

<p><img src="/images/meetings/gothe.jpg" width="80%" /></p>

<p><a href="https://broadinstitute.swoogo.com/ga4gh6thplenary">Global Alliance for Genomics and Health (GA4GH)</a> - 2018 Basel, Switzerland</p>

<p><img src="/images/meetings/basel.jpg" width="80%" /></p>

<p><a href="https://www.genopri.org">International Workshop on Genome Privacy and Security (GenoPri’18)</a> - 2018, Basel, Switzerland</p>

<p><img src="/images/meetings/genopri.jpg" width="80%" /></p>

<p><a href="http://transmartfoundation.org/europe-fall-meeting-2018/">i2b2 tranSMART Academic Users Group Conference</a> 2018 - Geneva, Switzerland</p>

<p><img src="/images/meetings/geneva.jpg" width="80%" /></p>

<p><a href="http://www.cambridgebioresource.group.cam.ac.uk/volunteers/rare">NIHR BioResource Rare Diseases</a> 2018 - Trinity College, Cambridge, UK</p>

<p><img src="/images/meetings/cambridge.jpg" width="80%" /></p>

<p><a href="http://esid2017.kenes.com">European Society for Immunodeficiencies ESID</a> 2017 - Edinburgh, UK
Autoimmunity &amp; Inflammation in PID</p>

<p><img src="/images/meetings/edinburgh.jpg" width="80%" /></p>

<p><a href="https://medhealth.leeds.ac.uk/events/event/86/combined_northern_and_yorkshire_annual_rheumatology_meeting_national_railway_museum_york">Annual Northern &amp; Yorkshire Rheumatology</a> 2017 - National Railway Museum, York, UK</p>

<p><img src="/images/meetings/york.jpg" width="80%" /></p>

<p><a href="https://coursesandconferences.wellcomegenomecampus.org/Conferences.wt">Immunogenomics of Disease 2017</a> - Wellcome Genome Campus, Cambridge, UK</p>

<p><img src="/images/meetings/embl.jpg" width="80%" /></p>

<p><a href="http://www.cambridgebioresource.group.cam.ac.uk/volunteers/rare">NIHR BioResource Rare Diseases</a> 2016 - Downing College, Cambridge, UK</p>

<p><img src="/images/meetings/downing.jpg" width="80%" /></p>

<p><a href="http://esid.org">European Society for Immunodeficiencies ESID</a> 2016 - Barcelona, Spain</p>

<p><img src="/images/meetings/barcelona.jpg" width="80%" /></p>

<p><a href="http://www.immunology-conference.de">Annual meeting German Society for Immunology</a> 2014 - Bonn, Germany</p>

<p><img src="/images/meetings/bonn.jpg" width="80%" /></p>
</p>

  <h2> - </h2>
  <p><h1 id="genomic-analysis-for-rare-disease">Genomic analysis for rare disease</h1>

<ul id="markdown-toc">
  <li><a href="#genomic-analysis-for-rare-disease" id="markdown-toc-genomic-analysis-for-rare-disease">Genomic analysis for rare disease</a></li>
  <li><a href="#abbreviations" id="markdown-toc-abbreviations">Abbreviations</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#exome-sequencing" id="markdown-toc-exome-sequencing">Exome sequencing</a>    <ul>
      <li><a href="#sample-preparation" id="markdown-toc-sample-preparation">Sample preparation</a></li>
      <li><a href="#capture-library" id="markdown-toc-capture-library">Capture library</a></li>
      <li><a href="#sequencing" id="markdown-toc-sequencing">Sequencing</a></li>
      <li><a href="#ultra-deep-sequencing" id="markdown-toc-ultra-deep-sequencing">Ultra-deep sequencing</a></li>
    </ul>
  </li>
  <li><a href="#genomic-analysis" id="markdown-toc-genomic-analysis">Genomic analysis</a></li>
  <li><a href="#sec:routine_analysis" id="markdown-toc-sec:routine_analysis">Routine analysis</a>    <ul>
      <li><a href="#analysis-workflow-structure" id="markdown-toc-analysis-workflow-structure">Analysis workflow structure.</a></li>
      <li><a href="#analysis-storage-structure" id="markdown-toc-analysis-storage-structure">Analysis storage structure</a></li>
      <li><a href="#sequence-alignment-to-reference-genome" id="markdown-toc-sequence-alignment-to-reference-genome">Sequence alignment to reference genome</a></li>
      <li><a href="#read-adaptor-trimming" id="markdown-toc-read-adaptor-trimming">Read adaptor trimming</a></li>
      <li><a href="#read-sorting" id="markdown-toc-read-sorting">Read sorting</a></li>
      <li><a href="#gatk-best-practices" id="markdown-toc-gatk-best-practices">GATK best practices.</a></li>
      <li><a href="#read-deduplication" id="markdown-toc-read-deduplication">Read deduplication</a></li>
      <li><a href="#subsec:text_realtar" id="markdown-toc-subsec:text_realtar">Read realignment and targets</a></li>
      <li><a href="#subsec:text_bsqr" id="markdown-toc-subsec:text_bsqr">Base quality score recalibration</a></li>
      <li><a href="#subsec:text_hc" id="markdown-toc-subsec:text_hc">Haplotype calling</a></li>
      <li><a href="#subsec:text_joint" id="markdown-toc-subsec:text_joint">Cohort joint genotyping</a></li>
    </ul>
  </li>
  <li><a href="#tailored-analysis" id="markdown-toc-tailored-analysis">Tailored analysis</a></li>
  <li><a href="#integrating-databases" id="markdown-toc-integrating-databases">Integrating databases</a>    <ul>
      <li><a href="#subsec:gnomad" id="markdown-toc-subsec:gnomad">Population genetics</a></li>
      <li><a href="#phenotype-genotype-and-function" id="markdown-toc-phenotype-genotype-and-function">Phenotype, genotype, and function</a></li>
    </ul>
  </li>
  <li><a href="#sec:cohort_network_analysis" id="markdown-toc-sec:cohort_network_analysis">Rare disease cohort network analysis</a>    <ul>
      <li><a href="#introduction-1" id="markdown-toc-introduction-1">Introduction</a></li>
      <li><a href="#exome-analysis" id="markdown-toc-exome-analysis">Exome analysis</a></li>
      <li><a href="#cluster-list-preparation" id="markdown-toc-cluster-list-preparation">Cluster list preparation</a></li>
      <li><a href="#sec:net_construction" id="markdown-toc-sec:net_construction">Network construction</a></li>
      <li><a href="#sec:random_sample" id="markdown-toc-sec:random_sample">Random sampling</a></li>
      <li><a href="#expanding-damaged-gene-mcl-clusters" id="markdown-toc-expanding-damaged-gene-mcl-clusters">Expanding damaged gene MCL clusters</a></li>
      <li><a href="#sec:burden_rank" id="markdown-toc-sec:burden_rank">Burden rank</a></li>
      <li><a href="#sec:number_test" id="markdown-toc-sec:number_test">Determining the number of tests <em>m</em></a></li>
      <li><a href="#significance-testing" id="markdown-toc-significance-testing">Significance testing</a></li>
      <li><a href="#sec:enrichment_test" id="markdown-toc-sec:enrichment_test">Enrichment testing</a></li>
    </ul>
  </li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#command-line-example-code" id="markdown-toc-command-line-example-code">Command line example code</a></li>
</ul>

<h1 id="abbreviations">Abbreviations</h1>
<p>BWA (Burrows-Wheeler transformation aligner), FDR (False discovery
rate), GO (Gene Ontology), GrCh38 (Genome Reference Consortium Human
Build 38), GVCF (Genomic Variant Call Format), KEGG (Kyoto Encyclopedia
of Genes and Genomes), LoF (loss-of-function), NCBI (National Center for
Biotechnology), Pfam (Protein families database), PPI (Protein-protein
interaction), VCF (variant call format).</p>

<h1 id="introduction">Introduction</h1>

<p>This chapter contains theory and examples for the investigation of rare
disease by exome sequencing used throughout this thesis. Each section is
generally self-contained with a brief introduction. A specific section
is devoted to a novel method of rare disease cohort network analysis in
Sec [sec:cohort_network_analysis]. A separate introduction is also
included to begin that section in context. This procedure was developed
to provide a statistical method for the detection of damaged protein
pathways that drive disease. The method is based on measuring variant
enrichment and clustering by protein-protein interactions (PPI).</p>

<p>A detailed overall analysis plan is illustrated in . A accompanying data
storage plan is also provided in the same section that directly maps to
the analysis plan. A rough overview “infographic” of a next generation
sequencing study is shown <strong>Figure [fig:NGS]</strong>. The general
requirements, personnel responsibilities, and cost-breakdown is shown.</p>

<p><strong>Whole exome sequencing experiment design.</strong> The general
requirements, personnel responsibilities, and cost-breakdown is shown
for a small NGS study of approximately ten participants. If library
preparation and sequencing is performed at a dedicated facility then
scaling up to very large cohorts (&gt;1,000) potential only differs in
one critical feature; implementing the bioinformatic methods used in
this chapter also requires a critical expertise in high-performance
computing. No methods have been included to demonstrate job scheduling
and parallelisation across large computer
clusters.
<strong>FigureLabel</strong>
NGS</p>

<p><img src="/images/bioinfo/NGS.png" width="80%" /></p>

<p><em>image_caption</em></p>

<h1 id="exome-sequencing">Exome sequencing</h1>
<h2 id="sample-preparation">Sample preparation</h2>

<p>For genomic investigations, a patient generally donates a small blood
sample (2-6mL) along with signed consent to use their biological
material and data in genetic and functional research. Patient DNA is
purified from peripheral blood monocytes. In most cases, the
purification is done using a commercial kit such as that from Qiagen
(51104 QIAamp DNA Blood Mini Kit). This protocol takes about 1 hour to
purify 1-10 patient samples. Sometimes patient DNA is provided from an
external source such as a local hospital where blood samples are
processed routinely by dedicated staff. In this case, the purification
method may be unknown so extra care should be taken when checking
suitability for sequencing experiments. Consideration should be given to
the possibility of sample mix up, that contamination could have
occurred, etc.</p>

<p>High-throughput sequencing experiments benefit from consistency during
sequencing library preparation. While there are several commercial
options available, the protocol used in this study was the SureSelect XT
target enrichment system for Illumina paired-end multiplexed sequencing
library. A detailed protocol is available from the manufacturer.
However, the process can be summarised in four main steps. After DNA
quality has been checked, the basic protocol consists of:<br />
(1) DNA fragmentation into 100-300 base pair strands, either (i) by
using an enzyme that digests the DNA or (ii) by breaking by sonication;
the DNA is suspended inside a small glass tube containing a glass rod
which is vibrated by sonic waves inside a water bath.<br />
(2) Another round of quality control checks to ensure that the DNA is
fragmented into the correct size range.<br />
(3) These fragments are bound by probes that specifically recognise the
coding sequences which collectively make up the exome.<br />
(4) The DNA that has been selectively purified is then tagged by adding
a tail of nucleotides in specific sequences that label each of the
individual samples with a unique code. When the sequencing step is
performed later, all of the samples will get mixed together. The unique
tag allows us to later re-identify which sequences belong to every
person included in the study.</p>

<p>While it is important that library preparation is performed accurately,
the individual steps could be replaced by alternative methods. The
crucial component is an end product of targeted DNA fragments that have
been tagged appropriately to allow the sequencing chemistry on the
chosen system and that fragment lengths are in the correct range. A more
detailed summary of the procedure is outlined;</p>

<p><strong>Preparation of sample</strong></p>
<ol>
  <li>DNA is sheared, the most frequently used methods are by enzymatic
digestion and sonication.</li>
  <li>Fragmented DNA is purified using AMPure XP beads.</li>
  <li>Quality assessment.</li>
  <li>End repair.</li>
  <li>Purify using AMPure XP beads.</li>
  <li>Adenylation at 3’ end.</li>
  <li>Purify using AMPure XP beads.</li>
  <li>Paired-end adaptor ligation.</li>
  <li>Purify using AMPure XP beads.</li>
  <li>Amplification.</li>
  <li>Purify using AMPure XP beads.</li>
  <li>Assess quality.</li>
</ol>

<p><strong>Hybridization and capture</strong></p>
<ol>
  <li>Hybridize capture library probes to DNA.</li>
  <li>Capture the hybridized DNA using streptavidin-coated beads.
Note: at this step, custom gene target libraries can be used.</li>
</ol>

<p><strong>Indexing and multiplexing</strong></p>
<ol>
  <li>Captured libraries are amplified with indexing primers.</li>
  <li>Purify using AMPure XP beads.</li>
  <li>Assess quality and concentration of indexed library DNA.</li>
  <li>Pool samples at equal concentrations.</li>
</ol>

<h2 id="capture-library">Capture library</h2>
<p>For targeted sequencing experiments, the most important step in library
preparation is the hybridization of capture library probes. Libraries of
probes that are complementary to exome coding sequences can be ordered
from a number of commercial suppliers. For a whole exome, this consists
of hundreds of thousands of short RNA oligonucleotide strands bound to
biotin. When the capture library hybridization mix is added to the DNA,
most of the short probes bind to their complementary DNA sequences over
12-16 hours. To separate these selected fragments from the remaining
bulk of unwanted DNA, streptavidin-coated magnetic beads are added. The
streptavidin attaches to the biotin and therefore the DNA-bound probe
can be pulled out using a strong magnet. Unbound DNA can then be washed
away. Experiments in this study have been performed using Agilent
capture library SureSelect Human All Exon V4-6, although several other
options are available.</p>

<p>Targeted panels can also be used to focus on smaller sets of genes. For
example, in some immunological conditions a panel of  50 genes might be
targeted rather than a library for all known genes (exome). Cancer
genetics screening services sometimes use a small panel of 40-100 genes.
These small panels cut down on cost and focus only on genes where
interpretation of variants would be possible. For the same price as
whole exome, less capture library is needed and more samples can be
sequenced.</p>

<p>As of 2018, all-exon capture library costs roughly £16,000 for enough
reagent to prepare 96 DNA samples. This accounts for about 50% of the
cost of the total library preparation materials. In total, the library
preparation costs about £200 per sample. Once the samples have been
prepared it cost about another £200 to sequence; approximately £400
total.</p>

<h2 id="sequencing">Sequencing</h2>
<p>The sequencing carried out in this study was performed on Illumina
platforms. These include the MiSeq for very small runs of a select set
of genes, HiSeq 3000, 4000, and HiSeq X for whole exome or whole genome
sequencing. The prepared libraries of patient DNA are pooled to contain
5-12 samples per pool. Since each sample has a unique identifier tag, it
is OK to pool them together and later separate out all the individual
data per person. On the HiSeq 3000 approximately 12 samples can be run
per lane with acceptable coverage. This provides about 30-50X reads per
nucleotide, sufficiently deep to confidently identify true germline
mutations. There are 8 lanes per sequencing flow cell. Therefore, a
single sequencing run can contain anything from 50-100 patient samples.
Depending on the sequencing platform the run can take up to 5 days to
complete.</p>

<h2 id="ultra-deep-sequencing">Ultra-deep sequencing</h2>
<p>Mendelian disorders can be successfully explained using exome and whole
genome sequencing. Both the interpretability and cost per sample are
improved in cases where a gene sequencing panel can be used. Some
conditions, particularly autoinflammatory disorders, can arise from low
frequency somatic variants that are capable of driving disease through
potent gain-of-function mechanisms. It is worth noting that a
“gain-of-function” can also be considered as a succinct description for
systems where a loss of inhibitory activity occurs that directly results
in increased signaling cascade activity that would otherwise rest in an
inactive state; a homeostatic pathway. E.g. loss of an autoinhibitory
feature for a single protein or loss of an inhibitory mechanism that is
responsible for direct repression in the absence of stimulation or
specific agonist. In such cases, a low frequency de novo variant will
escape detection with typical sequencing methods, but ultra-deep
sequencing offers a method for detection. This option uses a high
concentration of capture reagent to prepare a highly enriched library
and sequence at high-density on a flow cell to produce ultra-deep
sequencing reads (e.g. &gt;5,000x versus 50x, as typical for whole exome
sequencing). In this case, PCR-free preparation is ideal for somatic
variant detection, naturally.</p>

<h1 id="genomic-analysis">Genomic analysis</h1>
<p>Like any data science, bioinformatics is a discipline of data
manipulation. The majority of jobs could be accomplished simply with a
method for sequence alignment and data mining using grep, sed, and awk.
However, the development of specialised genomics-based tools allows us
to standardise procedures and expand the avenues of exploration. One of
the greatest single, collaborative, sources of genomics analysis tool is
the Genome Analysis Toolkit developed by The Broad Institute.</p>

<p>While not every tool was used in this study, a synopsis of analysis
options is worthwhile; an overview of GATK provides a good example of
the current trends. The software provided by GATK includes methods for
data manipulation. As of writing, there are 291 packages in this
software suite. 
These are divided into major topics of genomic data
handling that include:</p>

<ul>
  <li>
    <p>Tools dedicated to managing read data in SAM, BAM or CRAM formats.</p>
  </li>
  <li>
    <p>Diagnostics and QC to collect sequencing quality and comparative
metrics;</p>
  </li>
  <li>
    <p>Interval manipulation to process genomic intervals in various formats.
For example, converting a BED file to a Picard interval list;</p>
  </li>
  <li>
    <p>Metagenomics. For example, microbial community composition and pathogen
detection using read filtering, microbe reference alignment, and
abundance scoring;</p>
  </li>
  <li>
    <p>Tools that manipulate FASTA format references. For example, creating a
custom capture library relies on oligonucleotide baits for hybrid
selection reactions, or making BWA-MEM index image files, or a sequence
dictionary to accompany a reference.</p>
  </li>
  <li>
    <p>Variant calling and genotyping for variants such as SNVs, SNPs, and
Indels. For example, haplotype calling of germline SNPs and indels by
performing a local re-assembly of haplotypes, such HaplotypeCaller gVCF
files are generally merged into batches of single gVCFs to manage
databases, and joint genotyping is a common approach on these databases.
Some tools also specialise in calling somatic SNVs and indels also by
local assembly of haplotypes.</p>
  </li>
  <li>
    <p>Variant manipulation software for handling variant call format (VCF)
data.</p>
  </li>
  <li>
    <p>Base calling. This is software that is used at the early stage of
sequence data interpretation to process the raw data, i.e. base calls,
and other attributes such as the adapters used.</p>
  </li>
  <li>
    <p>Read filters which can be applied by the engine to select reads for
analysis.</p>
  </li>
  <li>
    <p>Variant annotations is a software that can be used during critical
stages of analysis by other tools, i.e. HaplotypeCaller, Mutect2,
VariantAnnotator and GenotypeGVCFs.</p>
  </li>
  <li>
    <p>Copy number variant discovery using read coverage to detect copy number
variants.</p>
  </li>
  <li>
    <p>Coverage analysis using allele depths as the metric.</p>
  </li>
  <li>
    <p>Structural variant discovery.</p>
  </li>
  <li>
    <p>Variant evaluation and refinement. For example, variant calls can be
further detailed using annotations which are not offered by the base
software.</p>
  </li>
  <li>
    <p>Variant filtering that allows annotation of the FILTER column in a
dataset.</p>
  </li>
</ul>

<h1 id="sec:routine_analysis">Routine analysis</h1>
<p>Routine analysis can be summarised in order as raw sequence data quality
control, read trimming, reference alignment, subsequently followed by
the GATK best practices for SNV and indels. 
Figure “analysis flow”
illustrates the basic analysis workflow
structure. Proceeding top to bottom, the procedure making up the left
side of fig. [fig:analysis_flow] contains the procedures for routine
analysis. Each rectangle box labels a program function, key input and
output data are shown with light slanted boxes. The most important data
retention steps are indicated with a “data store” symbol. The right-hand
side of the same figure illustrates the second phase of analysis used in
this study; tailored analysis, or cohort-specific analysis. The
annotation, filtering, and segregation of data here depends on the
project. A generally useful strategy will output gene candidate data
based on inheritance type to produce individual datasets for each (i)
functional heterozygous variants (including de novo, somatic, known
dominant genes, etc.), (ii) homozygous only variants, and (iii)
potential compound heterozygous variants, and (iv) a master version of
all variants that have completed the filtering pipeline. These datasets
are generally small (&lt;1MB per individual) and combined into all
individuals per sequence run or cohort.</p>

<p>Genome and exome analysis is an iterative process. Although there are
routine steps, different methods will be used depending on each
experiment. Data storage is a major factor in genetic analysis. Not only
are the initial files large in size, many intermediate files are
produced and may themselves be important to retain for a certain period.
Key output files are shown by light slanted boxes. As shown in <strong>Figure
[fig:analysis_flow_storage]</strong>, storage structure is divided between
long-term and short-term storage. A /work/ directory is used for
long-term storage and is backed up routinely. Short-term storage is used
for intermediate files which are held in /scratch/ directories and not
backed up. File sizes are represented by colour, dark orange indicating
large and light yellow indicating small sizes.</p>

<h2 id="analysis-workflow-structure">Analysis workflow structure.</h2>
<p>Tools used are shown in square boxes.
Reference data used secondary to inputs are shown as light boxes with
curved sides. Key output files are shown by light slanted boxes. Storage
structure is divided between long-term and short-term storage. The same
figure key is applied to Fig.
[fig:analysis_flow_storage].</p>

<p><strong>FigureLabel</strong>
analysis_flow</p>

<p><img src="/images/bioinfo/analysis_flow.pdf" width="80%" /></p>

<p><em>image_caption</em></p>

<h2 id="analysis-storage-structure">Analysis storage structure</h2>
<p>Storage structure is divided
between long-term and short-term storage. A /work/ directory is used for
long-term storage and is backed up routinely. Short-term storage is used
for intermediate files which are held in /scratch/ directories and not
backed up. File sizes are represented by colour, dark orange indicating
large and light yellow indicating small sizes. Figure key is shown in
Fig.
[fig:analysis_flow].
<strong>FigureLabel</strong>
analysis_flow_storage
<img src="/images/bioinfo/analysis_flow_storage.pdf" width="40%" /></p>

<h2 id="sequence-alignment-to-reference-genome">Sequence alignment to reference genome</h2>
<p>The analysis methods are normally run as a pipeline workflow. The basic
methods do not have major changes in theory, although there are usually
several methods or software options available for each step. Once a
working pipeline is established, most of a researcher’s time can be
spent on the tailored analysis at the end of the pipeline, which
requires more specialised steps. Each individuals’ exome sequence data
contains approximately 3-8 GB of raw data. This is output as  150bp raw
unmapped sequence fragments that must be aligned to the reference human
genome. The raw sequence data is normally collected into a fasta format
file called a “fastq” file (pronounced “fast” “q”).</p>

<p>An important consideration for sequence analysis is the reference genome
used for comparison. The coordinates for individual nucleotides vary
between reference versions. For example, aligning with one reference
version will produce a file that contains chromosome, position, and
variants specific to that genome reference. Annotation will be required
to interpret results, but if databases based on coordinates from
different reference versions are used during this step the results will
be incorrect.</p>

<p>The current human genome reference is a version of Genome Reference
Consortium Human Build 38 patch release 13 (GrCh38)
(https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.39).
Because of the timing when next generation sequencing became popular,
many researchers tend to use genome build GrCh37 in their analysis<br />
(https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.13/)
However, it is preferable to use the more recent GrCh38. A lot of the
best standardised methods that are used in the field were developed
while genome build GrCh37 was the most recent version. Thousands of
database samples will be in storage which have been aligned with this
reference. Bioinformatic analysis is extremely more powerful when
comparing many samples than when looking at one sample individually.
Therefore, many people still tend to align their data to GrCh37 so that
they can use their reference databases without going back and realigning
all of their old samples again to GrCh38.
The most popular method for aligning short read data to the reference
human genome is “BWA-MEM” (a Burrows-Wheeler transformation aligner)
[@Li2009Fast]. BWA-MEM was used to align sequencing data in this study
to GrCh37 [subsec:text_alignment] (for an example usage see page ).</p>

<h2 id="read-adaptor-trimming">Read adaptor trimming</h2>
<p>Since Illumina-based sequencing technology relies on duplexed samples,
identification sequence tags were added to all sequence libraries.
During analysis these tag sequences can affect alignment and are
therefore removed from each read [subsec:text_cut]. The command line
usage is shown on page .</p>

<h2 id="read-sorting">Read sorting</h2>
<p>To allow downstream analyses to run efficiently, the sequences within
files are rearranged based on their coordinate position after alignment
with the reference genome. This process is carried out using SamTools
[subsec:text_sort] This software is part of the The Broad
Institute-maintained Genome Analysis Toolkit (GATK). Their standardised
pipeline is illustrated here in [fig:gatk]; a protocol familiar to
most bioinformaticians. And example of usage can be seen on page .</p>

<h2 id="gatk-best-practices">GATK best practices.</h2>
<p>Illustration from software.broadinstitute.org. Per-sample variant calling is used to
produce a file in GVCF format. GVCFs are consolidated from multiple
samples into a GenomicsDB datastore. Joint genotyping is carried out,
and finally, variant quality score recalibration filtering is used to
produce the final multi-sample callset with the desired balance of
precision and sensitivity. Further downstream analysis, including
annotation is not shown.
<strong>FigureLabel</strong>
gatk
<img src="/images/bioinfo/gatk.png" width="40%" /></p>

<h2 id="read-deduplication">Read deduplication</h2>
<p>Sequence library preparation may contain a PCR amplification step.
Individual fragments of genomic DNA will be amplified. If a read
contains a variant then, after amplification, we only want to count this
occurrence once so that we do not interpret an inflated allele depth.
Therefore, identical reads are marked as duplicates. Alternative
overlapping reads that also contain the same variant will result in
detection of a true germline variant. When no other overlapping reads
contain the variant then the allele depth will remain low and be
filtered out later by a frequency threshold, or flagged as potentially
somatic. [subsec:text_dedup] For command line usage examples of this
step, see page .</p>

<h2 id="subsec:text_realtar">Read realignment and targets</h2>
<p>After sequence alignment, regions of misalignments will inevitably
exist. To deal with this feature, a local realignment process is used
such that the number of mismatching bases is minimized across all the
reads. This main source of misalignments corrected in this step are due
insertions and deletions. Current versions of the GATK suite no longer
require this step as it is integrated into the downstream process of
haplotype assembly (via HaplotypeCaller or MuTect2). However, the step
is included here since it is a well known legacy feature and is a very
useful concept to understand for new users. As usage example is provided
on page .</p>

<h2 id="subsec:text_bsqr">Base quality score recalibration</h2>
<p>The alignment steps are difficult and computationally intensive. There
are methods to double check the alignment and see if more appropriate
corrections can be made. Once the quality control is all done, we are
left with a Bam file format which is ready for variant analysis. Most of
the bioinformatic community agrees on some best practices using the
tools maintained by the Broad Institute. The GATK is widely used for the
QC and variant analysis of genomic data.</p>

<p>Joint analysis of multiple samples increases the accuracy of our
methods. Not only are the algorithms checking for consistencies in the
data, but sometimes the sequence library preparation induces errors in
the sequences produced. For example, sometimes a particular nucleotide
position can be sequenced incorrectly. In isolation we would expect that
this patient has a true mutation in the gene, but when we compare the
whole cohort we see that it is just a common sequencing artefact.</p>

<p>When we look at the number of variants compared to the reference genome
there can be hundreds of thousands. The vast majority of these can be
ignored by [1] comparing the in-house database of false positive,
[2] comparing the unrelated samples sequenced on the same run to
remove library preparation errors, [3] compare to databases of common
polymorphisms.</p>

<p>In genome wide association studies, researchers are generally looking at
the mild effects of common polymorphisms which occur in the general
population and may associate with a particular phenotype. In rare
disease analysis we are focusing on the very rare variants that have a
strong effect to produce a severe phenotype. Therefore, another step for
pruning out the data is to compare to large cohorts of “healthy”
populations to leave only the very rare variants in our dataset. The
command line arguments can be see on page .</p>

<h2 id="subsec:text_hc">Haplotype calling</h2>
<p>The final output, illustrated in the GATK best practices figure above,
is stored in a Genomic Variant Call Format (GVCF). The GVCF file type
that now presents our data has one row for each nucleotide along the
genome. The row contains the DNA position, the nucleotide (either
wild-type (ref) or mutation (alt)) and lots of quality and metrics
information. We analyse variants against curated databases of known
mutations. We also analyse again separately for indels, since a shift in
the sequence position due to a indel could affect the alignment
accuracy. For an example see page .</p>

<h2 id="subsec:text_joint">Cohort joint genotyping</h2>
<p>We can merge 10-100s of samples together by combining the files to
simplify how we handle the data. Tracking hundreds of files is
exponentially more difficult than tracking 1. The GVCF contains a row of
data for every single nucleotide. We can condense the information by
converting to a VCF which instead only keeps information for every
variant but not every wild type nucleotide (since wild type is healthy
and of no interest to us). The GATK documentation provides a great
explanation of the shared features and differences between gVCF and VCF
files.</p>

<p>As our dataset becomes smaller we can double check to focus on just the
most likely disease-causing mutations. Often times, a research group or
clinical research team will collect genetic material from patients who
they would like to diagnose genetically, or even collect a great
database of patients with a shared phenotype. There are many of
facilities that will sequence the samples commercially. When one orders
exome or whole genome sequencing commercially, most facilities will also
provide data analysis.</p>

<p>The output of their analysis is usually this VCF file (mostly contain
the chromosome, nucleotide position, and a selection of quality control
information). This file is usually the end-point of routine analysis.
However, it does not really put one in a position for a genetic
diagnosis. Very good services will also provide lists of top candidate
genetic determinants along with information on each of the genes and
possible mechanisms of pathogenicity (although the number of companies
doing high-level tailored analysis is small but growing). There are
usually more hurdles in determining candidate variants of unknown
significance. An example of the command line arguments used can be found
on page .</p>

<h1 id="tailored-analysis">Tailored analysis</h1>
<p>Routine analysis typically takes up to a week, although it is usually
performed on a standardised pipeline that can run automatically on a
high-performance computing platform. A large part of custom filtering
begins when the routine analysis steps have been completed; downstream
analysis is adapted for each particular challenge. The discussion in
explains some foundational steps towards a fully automatic system that
relies only on some input features, such as clinical information. While
many software packages exist that claim to output tailored analysis,
these tend to either only tackle a specific niche or require lots of
curated auxiliary input data.</p>

<p>The output of non-routine analysis (outlined in this chapter) sometimes
takes only five minutes to interpret a cause of disease. In other cases,
data that has been sequenced years previously has not yet relented an
explanation for phenotypes that almost certainly should be explained by
coding variants present within the sequence data. For example, for a
dozen patients who share a similar and severe phenotype, it is often
likely that the same gene or related genes could cause their disease.
Unrelated patients with a rare dominant disease are not to all carry the
same disease-causing variant; they may have different variants in shared
gene, or variants among different genes which all contribute to a shared
pathway that would result in the same end-point phenotype.</p>

<p><strong>Shared pathways in candidate genes.</strong> Output of a STRING database
query for known and predicted protein-protein interactions. These
interactions include physical and functional associations. (STRING is an
SIB-run service of the ELIXIR core data open resources for publicly
funded research).</p>

<p><strong>FigureLabel</strong>
string_normal_image
<img src="/images/bioinfo/string_normal_image.png" width="40%" /></p>

<p><em>image_caption</em></p>

<p>For example, in <strong>Figure [fig:string_normal_image]</strong> above we see
that from a group of unrelated people, all of the candidate genes
carrying functional variants are joined by their shared functional
interactions. For an autoinflammatory phenotype, genes like <em>NLRP3</em>,
<em>NOD2</em>, <em>TNFAIP3</em>, <em>MyD88</em>, <em>IKBKB</em>, <em>FASLG</em>, or <em>TMEM173</em> might all
have different functions but damaging mutations in any of these could
result in phenotypes that, on the surface, appear related.</p>

<p>Another circumstance might be seen in a small cohort of patients with a
shared autoinflammatory phenotype. For example, the gene <em>NLRP7</em> has
relatively few publications examining it’s role in autoinflammatory
disease. One would not consider this a strong candidate gene if faced
with a variant of unknown significance in this gene from a single
patient. However, three or four very rare or novel mutations in
unrelated patients should be given consideration as producing an
autoinflammatory disease. Single case, or small cohorts lack the power
to measure significant associations. Therefore in the situation proposed
here, manual interpretation is required (biased as it may be).</p>

<p><em>NLRP7</em> variants not reported as producing disease, like <em>MEFV</em>, or
<em>TNFAIP3</em>. However, we must consider that genes plausibly responsible
for causing disease in a dominant manner and that are highly conserved
are generally under purifying selective pressure. Damaging mutations may
be not be compatible with viability and therefore we never see cases of
disease. Variants which are damaging to protein function but that do not
completely destroy all of the normal structure may produce a phenotype
that is pathogenic but viable with modern medical intervention.</p>

<p>In the example of NLRP7, the protein is known to Inhibit
CASP1/caspase-1-dependent IL-1$\beta$ secretion. The functional domains
of this protein are shared in other pro-inflammatory processes. Pyrin,
NACHT, and LRR, domain variants are all studied for autoinflammatory
diseases. The related gene, <em>NLRP3</em>, is probably the most widely
recognised gene where damaging variants in these functional domains
produce severe immune disorders. In cases where we have protein
structures, we can also model the effect.</p>

<p>In our example, <em>NLRP7</em> variants have been reported as the genetic
determinant of a condition that causes early neonatal death and ectopic
pregnancy. Many of the reported variants are stop mutations that will
either produce a truncated protein or prevent expression of the allele
altogether through nonsense-mediated decay. It is difficult predict the
mechanism of disease in cases like this where the two outcomes have
opposing paths. That is to say, a truncated protein may have an active
functional domain which can no longer be inhibited since the C-terminal
domains are missing, while haploinsufficiency would mean that cells
cannot perform their normal function for the pathway since 50% of the
protein is depleted (in heterozygous cases). Haploinsufficiency can
result in a disease that phenotypically resembles a gain-of-function
when the responsible protein normally acts as an inhibitor for an
inflammatory pathway [@Lawless2018acase]. This is not expected with
<em>NLRP7</em> and therefore heterozygous loss-of-function does not explain
disease.</p>

<p>For a candidate gene like this, we have some plausible evidence but
cannot really progress any further without new functional studies. The
first step involved confirmatory Sanger sequencing for all patients
identified through exome sequencing. Next, any close relatives that are
available might be also sequenced for the same variants. If the
mutations are disease-causing then other carriers would also be expected
to have some shared phenotype features. The possibilities in functional
experiments vary widely and are highly dependent on the candidate genes.
The procedure outlined in this hypothetical example is generally
applicable in for the majority of single-case studies and illustrates
the importance of tailored analysis. The initial findings of genomic
analysis may produce more follow up questions, including whether other
probable gene candidates can be ruled out, for which the patient carries
only the “normal” reference alleles (e.g. <em>CFTR</em> screening for cystic
fibrosis/lung disease).</p>

<h1 id="integrating-databases">Integrating databases</h1>
<h2 id="subsec:gnomad">Population genetics</h2>
<p>GnomAD (version r2.0.2) [@lek2016analysis] was used in these studies as
the best source of population genetics data. The reference genome is
GRCh37. Offline local database mirrors were used in most cases. Input
sets used GnomAD variant allele frequencies and reference sequences
processed as VCF and CSV files. outlines a specific data transformation
using the gnomAD database, but in general, gnomAD was used as a
filtering threshold for determining the expected population frequency of
each variant. A strict threshold for rare variants could be set to
ignore and candidate variants that are more frequent than 0.001.
However, in most cases a more lenient level is used and any remaining
benign or common variants are removed by “technical control” (filter on
cohort to remove common variants between individuals that do not share a
phenotype). A more modest cut-off threshold allows us to sometimes
identify variant that are present in the general population, which are
responsible for a recessive disease with no predictable heterozygous
loss-of-function intolerance.</p>

<p>Other sources of population genetics data comes from resources such as
CliVar and dbSNP, which as they grow in size become an annotated and
curated for of population data. These resources allow us to calculate
the expected frequencies for disease-causing variants. However, since
these are manually curated database and predominantly European based,
they are inherently biased and not reliable for statistical
applications.</p>

<h2 id="phenotype-genotype-and-function">Phenotype, genotype, and function</h2>
<p>Population genetics database gnomAD has been individually addressed in
section [subsec:gnomad], as this is the most important type of
annotation and filtering criteria for genetic determinants of rare
disease. Additionally, in these studies many phenotype and genotype
databases have been used for annotation and interpretation.
Specifically, the most frequently used data came from MGI Phenotype,
MorbidMap, VOC MammalianPhenotype, Gencode symbol, UniProtKB, Enterez
ID, ENSGene ID, GO ID, Description, OMIM, BIOGRID interactions, HGMD
human phenotype, ClinVar, and dbSNP. In most cases, every candidate
variant was annotated with the main information per gene from a local
database containing the information from each of the listed resources.</p>

<p>These are the “basic” information databases that we used to annotate
variants. In a cohort study, data mining can find correlations and was
therefore included for posterity as it does not significantly increase
the data storage. Even if an obvious cause of disease was found we may
later return to the data to find other cofactors or genetic modifiers.
Or for example, in a single case study, a variant of unknown
significance may have no statistical basis to be selected or ignored. We
use this information to decide if that mutation is worth consideration:
Is it in a protein domain of known function? Are there other cases
reported with the same phenotype? What is the gene function, ontology,
etc.?</p>

<p>We have also used some gene lists that are specific to disease,
druggability, etc. A major contributor for collecting these gene lists
has been the Mac Arthur et al. [@macarthurgit]. These gene lists can be
used is special cases. For example, a study looking at (1) dominant
pathogenic mutations, and (2) in known immune genes might filter to
included only those known observables. We could decide to only study
SNPs in FDA-approved drug targets.</p>

<table>
  <tbody>
    <tr>
      <td>[</td>
      <td>p[4.5cm]{}</td>
      <td>c</td>
      <td>p[6cm]{}</td>
      <td>]{}</td>
    </tr>
  </tbody>
</table>

<p><br />
&amp; [<strong>Gene Count</strong>]{} &amp; [<strong>Reference</strong>]{}<br />
&amp; [19,194]{} &amp; [HUGO 2018 [@HUGO2018]]{}<br />
[FDA-approved drug targets]{} &amp; [385]{} &amp; [Wishart 2018
[@Wishart2018]]{}<br />
[Drug targets]{} &amp; [201]{} &amp; [Nelson 2012 [@Nelson2012]]{}<br />
[Autosomal dominant genes]{} &amp; [307]{} &amp; [Blekhman 2008
[@Blekhman2008]]{}<br />
[Autosomal dominant genes]{} &amp; [631]{} &amp; [Berg 2013 [@Berg2013]]{}<br />
[Autosomal recessive genes]{} &amp; [527]{} &amp; [Blekhman 2008
[@Blekhman2008]]{}<br />
[Autosomal recessive genes]{} &amp; [1073]{} &amp; [Berg 2013 [@Berg2013]]{}<br />
[X-linked genes]{} &amp; [66]{} &amp; [Blekhman 2008 [@Blekhman2008]]{}<br />
[X-linked recessive genes]{} &amp; [102]{} &amp; [Berg 2013 [@Berg2013]]{}<br />
[X-linked dominant genes]{} &amp; [34]{} &amp; [Berg 2013 [@Berg2013]]{}<br />
[X-linked ClinVar genes]{} &amp; [61]{} &amp; [Landrum 2014 [@Landrum2014]]{}<br />
[All dominant genes]{} &amp; [709]{} &amp; [Blekhman 2008, Berg 2013
[@Blekhman2008; @Berg2013]]{}<br />
[All recessive genes]{} &amp; [1183]{} &amp; [Blekhman 2008, Berg 2013
[@Blekhman2008; @Berg2013]]{}<br />
[Homozygous LoF tolerant]{} &amp; [330]{} &amp; [Lek 2016 [@lek2016analysis]]{}<br />
[Essential in culture]{} &amp; [283]{} &amp; [Hart 2014 [@Hart2014]]{}<br />
[Essential in culture*]{} &amp; [683]{} &amp; [Hart 2017 [@Hart2017]]{}<br />
[Non-essential in culture*]{} &amp; [913]{} &amp; [Hart 2017 [@Hart2017]]{}<br />
[Essential in mice]{} &amp; [2,454]{} &amp; [Blake ‘11, Georgi ‘13, Liu ‘13
[@Blake2010; @Georgi2013; @Liu2013]]{}<br />
[Genes nearest to GWAS peaks]{} &amp; [6,336]{} &amp; [MacArthur 2017
[@MacArthur2017]]{}<br />
[DNA Repair Genes]{} &amp; [178]{} &amp; [Wood 2005 [@Wood2005]]{}<br />
[DNA Repair Genes]{} &amp; [151]{} &amp; [Kang 2012 [@Kang2012]]{}<br />
[ClinGen haploinsufficient genes]{} &amp; [294]{} &amp; [Rehm 2015
[@Rehm2015]]{}<br />
[Olfactory receptors]{} &amp; [371]{} &amp; [Mainland 2015 [@Mainland2015]]{}<br />
[Reported in ClinVar]{} &amp; [3078]{} &amp; [Landrum 2014 [@Landrum2014]]{}<br />
[Kinases]{} &amp; [347]{} &amp; [UniProt 2016 [@UniProt2016]]{}<br />
[GPCRs from guide to pharmacology]{} &amp; [391]{} &amp; [Alexander 2017,
Harding 2018. [@Alexander2017; @Harding2017]]{}<br />
[GPCRs from Uniprot]{} &amp; [756]{} &amp; [UniProt 2016 [@UniProt2016]]{}<br />
[Natural product targets]{} &amp; [37]{} &amp; [Dancik 2010 [@Dancik2010]]{}<br />
[BROCA - Cancer Risk Panel]{} &amp; [66]{} &amp; [BROCA Cancer Risk Panel
[@BROCACancerRiskPanel]]{}<br />
[ACMG V2.0]{} &amp; [59]{} &amp; [Kalia 2017 [@Kalia2016]]{}<br />
[GPI-anchored proteins]{} &amp; [135]{} &amp; [UniProt 2016 [@UniProt2016]]{}\</p>

<p>@verma2018rare take an interesting approach to comparing druggable
targets with population genetics data. DrugBank is a database for over
800 genes with over 950 unique drugs. Genetic data can be filtered for
these genes and targeted for LoF variants. Association analysis consists
of logistic regression using the ICD-9 codes, and linear regression
using quantitative variables. This gene binding and regression analysis
steps are done using BioBin.</p>

<p>The International Statistical Classification of Diseases and Related
Health Problems (commonly known as the ICD) provides alpha-numeric codes
to classify diseases and a wide variety of signs, symptoms, abnormal
findings, complaints, social circumstances and external causes of injury
or disease. Nearly every health condition can be assigned to a unique
category and given a code, up to six characters long. Such categories
usually include a set of similar diseases</p>

<p>BioBin relies on the Library of Knowledge Integration (LOKI), which
integrates multiple databases providing a comprehensive biological
knowledge platform for variant binning [@pendergrass2013genomic]. The
LOKI database consolidates biological information from several sources,
most notably the National Center for Biotechnology (NCBI) dbSNP and
Entrez Gene, Kyoto Encyclopedia of Genes and Genomes (KEGG), Reactome,
Gene Ontology (GO), Protein families database (Pfam), NetPath-signal
transduction pathways, amongst others
[@coordinators2017database; @kanehisa2011kegg; @milacic2012annotating; @ashburner2000gene; @finn2013pfam; @kandasamy2010netpath].</p>

<h1 id="sec:cohort_network_analysis">Rare disease cohort network analysis</h1>
<h2 id="introduction-1">Introduction</h2>
<p>The exome sequencing is most commonly used for genetic diagnosis in
single use cases. Over the next decade exome and genome sequencing will
become very commonplace for the average person at least in high-GDP
countries. A massive expanse in population genetics data will provide
the information that GWAS studies have always sought. We will still be
left with large genomic black holes; that is conserved coding and
non-coding regions that are obviously important as the determinants of
human health within Mendelian genetics. To uncover the function of these
genetic loci we will still be at the mercy of cohort size in rare
disorder studies. For true rare genetic disorders, a disease frequency
of 0.01% equates to approximately 800,000 cases worldwide for diseases
that are not embryonic lethal and where lifespan is about normal. If we
consider high income populations where genomic sequencing would be
common, then we may have 100,000 cases. A very well organised rare
disease study would do well to recruit 1 per 1000 in a clearly defined
disease; this is currently the situation although most studies cannot
finance full genomic investigation. Therefore, now and well into the
future, rare disease studies will generally be limited to a maximum
number of living participants on the scale of hundreds.</p>

<p>Current best practices in genomic analysis will first identify “low
hanging fruit”; single cases in a cohort with a clear genetic
determinant (e.g. haploinsufficiency of a well-defined dominant gene).
The second order will identify commonly mutated genes or loci based on
burden testing comparing cases to controls or background population
genetics. Many disorders have a phenotype that can be derived from
mutations in several different genes. The encoded genes generally are a
part of the same protein pathway, even directly upstream and downstream
of each other in some cases. For example, covers this topic with
individual cases of RAG1 and RAG2 deficiency.</p>

<p>Proposed here is a statistically robust and unbiased method to find
variants in protein-coding genes that share a common functional protein
pathway for a disease cohort. <strong>Figure [fig:method]</strong> provides a
high-level graphical summary of the concept. <strong>Figure [fig:abstract]</strong>
conveys the theory of the procedures for this method in more detail with
the major datasets explicitly shown.</p>

<p><strong>Deleterious rare variants in damaged protein pathways in rare
disease.</strong> A. GATK best practices were used for whole exome analysis
with joint genotyping for cases and controls; 200 in total. Custom
filtering [@vcfhacks2015Parry] extracted variants of high impact
consequence (ostensibly loss-of-function (LoF)), present only in cohort
cases. B. Genes harboring rare predicted LoF variants were grouped based
on protein-protein interactions [@String2017Szklarczyk] using a Markov
cluster algorithm [@Enright2002efficienct]. C. Case-control testing was
performed on each protein pathway cluster.</p>

<p><strong>FigureLabel</strong>
method
<img src="/images/net_analysis/method.png" width="40%" /></p>

<p><strong>Rare variant analysis and protein pathway significant enrichment.</strong>
A. DNA is collected and sequenced. B. Routine genomic analysis is
carried out according to best practices, for both (i) control and (ii)
case groups of patients. First, all rare variants are output, followed
by a smaller subset of loss-of-function (LoF) variants. C.
Variant-carrying genes are cluster of protein-protein interactions based
on function and ontology. D. A clustering method is applied to break a
large highly connected network into smaller individual ones. E. The
number of tests can be reduced by, for example, testing only networks
that carry a threshold level of LoFs and are therefore biologically
relevant to disease. F. Deleterious variant load per network was tested
for enrichment in cases, controls, or random sampling. G. Multiple
testing correction is applied to identify the critical significant
threshold.
<strong>FigureLabel</strong>
abstract
<img src="/images/net_analysis/abstract.pdf" width="40%" /></p>

<h2 id="exome-analysis">Exome analysis</h2>
<p>Exome sequencing analyses has been discussed in detail. The rare disease
cohort network analysis requires less tailored analysis steps than
traditional variant interpretation. Therefore, the data preparation is
briefly outlined here.</p>

<p>Sequences were trimmed and quality controlled using FastQC via
Trim-galore. Reads were aligned to GrCh37 using BWA-MEM. GATK “best
practices” were used for marking duplicate reads, recalibration, and
whole cohort variant quality score recalibration before generating
genomic VCFs with HaplotypeCaller and joint genotyping. Filtering and
prediction of functional consequences was performed using Variant Effect
Predictor<br />
(http://www.ensembl.org/info/docs/tools/vep/index.html), Exome Variant
Server<br />
(http://evs.gs.washington.edu/EVS/), The Single Nucleotide Polymorphism
database<br />
(https://www.ncbi.nlm.nih.gov/projects/SNP/) and ClinVar
(https://www.ncbi.nlm.nih.gov/ clinvar/), The Exome Aggregation
Consortium and The Genome Aggregation Database<br />
(http://gnomad.broadinstitute.org). Filtering of common variations and
annotation was performed using VCFhacks<br />
(https://github.com/gantzgraf/vcfhack). Candidate variants were required
to pass the following filtering conditions: frequency (count/coverage)
between 20-100%, according to VEP-annotation at least one canonical
transcript is affected with one of the following consequence: variants
of the coding sequence, frameshift, missense, protein altering, splice
acceptor, splice donor, or splice region; an inframe insertion or
deletion; a start lost, stop gained, or stop retained, or according to
VEP an GnomAD frequency unknown, &lt;=0.01, or with clinical
significance ‘path’. VCFhacks [@vcfhacks2015Parry] was used for
cohort-specific filtering retained functional variants that were present
in at least one case but absent in controls (for case-driven PPI
clustering). The same criteria were used to also collect functional
variants that were present in at least one control but absent in
controls (for control-driven PPI clustering).</p>

<h2 id="cluster-list-preparation">Cluster list preparation</h2>
<p>Group-specific variant data was extracted from the joint cohort.
Specifically, the datasets came from the routine analysis pipeline show
in <strong>Figure [fig:analysis_flow]</strong> as the output of the process
“filter on Sample” and converted from VCF to tsv format using the
process “annovcftoSimple” using the tool VCFhacks [@vcfhacks2015Parry].
Four gene lists were prepared consisting of the following groups; (1)
variants present in controls and (2) variants present in cases and
further divided for genes that harboured either (i) all rare variants or
(ii) only potential loss-of-function variants. Specifically, the
datasets for (i) all rare variants came from the output of the process
“filter on sample” via “get functional variants”. The datasets for (ii)
potential loss-of-function variants is a subset of (i), processed by the
R script at the step where “damaging variants” are written out to file.</p>

<p>Analysis workflow structure. Tools used are shown in square boxes.
Reference data used secondary to inputs are shown as light boxes with
curved sides. Key output files are shown by light slanted boxes. Storage
structure is divided between long-term and short-term
storage.
<strong>FigureLabel</strong>
analysis_flow
<img src="/images/net_analysis/analysis_flow.pdf" width="80%" /></p>

<h2 id="sec:net_construction">Network construction</h2>
<p>Group-specific gene lists [1 (i-ii) and 2 (i-ii)] were assessed for
PPI using the STRING database [@String2017Szklarczyk] via Cytoscape
[@Shannon2003cytoscape]. An initial PPI network was generated for each
of the 4 dataset groups. The STRINGdb default confidence score cut-off
(0.4) was used for these tests. This score is the measure of evidence
required to create an interaction between two nodes. A stricter value
can be set if networks are too large. Query genes were defined as nodes,
PPI were defined as edges, and networks of proteins linked through PPI
were defined as clusters. Clusters or networks can also be generally
considered as making up a part of a protein pathway.</p>

<p>[*[5]{}[Z]{}]{}</p>

<p><br />
&amp; [Network cluster]{} &amp; [Number of nodes]{} &amp; [Number of edges]{} &amp;
[Number of clusters]{}<br />
&amp; [Total ]{} &amp; [1956]{} &amp; [9559]{} &amp; [114]{}<br />
&amp; [No edges]{} &amp; [1]{} &amp; [0]{} &amp; [107]{}<br />
&amp; [One edge]{} &amp; [2]{} &amp; [1]{} &amp; [6]{}<br />
&amp; [Large multi-edge]{} &amp; [1837]{} &amp; [9553]{} &amp; [1]{}<br />
&amp; [Total]{} &amp; [2305]{} &amp; [14139]{} &amp; [102]{}<br />
&amp; [No edges]{} &amp; [1]{} &amp; [0]{} &amp; [77]{}<br />
&amp; [One edge]{} &amp; [2]{} &amp; [1]{} &amp; [3]{}<br />
&amp; [Two edges]{} &amp; [3]{} &amp; [2]{} &amp; [1]{}<br />
&amp; [Large multi-edge]{} &amp; [2219]{} &amp; [14134]{} &amp; [1]{}\</p>

<p><strong>Table [table:node_summary]</strong> lists the characteristics of PPIs for
genes found to harbour functional, potential LoF rare variants in cases
and controls (i.e. gene lists 2 [i-ii]). Most query proteins were seen
to cluster into one large multi-edge node which contained many weak
interactions. The data used in this table is represented again visually
in <strong>Figure [fig:damage_list_case]</strong>. Each dot, or node represents a
protein-coding gene that has at least one potentially damaging variant.
The edges, or lines connecting nodes, represent known PPI data that link
proteins. This visual information clearly illustrates the body of
functional protein data that can be included in variant analysis.
However, since nearly every protein has some potential evidence of
effect on many other proteins, then no clear definable protein pathway
can be seen.</p>

<p><strong>Genes harbouring potentially damaging variants in a disease
cohort.</strong> A visual representation of PPI occurring in all genes that
harbour potentially damaging functional variants in a typical disease
cohort.
<strong>FigureLabel</strong>
damage_list_case
<img src="/images/net_analysis/damage_list_case.png" width="50%" /></p>

<p>To segregate protein pathways and refine the number of genes (nodes) in
each cluster, the Markov cluster algorithm (MCL) was used
[@van2000graph; @Enright2002efficienct]. The principal data-specific
adjustment required for using MCL is the inflation operator, which
regulates cluster granularity or tightness. The optimum inflation
parameter for separating protein pathways was found to be 2.5, using a
measure of uniform distribution across datasets. <strong>Figure
[fig:inflation]</strong> illustrates an optimal inflation of a large PPI
network into smaller, clearly defined protein pathway clusters.</p>

<p>As a reference example, <strong>table [table:node_edge]</strong> lists three
inflation parameters tested for most consistent separation (2.5, 3, 4)
and shows the effect of adjustment on the total number of edges (protein
interactions). The median number of nodes (query proteins) are shown for
cases and controls (also shown as total number of nodes in <strong>table
[table:node_summary]</strong>).</p>

<p>[@l@l@]{} [0pt][0pt]</p>

<p>[Inflation separates protein pathways][<strong>=0 Inflation separates
protein pathways.</strong> A visual representation the ideal inflation
parameter used on a PPI cluster. Weak bonds are broken and strong bonds
draw nodes closer together. No bonds are retained between clusters. With
this type of inflation each protein network cluster can be investigated
without considering overlaps.]{} [fig:inflation]</p>

<p>[*[4]{}[Z]{}]{}</p>

<p><br />
&amp; &amp; [Total count median]{} &amp; [Node/Edge ratio ]{}<br />
&amp; &amp; [Case/control $\pm$ S.D.]{} &amp; [Case/control $\pm$ S.D.]{}<br />
&amp; &amp; [2130.5 $\pm$ 246.78]{} &amp;<br />
&amp; [PPI only *]{} &amp; [11849 $\pm$ 3238.55]{} &amp; [0.18 $\pm$ 0.03]{}<br />
&amp; [Inflation 2.5]{} &amp; [2787.5 $\pm$ 740.34]{} &amp; [0.78 $\pm$ 0.12]{}<br />
&amp; [Inflation 3]{} &amp; [4229.5 $\pm$ 3669.18]{} &amp; [0.77 $\pm$ 0.61]{}<br />
&amp; [Inflation 4]{} &amp; [1199.5 $\pm$ 146.37]{} &amp; [1.78 $\pm$ 0.01]{}\</p>

<p><strong>Figure [fig:network_size_inflation]</strong> illustrates the effect of
adjusting the inflation parameter for MCL clustering on protein
networks. After MCL clustering, cases and controls were found to group
into 928 and 1034 networks clusters respectively. Of these, 494 and 568
were single-node (single-protein) “clusters” which shared no interaction
with another protein while 434 and 466 clusters had at least one
interaction between proteins. The cumulative probability plot (figure
[fig:cumulative_sum_net_rank]) shows the cumulative sum of proteins
per network against network rank size. <strong>Figure [fig:qqplot_2]</strong>
shows qqplot for the same data for distribution compared between groups
after inflation at 2.5.</p>

<p><strong>Effect of inflation on network size distribution.</strong> The outcome on
network size is demonstrated to compare effect of two inflation
parameters. An ideal separation of networks should provide an geometric
decrease in the number of proteins per network regardless of the sample
group. Inflation parameter 2.5 produced the ideal distribution while
inflation parameter 3 produced one large, poorly separated network and a
large increase in single-protein nodes on one group. Binwidth of
10.
<strong>FigureLabel</strong>
network_size_inflation
<img src="/images/net_analysis/network_size_inflation_free.pdf" width="40%" /></p>

<p><strong>Cumulative sum of network rank by size</strong>. The effect of inflation on
network size distribution could be potentially measured automatically by
quantifying the cumulative sum of network rank by size and determining
the best inflation parameter to use. This process would reduce user
bias.
<strong>FigureLabel</strong>
cumulative_sum_net_rank
<img src="/images/net_analysis/cumulative_sum_net_rank.pdf" width="40%" /></p>

<p><strong>QQ plot illustrating uniform inflation.</strong> The data presented in
figure [fig:cumulative_sum_net_rank] is used to produce the
quantile-quantile plot for the most uniform distribution between the
case and control groups after all inflation parameters were
tested.
<strong>FigureLabel</strong>
qqplot_2
<img src="/images/net_analysis/qqplot_2.pdf" width="40%" /></p>

<p><strong>Figure [fig:network_size_nodes]</strong> shows the number of proteins per
network. For example, 235 clusters (470 protein nodes) were seen for
cases where only one interaction was shared between two proteins. A
median of 0.78 nodes-per-edge (proteins-per-interaction) was found in
the cases group; naturally the majority of edges appear in large network
clusters and therefore the frequency of nodes-per-edge increases as
network sizes decrease.</p>

<p>Number of proteins per network for case-driven clustering. The size of
protein networks has a geometric distribution that decreases until
protein (nodes) with no interactions remain; in this cases approximately
200 out of 400 proteins did not play a major role in a single
pathway.
<strong>FigureLabel</strong>
network_size_nodes
<img src="/images/net_analysis/network_size_nodes.pdf" width="40%" /></p>

<h2 id="sec:random_sample">Random sampling</h2>
<p>With our group-specific gene lists [1 (i-ii) and 2 (i-ii)], prepared
in section [sec:net_construction], we found the distribution of genes
per networks and output the list of genes in each network for all 4
datasets. The mean number of genes per network rank was found between
cases and controls, again for (i) all rare variants and (ii) only
potential loss-of-function variants. A third gene cluster list was
produced by random sampling gene symbols in artificial networks equal to
the same median size as case-driven and control-driven clusters in from
datasets (i) and (ii). The resulting dataset [3 (i-ii)] mirrors those
of cases and controls but instead of true PPI networks, the networks
contained randomly assigned genes.</p>

<h2 id="expanding-damaged-gene-mcl-clusters">Expanding damaged gene MCL clusters</h2>
<p>For each of the 4 MCL-clustered datasets, cases and controls [1 (i-ii)
and 2 (i-ii)], the cluster ID and list of gene symbols was extracted.
The gene lists of network clusters made from datasets (ii) (potential
LoF) were used to find the network clusters in (i), all-variant gene
clusters, the contained the same overlapping genes. This occurs where
list (ii) is a subset of list (i). The clusters that contained gene
overlaps were extracted since they contained at least one potential LoF
per network. Using this output, the total variant load in “damaged
pathways” could be compared. For clarity, this procedure is summarised
again in Box [box:expanding]; items <strong>A-B</strong>. Item <strong>C</strong> outlines the
remaining steps. <strong>Figure [fig:damage_list_case]</strong> illustrates the
effect of inflation with an ideal inflation parameter. The large network
of PPI were separated into individually contained protein networks.</p>

<p>[box:expanding]</p>

<h2 id="sec:burden_rank">Burden rank</h2>
<p>Our downstream case-control testing compares the mean total variant load
per network. To prevent dilution of our significance threshold due to
multiple testing an arbitrarily high number of networks we assumed that
protein networks harbouring loss-of-function variants at a consistent
frequency in all groups were unlikely to contain genes of interest. To
remove these networks, we firstly found (<em>p</em>) the ratio of LoF to all
variants within the group per network, and secondly found (<em>q</em>); the
ratio of <em>p</em> between groups per network. Networks were ranked by value
<em>q</em>. Values passing a threshold of 0.7 were included for total variant
load means testing (i.e. 70% of ostensibly damaging variants occurred in
cases regardless of the proportion of total variants). This also has the
effect that even if there is no significant difference in a case/control
total-variant means test downstream, potential false negatives may be
rescued by checking for LoF enrichment. This method is applied to real
data in section [sec:enrichment_test] and <strong>table
[table:bh_real]</strong>.</p>

<h2 id="sec:number_test">Determining the number of tests <em>m</em></h2>
<p>The number of tests should be determined by the predefine LoF ratio per
network, <em>q</em>. This value is arbitrarily set and has the problem that an
investigator can decide to use a higher threshold to nude the critical
significant threshold in a desired direction. However, testing roughly
the top 20-30% of networks is suggested. In our experiments we set our
test number as the top 25% of burden-ranked networks. This will be
approximately 10 networks to test (the asymptote of network numbers peak
when the study size increases over approx. 400 samples as all of the
possible PPIs are saturated once the maximum queryable genes are
included). Study sizes that are much larger than this will likely only
(1) be for disease that are not very rare and (2) be large enough to
start expecting single gene significance levels without requiring
network analysis. However, some very strict filtering rules could allow
larger studies with this method.</p>

<h2 id="significance-testing">Significance testing</h2>
<p>We hypothesised firstly that no variant enrichment would be seen in
random sampling or control-driven gene clusters, and secondly enrichment
would only be seen in case-driven clusters for protein-pathways that
provide susceptibility to viral infection. For measuring a significant
enrichment of functional variants in a protein network, there are three
factors to consider.</p>

<ol>
  <li>
    <p>Our aim is to do a comparison of means between case and control, for
total variant load per network.</p>
  </li>
  <li>
    <p>This is done in three iterations; [1] control-driven, [2]
case-driven, and [3] random sample-driven.</p>
  </li>
  <li>
    <p>We correct our significance threshold to account for multiple
testing using the Benjamini-Hochberg procedure.</p>
  </li>
</ol>

<p>With our group-specific gene lists [1 (i-ii), 2 (i-ii), and [3
(i-ii)], prepared in sections [sec:net_construction] and
[sec:random_sample], we found the distribution of genes per networks
and output the list of genes in each network for all 6 datasets. In each
of the 3 “all variant” datasets we simply do a comparison of means for
total variant load per network comparing case to control, or random.</p>

<p>While the test is not complicated, the significance threshold deserves
an in-depth explanation; this is a novel method and most people
replicating this study will not have experience with the statistical
procedures required. The statistical significance also only allows a
narrow margin for successful discovery. When a large number of tests are
performed, one is likely to produce P-values that are “statistically
significant” by chance (P &lt; 0.05), even if the null hypothesis is
true. The null hypothesis would state that “random controls and people
with disease have the same average frequency of potentially pathogenic
variants in some protein pathway”. The alternate hypothesis would state
that “people with disease have an increased frequency of potentially
pathogenic variants in some protein pathway than random controls”.</p>

<p>Traditionally, Bonferroni correction has been used in cases like this.
For each “family” (network means test) being tested one must correct the
critical P-value. For example, for one test a significant P-value might
be 0.05 and below this we consider the result to be significant. The
chance of getting this result if the null hypothesis was true would be
5%. That does not mean that there is 5% chance that it is true. The
following examples are reiterated summary of the topic found in the
Handbook of biological statistics [@mcdonald2009handbook].</p>

<p>For multiple tests of “families” then we need to adjust the P-value
since we are more likely to get false positives by chance. In a
published example, @garcia2014calorie tested 25 associations with
mammographic density, which is an important risk factor for breast
cancer. The 25 “families” tested were dietary variables including “Total
calories”, “Olive oil”, “whole milk”, “white meat”, etc. For each
variable a P-value was given for its association with mammographic
density, i.e. total calories P &lt; 0.001, olive oil P = 0.008, whole
milk P = 0.039.</p>

<p>To perform a Bonferroni correction, the critical P-value (or significant
threshold) should be divided by the number of tests, 0.05/25 = 0.002.
Therefore, only “total calories” would be significantly associated with
the risk factor. If 75 more variables were measured (100 total) then the
critical P-value would have to be 0.05/100 = 0.0005. However, it may not
be reasonable to invalidate the significance of the original findings.
Using Bonferroni correction for family-wise error rate can mean
extremely small P-values. So instead we use a more powerful method for
controlling the false discovery rate; the Benjamini-Hochberg procedure
[@simes1986improved; @benjamini1995controlling].</p>

<p>In this procedure, we compare each individual P-value to its
Benjamini-Hochberg critical value, $(i/m)Q$, where $i$ is the rank, $m$
is the total number of tests, and $Q$ is the chosen false discovery
rate. The largest P-value that has $P&lt;(i/m)Q$ (i.e. P less than
BH-critical value) is significant, and all of the P-values smaller than
it are also significant, even the ones that aren’t less than their own
Benjamini-Hochberg critical value.</p>

<p>So in the same example, with 25 tests and Benjamini-Hochberg critical
value for a false discovery rate set to 0.25, table
[table:bh_example] shows the outcome. The largest P-value that is
less than its $(i/m)Q$ values is 0.042 for protein. Therefore, the first
5 variables are significantly associated, including whole milk and white
meat despite the fact that their BH-critical value is higher than their
P-value. If we were to never have measured protein in this example, $m$
the number of tests would be 24, slightly increasing the BH-critical
value, and again identify a significant association for the first 4
tests. Someone interested can recalculate this table to see this effect.</p>

<p>[*[2]{}[Z]{}]{}</p>

<p><br />
&amp; [P value]{}<br />
&amp; [&lt;0.001]{}<br />
[Olive oil]{} &amp; [0.008]{}<br />
[Whole milk]{} &amp; [0.039]{}<br />
[White meat]{} &amp; [0.041]{}<br />
[Proteins]{} &amp; [0.042]{}<br />
[Nuts]{} &amp; [0.06]{}<br />
[Cereals and pasta]{} &amp; [0.074]{}<br />
[White fish]{} &amp; [0.205]{}<br />
[Butter]{} &amp; [0.212]{}<br />
[Vegetables]{} &amp; [0.216]{}<br />
[Skimmed milk]{} &amp; [0.222]{}<br />
[Red meat]{} &amp; [0.251]{}<br />
[Fruit]{} &amp; [0.269]{}<br />
[Eggs]{} &amp; [0.275]{}<br />
[Blue fish]{} &amp; [0.34]{}<br />
[Legumes]{} &amp; [0.341]{}<br />
[Carbohydrates]{} &amp; [0.384]{}<br />
[Potatoes]{} &amp; [0.569]{}<br />
[Bread]{} &amp; [0.594]{}<br />
[Fats]{} &amp; [0.696]{}<br />
[Sweets]{} &amp; [0.762]{}<br />
[Dairy products]{} &amp; [0.94]{}<br />
[Semi-skimmed milk]{} &amp; [0.942]{}<br />
[Total meat]{} &amp; [0.975]{}<br />
[Processed meat]{} &amp; [0.986]{}\</p>

<p>The choice of a false discover rate depends on the application. False
positives can waste time, resources, and pollute future work. Minimising
false negatives could result in missing a very important finding, that
is, when there is a real effect but it is not deemed statistically
significant. Allowing a pre-determined level false negatives is often
reasonable. As in our application, finding enriched protein networks is
the main goal, and downstream work will also be done such as clinical
interpretation or functional studies which will catch false negatives.
Therefore, the false discovery rate does not have to be very small;
consider that our input dataset is already filtered down to ostensibly
damaging rare variants. Furthermore, the input dataset is essentially
the result of traditional best practices in exome or genome sequencing
analysis.</p>

<h2 id="sec:enrichment_test">Enrichment testing</h2>
<p>For all networks, the top 30 networks in size (largest to smallest;
1-30) were ordered using the burden rank (sec [sec:burden_rank]).
From these, the number of tests was set (according to the rules defined
in sec [sec:number_test], so that only the top 8 burden-ranked
networks were means tested for their total variant load. <strong>Figure
[fig:means_test]</strong> shows the test of means for the top 8 protein
pathway networks. Table [table:bh_real] lists the P-values assessed
for significance using the BH-procedure. We found that only one of the
networks was significantly associated with a pathogen-specific
immunodeficiency. The variant load was significantly higher than for
controls. The total potential LoF variants only accounted for 30.5% of
total variants in the network but was ranked high during the burden rank
(see sec [sec:burden_rank]) because no controls harboured potential
LoF variants in this network and therefore 100% occurred in cases. This
protein network contained genes responsible for pathogen detection; some
genes <em>might have been</em> identified as candidates using the routine exome
analysis pipeline such as the antiviral receptors and antiviral
interferon regulatory factors. However, most of the other genes that are
integral to this pathway would not have been identified by standard best
practices. The protein network is shown in <strong>Figure
[fig:immune_cluster]</strong> where potential LoF variants-harbouring genes
are coloured in red. Gene candidates with variants of unknown
significance are coloured in red and, anecdotally, the colouring
thereafter becomes lighter (orange to yellow) based on the likelihood of
candidates being identified by manual interpretation of unknown
candidates.</p>

<p><strong>Case and control means test.</strong> The total rare variants per network
are shown, comparing groups. A test of means was conducted in this test
dataset and P-values are
shown.
<strong>FigureLabel</strong>
means_test
<img src="/images/net_analysis/means_test.pdf" width="30%" /></p>

<p>[*[6]{}[Z]{}]{}</p>

<p><br />
&amp; [<strong>LoF freq in cases</strong>]{} &amp; [<strong>LoF freq due to cases per network</strong>]{}
&amp; [<strong>P-value</strong>]{} &amp; [<strong>rank</strong>]{} &amp; [<strong>$(i/m)Q$</strong>]{}<br />
&amp; [0.306]{} &amp; [1]{} &amp; [0.023]{} &amp; [1]{} &amp; [0.025]{}<br />
[27]{} &amp; [0.429]{} &amp; [1]{} &amp; [0.12]{} &amp; [2]{} &amp; [0.05]{}<br />
[16]{} &amp; [0.6]{} &amp; [0.919]{} &amp; [0.13]{} &amp; [3]{} &amp; [0.075]{}<br />
[19]{} &amp; [0.281]{} &amp; [0.835]{} &amp; [0.14]{} &amp; [4]{} &amp; [0.1]{}<br />
[25]{} &amp; [0.25]{} &amp; [1]{} &amp; [0.28]{} &amp; [5]{} &amp; [0.125]{}<br />
[11]{} &amp; [0.357]{} &amp; [0.838]{} &amp; [0.33]{} &amp; [6]{} &amp; [0.15]{}<br />
[10]{} &amp; [0.516]{} &amp; [0.856]{} &amp; [0.34]{} &amp; [7]{} &amp; [0.175]{}<br />
[18]{} &amp; [0.474]{} &amp; [0.85]{} &amp; [0.47]{} &amp; [8]{} &amp; [0.2]{}\</p>

<p>[@l@l@]{} [0pt][0pt]</p>

<p>[Protein network with significantly enriched variant load.][<strong>=0
Protein network with significantly enriched variant load.</strong> From the
example data, network 22 was significantly enriched for rare variants.
The same clustering method was again used on all variants with a less
stringent variant frequency (&lt;1% in general population and present in
any cohort sample). With the resulting, more common variants, the full
protein network can be seen (about double in size compared to only very
rare variants). Gene candidates with variants of unknown significance
are coloured in red and, anecdotally, the colouring thereafter becomes
lighter (orange to yellow) based on the likelihood of candidates being
identified by manual interpretation of unknown candidates. ]{}
[fig:immune_cluster]</p>

<h1 id="discussion">Discussion</h1>
<p>Exome sequence data is usually about 4 GB of information per person.
Whole genomes are approximately 50GB of data. The analysis of whole
genome sequencing is almost identical to the exome pipeline outlined
here. While there is much more information (for not much of a higher
cost), a lot of the non-coding sequence contains information that we
can’t yet interpret. For Mendelian disease the whole exome often
uncovers the coding variants that explain disease. We may not understand
anything else outside the exome (and the surrounding splice regions) in
relation to a patients’ disease. Mutations in the promoters or enhancers
that prevent transcription may not be as readily interpretable as the
majority of coding variant effects. Therefore, whole genome is often not
required. This excuse for performing exome sequencing rather than whole
genome mostly depends on value for money. Performing all the different
kinds of analysis, including non-coding genome analysis, requires many
people with expertise in each topic. Even if whole genome data was
available to smaller research teams, it is often the case that they
cannot carry out all the work required to interpret it. For national
level genomics, there is no question that whole genome sequencing is
preferential. We can retain the data for decades with hundreds of
experts to share the work-load, while the cost is essentially a
political factor. An important question to address is the right for a
person to agree to genetic forfeiture. We are at the brink of
preventative medicine using genome sequencing in newborns. Regardless of
the popular ethical consensus, any preventative non-consenting genomic
analysis can be considered coercion.</p>

<p><strong>Figure [fig:immune_cluster]</strong> illustrates how not only can very
rare or damaging variants be clustered, but the same network can be
expanded to include peripherally interacting genes. This modification
may be used for downstream functional work such as looking at
pathway-level expression data. An important consideration for protein
network cohort analysis is evident in <strong>Figure
[fig:network_size_nodes]</strong>. About 50% of genes with a functional
variant are do not get clustered into a PPI network (protein pathway).
However, some of these genes could still harbour a potential
loss-of-function or damaging variant. If we found 3 significantly
enriched protein networks, a potential 4th missed network (false
negative), because of unclustered genes, would not detract from the
significant findings. Therefore, the singleton genes remaining from MCL
clustering should be listed and reassessed based on traditional
interpretations; variant effect, loss-of-function intolerance, etc. The
converse, a false positive because of over clumping weakly related
proteins, would be negative.</p>

<p>The analysis of genomic data is an iterative process. Therefore, access
to raw unprocessed genetic information is often required to utilize
cutting edge methods [@Auwera2013From; @Poplin2018Scaling]. Furthermore,
genetic analysis is a complex, multi-stage procedure. Due to the
inherent complexity, there is a number of output streams which consist
of different data types. To provide seamless integration with current
best practices in precision medicine, it is valuable to adhere to
standard genomic data types, including CRAM, SAM/BAM, FASTQ, and VCF
[@Li2009Sequence; @Hsi2011Efficient; @cock2009sanger; @Danecek2011Variant].
There is benefit to creating new data formats that increase efficiency.
However, by focusing on key data types in genomics, one can enable
integration with most current software
[@pabinger2014survey; @Auwera2013From].</p>

<p>An interesting caveat to genetic data is that at pre-processing stages,
several data types cannot be currently provided with protection through
the use of modern cryptographic methods
[@froelicher2017unlynx; @juvekar2018gazelle]. There is currently a
severe lack of tools that complement current methods required to
interrogate genetic data at different stages while protecting individual
personal genetic records. Furthermore, despite the attempts to promote
data privacy and integrity through global initiatives, such as Global
Aliance 4 Genome Health, little has been done to produce queryable data
that protects the genetic identity of a subject.</p>

<p>The privacy concerns at the early stages of data processing are often
overlooked. Almost every method offered for data security relies on
protecting only fully process data (e.g. already variant called VCF
format data) or summary statistics. In worst cases, privacy concerned
genomics falls back to “trust-based” systems where data generators or
researchers are required to accept responsibility for preventing any
re-anonymisation. Of course, researcher trust is an important factor,
however, relying on this method for protecting subject information is
immoral. Unlike nearly all clinical data, genetic data is inherently
identifiable and is not readily anonymised. The information that makes
up the data is itself the identity or commodity. In nearly every other
type of clinical data, it is only a commodity when there is an identity
to which it is paired or if it is part of a large dataset-of-normals.
The lack of strong methods of genetic data protection is not an apparent
risk generally. Extrapolating the risk which differentiates other types
of data that requires informed consent is a difficult task for many
experts. Relying on patient consent and trust in data protection is not
sufficient for the future of global genomics. Successfully overcoming
these challenges will allow for the use of analysis methods that
otherwise provide vulnerabilities against the protection of private data
[@Li2009Fast], [GA4GH (https://www.ga4gh.org)].</p>

<h1 id="conclusion">Conclusion</h1>
<p>A pipeline of routine exome analysis was outlined. Important points on
tailored analysis are demonstrated. A new method was developed for the
unbiased detection of a protein network, driving disease, based on
potential loss of function variants.</p>

<h1 id="command-line-example-code">Command line example code</h1>
<p><strong>Whole exome analysis</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash </span>
<span class="c">############################################ </span>
<span class="c">#### The basic protocol for analysis. </span>
<span class="c">#### It is best to set up a loop that </span>
<span class="c">#### can run the protocol on all samples. </span>
<span class="c">############################################ </span>
<span class="c"># Make project organisation folders </span>
<span class="nb">mkdir</span> ~/1.fastq/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/2.trim/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/3.sort/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/4.dedup/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/5.realtar/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/6.indelrealn/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/7.baserecal/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/9.printbam/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/10.gvcf/ <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">mkdir</span> ~/geno/ <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Typical workflow </span>
<span class="c">############################################ </span>

<span class="c">############################################ </span>
<span class="c">#### [command_cut] </span>
<span class="c">############################################ </span>
trim_galore <span class="nt">-q</span> 20 <span class="nt">-fastqc_args</span> <span class="se">\</span>
<span class="nt">-outdir</span> ~/2.trim/QC_reports <span class="nt">-illumina</span> <span class="nt">-gzip</span> <span class="se">\</span>
<span class="nt">-o</span> ~/2.trim/ <span class="nt">-length</span> 20 <span class="nt">-paired</span> <span class="se">\</span>
~/1.fastq/Sequencing_ID_L001_R1_001.fastq.gz <span class="se">\</span>
~/1.fastq/Sequencing_ID_L001_R2_001.fastq.gz <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_align] </span>
<span class="c">############################################ </span>
bwa mem <span class="nt">-t</span> 12 <span class="nt">-M</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
~/2.trim/Sequencing_ID_L001_R1_001_val_1.fq.gz <span class="se">\</span>
~/2.trim/Sequencing_ID_L001_R2_001_val_2.fq.gz <span class="se">\</span>
<span class="nt">-v</span> 1 <span class="nt">-R</span> <span class="s1">'@RG\tID:Sample_ID\tSM:Sample_ID \
tPL:ILLUMINA\tLB:Sample_ID'</span> <span class="se">\</span>
<span class="nt">-M</span> | samtools view <span class="nt">-Sb</span> - <span class="o">&gt;</span> ~/2.trim/Sample_ID.bam <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_sort] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/picard/picard-tools-2.5.0/picard.jar <span class="se">\</span>
SortSam <span class="se">\</span>
<span class="nv">I</span><span class="o">=</span> ~/2.trim/Sample_ID.bam <span class="se">\</span>
<span class="nv">O</span><span class="o">=</span> ~/3.sort/Sample_ID.sort.bam <span class="se">\</span>
<span class="nv">SO</span><span class="o">=</span>coordinate <span class="nv">CREATE_INDEX</span><span class="o">=</span>TRUE <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_dedup] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/picard/picard-tools-2.5.0/picard.jar <span class="se">\</span>
MarkDuplicates <span class="se">\</span>
<span class="nv">I</span><span class="o">=</span> ~/3.sort/Sample_ID.sort.bam <span class="se">\</span>
<span class="nv">O</span><span class="o">=</span> ~/4.dedup/Sample_ID.sort.dedup.bam <span class="se">\</span>
<span class="nv">M</span><span class="o">=</span> ~/4.dedup/Sample_ID.sort.dedup.metrics <span class="se">\</span>
<span class="nv">CREATE_INDEX</span><span class="o">=</span>TRUE <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_realtar] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx6g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> RealignerTargetCreator <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-known</span> ~/ref/1000G_phase1.indels.b37.vcf <span class="se">\</span>
<span class="nt">-known</span> ~/ref/Mills_and_1000G_gold_standard.<span class="se">\ </span>indels.b37.sites.vcf <span class="se">\</span>
<span class="nt">-I</span> ~/4.dedup/Sample_ID.sort.dedup.bam <span class="se">\</span>
<span class="nt">-o</span> ~/5.realtar/Sample_ID.sort.dedup.bam.intervals <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_indelrealign]</span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx6g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> IndelRealigner <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-known</span> ~/ref/1000G_phase1.indels.b37.vcf <span class="se">\</span>
<span class="nt">-known</span> ~/ref/Mills_and_1000G_gold_standard.<span class="se">\ </span>indels.b37.sites.vcf <span class="se">\</span>
<span class="nt">-I</span> ~/4.dedup/Sample_ID.sort.dedup.bam <span class="se">\</span>
<span class="nt">-targetIntervals</span> <span class="se">\</span>
~/5.realtar/Sample_ID.sort.dedup.bam.intervals <span class="se">\</span>
<span class="nt">-o</span> ~/6.indelrealn/Sample_ID.sort.dedup.indelrealn.bam <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_bsqr] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> BaseRecalibrator <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-knownSites</span> ~/ref/dbSnp146.b37.vcf.gz <span class="se">\</span>
<span class="nt">-knownSites</span> ~/ref/1000G_phase1.indels.b37.vcf <span class="se">\</span>
<span class="nt">-knownSites</span> ~/ref/Mills_and_1000G_gold_standard.<span class="se">\ </span>indels.b37.sites.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/7.baserecal/Sample_ID.sort.dedup.indelrealn.recal.grp <span class="se">\</span>
<span class="nt">-I</span> ~/6.indelrealn/Sample_ID.sort.dedup.indelrealn.bam <span class="se">\</span>
<span class="nt">-nct</span> 6 <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Optional check for base recalibration </span>
<span class="c">############################################ </span>
<span class="c">####  Print reads</span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx12g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> PrintReads <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-I</span> ~/6.indelrealn/Sample_ID.sort.dedup.indelrealn.bam <span class="se">\</span>
<span class="nt">-BQSR</span> ~/7.baserecal/Sample_ID.sort.dedup.indelrealn.recal.grp <span class="se">\</span>
<span class="nt">-o</span> ~/9.printbam/Sample_ID.sort.dedup.indelrealn.recal.bam <span class="se">\</span>
<span class="nt">-disable_indel_quals</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### [command_hc] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> HaplotypeCaller <span class="nt">-emitRefConfidence</span> GVCF <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-D</span> ~/ref/dbSnp146.b37.vcf.gz <span class="se">\</span>
<span class="nt">-stand_call_conf</span> 30 <span class="se">\</span>
<span class="nt">-stand_emit_conf</span> 10 <span class="se">\</span>
<span class="nt">-o</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-L</span> ~/ref/SureSelectAllExonV6/S07604514_Regions_b37.bed <span class="se">\</span>
<span class="nt">-ip</span> 30 <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="c"># deprecated -I ~/9.printbam/Sample_ID.sort.dedup.indelrealn.recal.bam</span>

<span class="c">############################################ </span>
<span class="c">#### [command_joint] </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx12g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> GenotypeGVCFs <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-D</span> ~/ref/dbSnp146.b37.vcf.gz <span class="nt">-stand_call_conf</span> 30 <span class="se">\</span>
<span class="nt">-stand_emit_conf</span> 10 <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-V</span> ~/10.gvcf/Sample_ID.sort.dedup.indelrealn.recal.HC.g.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.vcf <span class="nt">-nda</span> <span class="nt">-showFullBamList</span> <span class="nt">-nt</span> 12 <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Hard filter selecting SNVs </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx12g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> SelectVariants <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-selectType</span> SNP <span class="se">\</span>
<span class="nt">-variant</span> ~/geno/genotype.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.raw-snps.vcf <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Hard filter selecting INDELs </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx12g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> SelectVariants <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-variant</span> ~/geno/genotype.vcf <span class="se">\</span>
<span class="nt">-selectType</span> INDEL <span class="nt">-selectType</span> MNP <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.raw-indels.vcf <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Applying hard filter for SNVs </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> VariantFiltration <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-V</span> ~/geno/genotype.raw-snps.vcf <span class="se">\</span>
<span class="nt">-filterExpression</span> QD &lt; 2.0 <span class="o">||</span> FS <span class="o">&gt;</span> 60.0 <span class="o">||</span> MQ &lt; 40.0 <span class="o">||</span><span class="se">\</span>
MappingQualityRankSum &lt; <span class="nt">-12</span>.5 <span class="o">||</span> ReadPosRankSum &lt; <span class="nt">-8</span>.0 <span class="se">\</span>
<span class="nt">-filterName</span> snp_hard_filter <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.raw-snps.filtered.snvs.vcf <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Applying hard filter for INDELs </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> VariantFiltration <span class="se">\</span>
<span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-V</span> ~/geno/genotype.raw-indels.vcf <span class="se">\</span>
<span class="nt">-filterExpression</span> QD &lt; 2.0 <span class="o">||</span> FS <span class="o">&gt;</span> 200.0 <span class="o">||</span><span class="se">\</span>
ReadPosRankSum &lt; <span class="nt">-20</span>.0 <span class="se">\</span>
<span class="nt">-filterName</span> indel_hard_filter <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.raw-indels.filtered.indels.vcf <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Combine filtered results </span>
<span class="c">############################################ </span>
java <span class="nt">-Xmx8g</span> <span class="nt">-jar</span> ~/GATK/GenomeAnalysisTK.jar <span class="se">\</span>
<span class="nt">-T</span> CombineVariants <span class="nt">-R</span> ~/ref/human_g1k_v37.fasta <span class="se">\</span>
<span class="nt">-variant</span> ~/geno/genotype.raw-snps.filtered.snvs.vcf <span class="se">\</span>
<span class="nt">-variant</span> ~/geno/genotype.raw-indels.filtered.indels.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.fltd-combinedvars.vcf <span class="se">\</span>
<span class="nt">-genotypemergeoption</span> UNSORTED <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Filter variants in EdbSNP &gt;/= 1% \</span>
<span class="c">#### and not listed as pathogenic by ClinVar </span>
<span class="c">############################################ </span>
perl ~/vcfhacks-v0.2.0/annotateSnps.pl <span class="se">\</span>
<span class="nt">-d</span> ~/ref/dbSnp146.b37.vcf.gz ~/ref/clinvar_20160531.vcf.gz <span class="se">\</span>
<span class="nt">-f</span> 1 <span class="nt">-pathogenic</span> <span class="se">\</span>
<span class="nt">-i</span> ~/geno/genotype.fltd-combinedvars.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.vcf <span class="se">\</span>
<span class="nt">-t</span> 12 <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Filter variants in EVS greater &gt;/= 1% </span>
<span class="c">############################################ </span>
perl ~/vcfhacks-v0.2.0/filterOnEvsMaf.pl <span class="nt">-d</span> ~/ref/evs/ <span class="se">\</span>
<span class="nt">-f</span> 1 <span class="nt">-progress</span> <span class="se">\</span>
<span class="nt">-i</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.vcf <span class="se">\</span>
<span class="nt">-t</span> 12 <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Exac filter for population frequency </span>
<span class="c">############################################ </span>
perl ~/vcfhacks-v0.2.0/filterVcfOnVcf.pl <span class="se">\</span>
<span class="nt">-i</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.vcf <span class="se">\</span>
<span class="nt">-f</span> ~/ref/ExAC/ExAC.r0.3.sites.vep.vcf.gz <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.exac.vcf <span class="se">\</span>
<span class="nt">-w</span> <span class="nt">-y</span> 0.01 <span class="se">\</span>
<span class="nt">-b</span> <span class="se">\</span>
<span class="c"># progress bar \</span>
<span class="nt">-t</span>  <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="c"># number of threads</span>

<span class="c">############################################ </span>
<span class="c">#### Annotate with variant effect predictor </span>
<span class="c">############################################ </span>
perl ~/variant_effect_predictor/variant_effect_predictor.pl <span class="se">\</span>
<span class="nt">-offline</span> <span class="nt">-vcf</span> <span class="nt">-everything</span> <span class="se">\</span>
<span class="nt">-dir_cache</span> ~/variant_effect_predictor/vep_cache <span class="se">\</span>
<span class="nt">-dir_plugins</span> ~/variant_effect_predictor/vep_cache/Plugins <span class="se">\</span>
<span class="nt">-plugin</span> Condel,<span class="se">\</span>
~/variant_effect_predictor/vep_cache/Plugins/config/Condel/config/ <span class="se">\</span>
<span class="nt">-plugin</span> ExAC,~/ref/ExAC/ExAC.r0.3.sites.vep.vcf.gz <span class="se">\</span>
<span class="nt">-plugin</span> SpliceConsensus <span class="se">\</span>
<span class="nt">-fasta</span> <span class="se">\</span>
~/variant_effect_predictor/fasta/<span class="se">\</span>
Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz <span class="se">\</span>
<span class="nt">-i</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.exac.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.exac.vep.vcf <span class="se">\</span>
<span class="nt">-fork</span> 12 <span class="o">&amp;&amp;</span> <span class="se">\</span>

<span class="c">############################################ </span>
<span class="c">#### Confirm samples names </span>
<span class="c">############################################ </span>
perl ~/vcfhacks-v0.2.0/getSampleNames.pl <span class="se">\</span>
<span class="nt">-i</span> ~/geno/genotype.fltd-combinedvars.1pcdbsnp.1pcEVS.exac.vep.vcf <span class="o">&amp;&amp;</span> <span class="se">\</span>


<span class="c">############################################ </span>
<span class="c">## Data extraction </span>
<span class="c">############################################ </span>
<span class="c">#### Extract columns </span>
<span class="c">############################################ </span>
<span class="c">#### A list of files for</span>
<span class="c">#### where the data from</span>
<span class="c">#### one column is compiled into</span>
<span class="c">#### a master table </span>
<span class="c">############################################ </span>

<span class="c">############################################ </span>
<span class="c">#### This takes column 3 from every file</span>
<span class="c">#### and appends to the output file.</span>
<span class="c">#### Space delimited. </span>
<span class="c">############################################ </span>
<span class="nb">awk </span><span class="nv">FNR</span><span class="o">==</span>1<span class="o">{</span>f++<span class="o">}{</span>a[f,FNR]<span class="o">=</span><span class="nv">$3</span><span class="o">}</span>END<span class="o">{</span><span class="k">for</span><span class="o">(</span><span class="nv">x</span><span class="o">=</span>1<span class="p">;</span>x&lt;<span class="o">=</span>FNR<span class="p">;</span>x++<span class="o">)</span><span class="se">\ </span>
<span class="o">{</span><span class="k">for</span><span class="o">(</span><span class="nv">y</span><span class="o">=</span>1<span class="p">;</span>y&lt;ARGC<span class="p">;</span>y++<span class="o">)</span><span class="nb">printf</span><span class="o">(</span>%s ,a[y,x]<span class="o">)</span><span class="p">;</span>print <span class="o">}}</span> <span class="se">\</span>
./../<span class="k">*</span>/pheno.txt <span class="o">&gt;</span> master.txt

<span class="c">############################################ </span>
<span class="c">#### The spacer method can be changed; tab, space, comma, etc.</span>
<span class="c">#### Another way to convert later is with the following command.</span>
<span class="c">#### [The tab character (after s/) must be removed</span>
<span class="c">#### and printed to the command line using ctrl+v then tab.] </span>
<span class="c">############################################ </span>
<span class="nb">sed</span> <span class="s1">'s/ /,/g'</span> input.tsv <span class="o">&gt;</span> output.csv

<span class="c">############################################ </span>
<span class="c">#### Candidate filter</span>
<span class="c">############################################ </span>
<span class="c">#### Filter a VCF on a candidate gene list. </span>
<span class="c">############################################ </span>
<span class="c">#### List format as X:1-2000,</span>
<span class="c">#### or -b for a bed file or</span>
<span class="c">#### a list file with 1 per line. </span>
<span class="c">############################################ </span>
<span class="k">for </span>f <span class="k">in</span> ~/immune.panel/vep/<span class="k">*</span>.vcf <span class="k">do 
</span>perl ~/vcfhacks-v0.2.0/filterVcfOnLocation.pl <span class="se">\</span>
<span class="nt">-i</span> ~/immune.panel/vep/<span class="nv">$f</span> <span class="se">\</span>
<span class="nt">-b</span> ~/deep.panel.bed <span class="se">\</span>
<span class="nt">-o</span> ~/immune.panel/filter/<span class="si">$(</span> <span class="nb">basename</span> <span class="nt">-s</span> .vcf <span class="nv">$f</span> <span class="si">)</span>.panel.vcf <span class="se">\</span>
<span class="k">done</span>

<span class="c">############################################ </span>
<span class="c">#### Post-routine analysis candidate filtering.</span>
<span class="c">#### Similar filtering can be done without going back</span>
<span class="c">#### to analysis stages to create a virtual panel. </span>
<span class="c">############################################ </span>
<span class="c">#### Export all gene names and give the count.</span>
<span class="nb">sort </span>list.txt | <span class="se">\</span>
<span class="nb">uniq</span> <span class="nt">-c</span> <span class="o">&gt;</span> InflammatoryDisorderCohortHitCount.txt
<span class="c">#### Format to csv.</span>
<span class="c">#### Cross against a master list of immune genes.</span>

<span class="c">############################################ </span>
<span class="c">#### In R, import data </span>
<span class="c">############################################ </span>
master &lt;- read.csv<span class="o">(</span>./master.csv, <span class="nv">stringsAsFactors</span><span class="o">=</span>FALSE<span class="o">)</span>
InflammatoryDisorderCohortHitCount &lt;- <span class="se">\</span>
read.csv<span class="o">(</span>./ InflammatoryDisorderCohortHitCount.csv, <span class="nv">stringsAsFactors</span><span class="o">=</span>FALSE<span class="o">)</span>

<span class="c">############################################ </span>
<span class="c">#### Merge the master immune gene list</span>
<span class="c">#### with the Inflammatory disorder cohort hits. </span>
<span class="c">############################################ </span>
combine &lt;- merge<span class="o">(</span>master, InflammatoryDisorderCohortHitCount, 
        by <span class="o">=</span> Gene, all <span class="o">=</span> TRUE<span class="o">)</span>

<span class="c">############################################ </span>
<span class="c">#### Remove the genes that happen to overlap</span>
<span class="c">#### gene of interest and remove anything from</span>
<span class="c">#### the master list that is not in the cohort list. </span>
<span class="c">############################################ </span>
clean &lt;- na.omit<span class="o">(</span>combine<span class="o">)</span>

<span class="c">############################################ </span>
<span class="c">#### Write out the table. </span>
<span class="c">############################################ </span>
write.csv<span class="o">(</span>clean, ./GenesOfInterest.csv, row.names <span class="o">=</span> FALSE<span class="o">)</span>

<span class="c">############################################ </span>
<span class="c">#### The output can be sorted as of interest</span>
<span class="c">#### e.g. autosomal dominant autoinflammatory gene. </span>
<span class="c">############################################ </span>

<span class="c">############################################ </span>
<span class="c">#### Tailored filtering</span>
<span class="c">############################################ </span>
<span class="c">#### Filter on sample.</span>
<span class="c">#### May need use a -freq option</span>
<span class="c">#### to account for index hopping.</span>
<span class="c">#### Filter on sample removes anything shared</span>
<span class="c">#### with cases (-s) that are not listed but not others (-x). </span>
<span class="c">############################################ </span>
perl /home/vcfhacks-v0.2.0/filterOnSample.pl <span class="se">\</span>
<span class="nt">-i</span> ~/samples.vep.vcf <span class="se">\</span>
<span class="nt">-s</span> <span class="k">case</span>.1 <span class="k">case</span>.2 <span class="k">case</span>.3 <span class="nt">-x</span> <span class="se">\</span>
<span class="nt">-o</span> ~/samples.getFunctionalVariantsVep.vcf

<span class="c">############################################ </span>
<span class="c">#### Get variants. </span>
<span class="c">############################################ </span>
<span class="c">#### Getting functional variants. The -n flag allows</span>
<span class="c">#### selections only when &gt;2 samples</span>
<span class="c">#### have variants in a shared gene. </span>
perl /home/vcfhacks-v0.2.0/getFunctionalVariants.pl <span class="se">\</span>
<span class="nt">-s</span> <span class="k">case</span>.1 <span class="k">case</span>.2 <span class="k">case</span>.3 <span class="se">\</span>
<span class="nt">-i</span> ~/samples.vep.vcf <span class="se">\</span>
<span class="nt">-f</span> <span class="nt">-n</span> 2 <span class="se">\</span>
<span class="nt">-o</span> ~/samples.getFunctionalVariantsVep.SharedGenes.vcf

<span class="c">#### Candidate compound heterozygous.</span>
<span class="c">#### Only variants that are common in ALL -s are considered.</span>
<span class="c">#### Flag -n specifies the number of cases</span>
<span class="c">#### required to return a genotype. </span>
perl /home/vcfhacks-v0.2.0/findBiallelic.pl <span class="se">\</span>
<span class="nt">-i</span> ~/samples.vep.vcf <span class="se">\</span>
<span class="nt">-s</span> <span class="k">case</span>.1 <span class="k">case</span>.2 <span class="k">case</span>.3 <span class="se">\</span>
<span class="nt">-n</span> 1 <span class="se">\</span>
<span class="nt">-o</span> ~/samples.findBiallelic.all.vcf

<span class="c">############################################ </span>
<span class="c">#### Rank, annontate, and simplify </span>
<span class="c">############################################ </span>
perl /home/vcfhacks-v0.2.0/rankOnCaddScore.pl <span class="se">\</span>
<span class="nt">-c</span> /data/shared/cadd/v1.3/<span class="k">*</span>.gz <span class="se">\</span>
<span class="nt">-i</span> ~/samples.getFunctionalVariantsVep.SharedGenes.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/samples.getFunctionalVariantsVep.SharedGenes.cadd.ranked.vcf <span class="se">\</span>
<span class="nt">-progress</span>

perl /home/vcfhacks-v0.2.0/geneAnnotator.pl <span class="se">\</span>
<span class="nt">-d</span> /home/vcfhacks-v0.2.0/data/geneAnnotatorDb <span class="se">\</span>
<span class="nt">-i</span> ~/samples.findBiallelic.all.vcf <span class="se">\</span>
<span class="nt">-o</span> ~/samples.findBiallelic.all.gene.anno

perl /home/vcfhacks-v0.2.0/annovcfToSimple.pl <span class="se">\</span>
<span class="nt">-i</span> ~/samples.findBiallelic.all.gene.anno <span class="se">\</span>
<span class="nt">-vep</span> <span class="nt">-gene_anno</span> <span class="se">\</span>
<span class="nt">-canonical_only</span> <span class="se">\</span>
<span class="nt">-u</span> <span class="nt">-contains_variant</span> <span class="se">\</span>
<span class="nt">-o</span> ~/samples.findBiallelic.all.gene.anno.simple.xlsx

</code></pre></div></div>
</p>

  <h2> - </h2>
  <p><h1 id="reference-databases">Reference databases</h1>

<ul id="markdown-toc">
  <li><a href="#reference-databases" id="markdown-toc-reference-databases">Reference databases</a></li>
  <li><a href="#population-statistics" id="markdown-toc-population-statistics">Population statistics</a></li>
  <li><a href="#disease-database" id="markdown-toc-disease-database">Disease database</a></li>
  <li><a href="#functionl-databases" id="markdown-toc-functionl-databases">Functionl databases</a></li>
  <li><a href="#methods" id="markdown-toc-methods">Methods</a></li>
  <li><a href="#pathogens" id="markdown-toc-pathogens">Pathogens</a></li>
  <li><a href="#misc" id="markdown-toc-misc">Misc</a></li>
  <li><a href="#commercial" id="markdown-toc-commercial">Commercial</a></li>
</ul>

<h1 id="population-statistics">Population statistics</h1>
<p><a href="https://www.ebi.ac.uk/gwas/home">GWAS Catalog</a><br />
<a href="https://cftr2.org/mutations_history">CFTR2 Variant List</a><br />
<a href="http://genet.sickkids.on.ca/LinkPage.html">Cystic Fibrosis Mutation Database</a><br />
<a href="https://cran.rstudio.com/web/packages/ukbtools/vignettes/explore-ukb-data.html">Explore UK Biobank data</a><br />
<a href="http://biobank.ctsu.ox.ac.uk/crystal/label.cgi">UKB : Browse by Category</a><br />
<a href="https://stjude.cloud/">St. Jude Cloud</a><br />
<a href="https://www.simonsfoundation.org/simons-genome-diversity-project/">Simons Genome Diversity Project</a><br />
<a href="https://opensnp.org/">openSNP</a><br />
<a href="https://www.genome.gov/gwastudies/">Catalog of Published GWAS - NHGRI</a><br />
<a href="https://pophuman.uab.cat/?loc=chr6%3A137998001..138396200&amp;tracks=DNA%2Cgene_annotations%2CPi_CEU_10kb%2Ctheta_CEU_10kb%2CTajima_D_CEU_10kb%2Chap_diversity_within_CEU_10kb%2CKelly_ZnS_CEU_10kb%2CDoS_CEU_10kb%2CK_CEU_10kb&amp;highlight=">PopHuman</a><br />
<a href="https://popgen.uchicago.edu/ggv/?data=%221000genomes%22&amp;chr=1&amp;pos=222087833">Geographic genomic variant browser</a><br />
<a href="https://www.nature.com/articles/ejhg2017130">SweGen</a><br />
<a href="https://www.finngen.fi/en">FinnGen</a><br />
<a href="http://www.lovd.nl/3.0/home">LOVD - Open Source DNA variation database system</a><br />
<a href="https://www.ncbi.nlm.nih.gov/gap">dbGaP - NCBI</a><br />
<a href="https://sites.google.com/site/jpopgen/dbNSFP">dbNSFP - Jpopgen</a><br />
<a href="https://gnomad.broadinstitute.org/">gnomad</a></p>

<h1 id="disease-database">Disease database</h1>
<p><a href="https://panelapp.genomicsengland.co.uk/panels/398/">Primary immunodeficiency disorders</a><br />
<a href="https://panelapp.genomicsengland.co.uk/panels/398/">Panel app GE</a><br />
<a href="http://www.matchmakerexchange.org/">Matchmaker Exchange</a><br />
<a href="https://www.cafevariome.org/home">Cafe Variome</a><br />
<a href="https://www.multiplesklerose.ch/fr/propos-de-la-sep/recherche/demande-de-soutien-de-votre-projet-de-recherche/">SEP MS cohort grant and data</a><br />
<a href="https://www.multiplesklerose.ch/de/ueber-ms/aus-der-forschung/forschungsantraege/#c8514">guidelines</a><br />
<a href="https://www.caapa-project.org">Consortium on Asthma among African-ancestry Populations in the Americas (CAAPA)</a></p>

<h1 id="functionl-databases">Functionl databases</h1>
<p><a href="https://variantvalidator.org/#variantValidator">VariantValidator</a><br />
<a href="https://www.drugbank.ca/releases/latest">DrugBank</a><br />
<a href="http://phylomedb.org/">PhylomeDB - large scale phylogenetic data</a><br />
<a href="https://www.innatedb.com/annotatedGenes.do?type=innatedb">InnateDB: Systems Biology of the Innate Immune Response</a><br />
<a href="https://www.nextprot.org/about/nextprot">Nextprot</a><br />
<a href="https://hpo.jax.org/app/download/annotation">Human Phenotype Ontology</a><br />
<a href="http://www.ebi.ac.uk/pdbe/docs/sifts/quick.html">SIFTS (Quick Access)&lt; PDBe &lt; EMBL-EBI</a><br />
<a href="https://github.com/macarthur-lab/gene_lists">List of gene lists for genomic analyses.</a><br />
<a href="https://mastermind.genomenon.com/detail?disease=all%20diseases&amp;gene=RAG1&amp;mutation=RAG1:S225R">Genome Mastermind - published variants</a><br />
<a href="https://gdac.broadinstitute.org/">Broad GDAC Firehose</a><br />
<a href="https://monarchinitiative.org/">Monarch gentype to phenotype</a><br />
<a href="https://www.inetbio.org/humannet/">HumanNet Search</a><br />
<a href="https://varsome.com/variant/hg19/RAG1%3AR737H">Varsome</a><br />
<a href="http://www.discovehrshare.com/">DiscovEHR genomics and EHR</a></p>

<h1 id="methods">Methods</h1>
<p><a href="https://www.genome.gov/20019523/">Genome-Wide Association Studies Fact Sheet - National Human Genome Research Institute (NHGRI)</a><br />
<a href="https://www.genomicsengland.co.uk/genomics-england-uses-mongodb-to-power-the-data-science-behind-the-100000-genomes-project/">Genomics England uses MongoDB to power the 100,000 Genomes Project | Genomics England</a><br />
<a href="https://www.mongodb.com/press/genomics-england-uses-mongodb-to-power-the-data-science-behind-the-100000-genomes-project">Genomics England uses MongoDB to Power the 100,000 Genomes Project | MongoDB</a><br />
<a href="http://docs.opencb.org/plugins/servlet/mobile?contentId=327756#content/view/327756">Confluence Mobile - OpenCB</a><br />
<a href="https://www.nextprot.org/">neXtProt platform | The human protein knowledge base and annotation database</a><br />
<a href="https://s3.us-east-2.amazonaws.com/ccrs/ccr.html">Integrative Genomics Viewer - CCRs</a><br />
<a href="https://vdjdb.cdr3.net/">VDJdb</a><br />
<a href="https://vdjviz.cdr3.net/">VDJviz: home</a><br />
<a href="https://www.personalgenomes.org.uk/data/">Personal Genome Project: United Kingdom</a><br />
<a href="http://www.drive5.com/muscle/">MUSCLE multiple sequence align</a><br />
<a href="https://www.cdisc.org/about">Clinical Data Interchange Standards Consortium</a><br />
<a href="http://transmartfoundation.org/europe-fall-meeting-2018/">European i2b2 tranSMART Academic Users Group</a><br />
<a href="https://rd-connect.eu/">RD-Connect</a>
<a href="https://www.sanger.ac.uk/science/tools">Tools and Software | Wellcome Sanger Institute</a>\</p>

<h1 id="pathogens">Pathogens</h1>
<p><a href="https://img.jgi.doe.gov/cgi-bin/vr/main.cgi">JGI Integrated Microbial Viral Genome Home</a><br />
<a href="https://www.hiv.lanl.gov/content/sequence/HIV/mainpage.html">HIV sequence database main page</a><br />
<a href="https://academic.oup.com/bioinformatics/article/34/13/i89/5045729">Ecoli Ab resistance example</a></p>

<h1 id="misc">Misc</h1>
<p><a href="http://tldp.org/LDP/abs/html/">Advanced Bash-Scripting Guide</a><br />
<a href="https://github.com/hadley/stats337#readings">Hadley Readings in applied data science</a><br />
<a href="https://toolbox.google.com/datasetsearch">Dataset Search</a><br />
<a href="https://registry.opendata.aws/">Registry of Open Data on AWS</a><br />
<a href="http://libgen.io/">LibGen literature</a></p>

<h1 id="commercial">Commercial</h1>
<p><a href="http://saphetor.com/technology_platform/">Saphetor</a><br />
<a href="https://www.dantelabs.com">Dante labs genome sequencing</a></p>

</p>

  <h2> - </h2>
  <p><h1 id="websites-for-basic-genetic-variant-information">Websites for basic genetic variant information</h1>
<p class="meta">26 Apr 2020</p>

<ul id="markdown-toc">
  <li><a href="#websites-for-basic-genetic-variant-information" id="markdown-toc-websites-for-basic-genetic-variant-information">Websites for basic genetic variant information</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#sites-and-tools-for-getting-basic-genetic-information" id="markdown-toc-sites-and-tools-for-getting-basic-genetic-information">Sites and tools for getting basic genetic information</a></li>
  <li><a href="#communities-and-learning" id="markdown-toc-communities-and-learning">Communities and learning</a></li>
</ul>

<h1 id="introduction">Introduction</h1>
<p>Identifying pathogenic variants with whole genome and whole exome sequencing is not simple.
Determining the correct filtering method can take some time but it is not the most difficult task.
Validating genetic factors is generally the most time consuming part of this type of research.
Here is a compilation of some of the websites and resources that I use constantly.
I will begin this simply as a list but continue to contribute information on how to use all of these over time.
I use most of the listed resources daily.</p>

<p>There are several steps in assessing if a gene variant is a good candidate to explain a clinical phenotype.
Often a clear story can be made between the genetic mutation and the resulting phenotype.
Other times (usually) a genetic finding (particularly biallelic mutations) seem to have a direct link to the clinical phenotype but it can take  weeks-months to functionally validate such a finding.
 With that in mind, it is good to have some sort of routine way to quickly assess the possible pathogenicity of a mutation by hand.
I will mostly discuss these in the context of rare mutations which are likely to be under selective pressure and occur at very low frequencies in a healthy population.</p>

<h1 id="sites-and-tools-for-getting-basic-genetic-information">Sites and tools for getting basic genetic information</h1>
<p>For assessing rare variants Ensembl and Exac (now gnomAD) are my bread and butter.
I haven’t done it yet but I need to set up a hotkey to open a browser with both of these sites simultaneously.
To demonstrate how I like to use these we could use an example.
Lets say we have NGS results for a patient with immunodeficiency with coding variants in the gene RAG2.
OK, well known gene, important for antibody production as wells as TCR and BCR development.
Looks good so far.
Let’s see if the variants are common SNPs or could they be likely to cause damage if they are not reported (of course this is in your pipeline automatically but it’s good practice and takes less than 60 seconds; valuable if there is a real person affected by your results).</p>

<p>After a long time getting confused about transcripts and coordinates, I now know how important it is to accurately report coordinates so there is no confusion if collaborating or reporting the mutations etc.</p>

<p><a href="http://exac.broadinstitute.org">Exac.org</a></p>

<p>This is, in a nutshell, the exomes of ~ 60,000 individuals which can be used to view how frequently mutations occur in the general population (unfortunately it is mostly just European but there is some global representation). Exac is vital for checking coding variants.
It covers some of the intronic regions (exon intron splice sites) and some of the upstream and downstream regions.
This is typical for anyone who does whole exome sequencing.
We mentioned confusion about transcripts and coordinates, Exac automatically loads the coverage as shown for the canonical transcript.
Stick with this transcript for reporting or at least for your own notes.
When you head over to Ensembl grab the same one in the transcript table.<br />
Update! <a href="http://gnomad.broadinstitute.org/about">The Genome Aggregation Database (gnomAD) is online</a>.<br />
This data set is the combination of “123,136 exomes and 15,496 genomes from unrelated individuals” which has “removed individuals known to be affected by severe pediatric disease, as well as their first-degree relatives.”
This is n extremely exciting resource. If you are familiar with Exac then you will know the value of this expansion into gnomAD.
<a href="https://youtu.be/_uRuFZv4JaU">youtube.com</a><br />
<a href="http://www.ensembl.org/index.html">Ensembl</a><br />
Any good pipeline will have annotation of the details for any coding variants but it can be pretty valuable to go and look at these again by hand.
It doesn’t take long but can end up saving time in the long run.
If you do it often, the first check on Exac take less than 60 seconds.
The next check on Ensemble will only take 2-3 minutes.
In the quick search I plug in the gene name, luckily for my stuff the top hit is always the human gene (sorry Alpaca researchers).</p>

<p>When you get to the gene page first click is always “Show transcript table.”
If you are lucky there is only one coding transcript like for RAG2.
Most of the time there are about 6 transcripts of wildly varying lengths just to confuse matters.
Go for the transcript ID of the canonical transcript which you noted on Exac.
If you do so then life will be easier when you go to check the coordinates. 
On the left hand side in the table “Transcript-based displays” click “cDNA” shown under “Sequence”.
You can then search through to find the variant and amino acid to see if everything lines up.
You see the cDNA position and amino acid positions overlaid. If you were to pick a different transcript then of course the coordinates are likely to be different.
From here I usually go back to the table on the left of the screen to search Exons.
This obviously just lays out the exon sequences in blocks along with useful information.
Only a small segment of the introns are displayed.
If you want reference sequences of multiple types just find the down load sequence button and chose FASTA and decide which type you want to display.
You would likely have the information based on the annotated NGS data but you may want to look at the different transcripts and Ensembl is the best option.</p>

<p>So far (in just a couple of minutes) you could have looked up the allele frequencies, affect of mutation on different transcripts and check that everything that should be reported from the NGS output matches up.
My next step is to check if these variants a already reported.
Everyone has their favourite method, searching PubMed etc.
For my topics OMIM often produces good results and a quick search.<br />
<a href="https://www.omim.org/">Online Mendelian Inheritance in Man</a>
This is a curated database and is generally very good.
Hopefully it continues to grow for a long time into the future.
Depending on how much you already know about your gene it is sometimes helpful to jump straight down to the “Allelic variants” section (if one is present).
You may find a few variants already reported with a similar phenotype being described as your case.
You may find the exact mutations already reported.
If this is the case then it is likely that it would have taken a few minutes longer to find the same cases on one of the other databases.</p>

<p>Whether you have found that there are many mutations reported similar to those that interest you or if you have found nothing reported so far, my next step is always to run through UniProt.<br />
<a href="http://www.uniprot.org">UniProt</a><br />
UniProt is so rich in information that there is no need to expnad on it here.
If you have never used it then just pick your favourite protein and go look it up now.
There is (usually) a combination of nearly everything you need to get a quick overview of a protein.
Gene function, functional domains, known variants, reported knockouts/mutagenesis studies, protein structures, expression, localisation, the list goes on.
Actually, as much as I love PDB, I find that using UniProt is usually quicker to check for available PDB protein structures before actually going to PDB to download from the source.</p>

<p>With these four websites one would likely be able to decide how confident you are about a candidate mutation/s.
At least if you are just looking coding variants.
Assessing non-coding regions is much messier business.
From here on in validation of a mutation can require a widely variable amount of functional work.
One thing is certain however, Sanger sequencing will be needed to confirm your NGS finding.<br />
<a href="https://www.youtube.com/watch?v=3amsDkyiMu8">youtube.com</a><br />
<a href="https://github.com/gantzgraf/autoprimer3/releases/tag/v3.0.2">Autoprimer3</a></p>

<p>Autoprimer3 is an excellent application that you can use to design primers for a gene of interest.
It is super quick for producing primers to be used on genomic DNA for “any UCSC genome and design PCR/sequencing primers to genes or genome coordinates”.
As an example I timed myself to see how long it takes to get a primer list for all exons of the gene RAG2 and a reference sequence from default genomic coordinates on hg38 while avoiding SNPs based on dbsnp142.
It took me 46 seconds to open the application and produce a primer list and reference sequence.
Less than 1% of the time I may have to go and redesign a primer manually because of an awkward sequence or a patient’s DNA may have some uncommon variant at the primer site. 
Depending on which supplier you order oligos from, Sanger sequencing to confirm a variant by found during NGS can be done within 3 days; about 90 seconds to design and order the oligos, a day or 2 until they are delivered,  and a day to PCR and sequence.
The explanation may be a bit long winded here but this app is excellent.
Just give it a try if you do any routine PCR or sequencing for coding variant.
As the name suggests, it is a simple version of Primer3 but super quick.
<a href="https://software.broadinstitute.org/gatk/">Genome Analysis Toolkit: Variant Discovery in High-Throughput Sequencing Data.</a>
GATK most useful to jump straight to: <a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/">Tool Documentation Index</a> Genome hg38 <a href="http://genome.ucsc.edu/cgi-bin/das/hg38/dna?segment=chr7:142299011,142813287">(TCR region as example)</a>
<a href="https://gpgtools.org">GPGtools</a>
for sending sensitive patient info.
<a href="https://www.gnupg.org">GnuPG</a> is GPL licensed alternative to the PGP suite for sending sensitive patient info.
See also Pretty good privacy for academic data.<br />
Human splice finder <a href="http://www.umd.be/HSF3/HSF.html">http://www.umd.be/HSF3/HSF.html</a><br />
Illumina-Pipeline-V2 (“Version 2 of Illumina pipeline that incorporates <a href="https://github.com/nirav99/Illumina-Pipeline-V2/blob/master/IlluminaPipelineCASAVA1_8.pdf">CASAVA 1.8”)</a><br />
Sequence Manipulation Suite<br />
<a href="http://www.coccidia.icb.usp.br/sms2/index.html">http://www.coccidia.icb.usp.br/sms2/index.html</a><br />
Sequence Ontology <a href="http://www.sequenceontology.org">http://www.sequenceontology.org</a><br />
UCSC Genome Bioinformatics FAQ <a href="https://genome.ucsc.edu/FAQ/FAQformat">https://genome.ucsc.edu/FAQ/FAQformat</a><br />
UCSC Table Browser <a href="https://genome.ucsc.edu/cgi-bin/hgTables">https://genome.ucsc.edu/cgi-bin/hgTables</a><br />
MutScan <a href="https://github.com/OpenGene/MutScan">https://github.com/OpenGene/MutScan</a><br />
Detect and visualise target mutations by scanning FastQ files directly.
Very useful if you are interested in some certain mutations but saves the time it would take to normally through your pipeline. </p>

<h1 id="communities-and-learning">Communities and learning</h1>
<p>No need to reinvent the wheel here. Stephen Turner has a better list of resources than I will produce with his post “Staying Current in Bioinformatics &amp; Genomics: 2017 Edition.” 
http://www.gettinggeneticsdone.com/2017/02/staying-current-in-bioinformatics-genomics-2017.html<br />
Essentially it boils down to the journals, Twitter, some expert blogs, and several genomics communities.
The journals and other sites I like to follow are detailed here.
When all directed into a single feed I think it produces an essential resource for most genetics/bioinformatics scientists.
Literature of Interest - In this post I show the use of Feedly to condense all the literature that I follow into a single source and allow the option to view by category.</p>

<p>In this post I have started to gather some of the resources I like to use and topics that I find interesting.
Some other links tagged on at the end:<br />
BioStarts - Bioinformatics academic community https://www.biostars.org<br />
Useful bash Bioinformatics one-liners<br />
https://github.com/stephenturner/oneliners<br />
Efficient R programming https://csgillespie.github.io/efficientR/<br />
Cheat sheets for data.   science http://www.datasciencecentral.com/…
RStudio Cheat Sheets<br />
https://www.rstudio.com/resources/cheatsheets/#515</p>
</p>

  <h2> - </h2>
  <p><h1 id="genomic-analysis-tools">Genomic analysis tools</h1>
<p class="meta">26 Apr 2020</p>

<ul id="markdown-toc">
  <li><a href="#genomic-analysis-tools" id="markdown-toc-genomic-analysis-tools">Genomic analysis tools</a></li>
  <li><a href="#command-line-tool" id="markdown-toc-command-line-tool">command line tool</a></li>
  <li><a href="#desktop_applications" id="markdown-toc-desktop_applications">desktop_applications</a></li>
  <li><a href="#websites" id="markdown-toc-websites">Websites</a></li>
</ul>

<h1 id="command-line-tool">command line tool</h1>
<p><a href="https://github.com/virajbdeshpande/AmpliconArchitect">AmpliconArchitect</a> AmpliconArchitect is used to identify circular DNA fragments in genomic data.<br />
<a href="https://anaconda.org">Anaconda2</a> <br />
<a href="https://anaconda.org">Anaconda3</a> <br />
<a href="http://annovar.openbioinformatics.org/">annovar</a> Annotate functional consequences of genetic variation from sequencing data<br />
<a href="https://github.com/cancerit/ascatNgs">ASCAT</a> <br />
<a href="https://github.com/Crick-CancerGenomics/ascat">ASCAT</a> <br />
<a href="https://www.gnu.org/software/autoconf/autoconf.html">Autoconf</a> <br />
<a href="https://www.gnu.org/software/automake/">Automake</a> <br />
<a href="https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html">Autotools</a> <br />
<a href="https://github.com/cancerit/cgpBattenberg">Battenberg</a> <br />
<a href="https://github.com/Wedge-Oxford/battenberg">Battenberg</a> <br />
<a href="https://github.com/andyrimmer/Platypus/blob/master/extensions/DeNovo/bayesianDeNovoFilter.py">bayesianDeNovoFilter</a> <br />
<a href="http://www.htslib.org/doc/bcftools.html">bcftools</a> Utilities for variant calling and manipulating VCFs and BCFs<br />
<a href="http://bedops.readthedocs.io/">bedops</a> Toolkit that performs highly efficient and scalable Boolean and other set operations, statistical calculations, archiving, conversion and other management of genomic data.<br />
<a href="http://bedtools.readthedocs.io/">bedtools</a> Set of tools for a wide-range of genomics analysis tasks.<br />
<a href="NA">bertha</a> <br />
<a href="https://www.gnu.org/software/binutils/">binutils</a> <br />
<a href="https://www.gnu.org/software/bison/">Bison</a> <br />
<a href="ftp://ftp.ncbi.nlm.nih.gov/blast/db/">Blast</a> It searches through non-human sequence looking for bacteria/viruses.<br />
<a href="http://www.bzip.org">bzip2</a> <br />
<a href="http://github.com/Illumina/canvas">canvas</a> A tool for calling copy number variants [CNVs) from human DNA sequencing data<br />
<a href="https://github.com/opencb/cellbase/wiki">cellbase</a> A comprehensive collection of RESTful web services for retrieving relevant biological information from heterogeneous sources<br />
<a href="https://github.com/lindaszabo/KNIFE">Circular RNA analysis</a> <br />
<a href="http://bonsai.hgc.jp/%7Emdehoon/software/cluster/software.htm">cluster</a> <br />
<a href="https://github.com/abyzovlab/CNVnator">CNVnator</a> A tool for CNV discovery and genotyping from depth-of-coverage by mapped reads<br />
<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwia5f_lu93cAhUI3KQKHTZNC1kQFjABegQIAhAB&amp;url=https%3A%2F%2Fdeveloper.nvidia.com%2Fcuda-zone&amp;usg=AOvVaw2J1e7C-ir5D_lz8OgoiUKF">CUDA</a> <br />
<a href="https://developer.nvidia.com/cudnn">cuDNN</a> <br />
<a href="https://curl.haxx.se">curl</a> <br />
<a href="https://github.com/im3sanger/dndscv">dndscv</a> Ability to calculate the non-synonymous to synonymous ratio [dN/dS) in cancer to find genes under negative or positive selection.<br />
<a href="https://github.com/dotnet">dotnet</a> <br />
<a href="NA">Eagle</a> <br />
<a href="https://github.com/easybuilders/easybuild">EasyBuild</a> <br />
<a href="NA">ERDS</a> <br />
<a href="https://sites.google.com/site/bioericscript/home">Eric-script</a> <br />
<a href="https://libexpat.github.io">expat</a> <br />
<a href="https://www.bioinformatics.babraham.ac.uk/projects/fastqc/">FastQC</a> All the necessary tools for RNA-Seq analysis from raw-sequence read quality assessment, to alignment, transcript quantification, and differential expression. Also it includes analysis for gene-fusion analysis and circular RNA analysis.<br />
<a href="http://www.fftw.org">FFTW</a> <br />
<a href="https://github.com/gabraham/flashpca">flashPCA</a> flashPCA performs fast principal component analysis [PCA) of single nucleotide polymorphism [SNP) data<br />
<a href="xhttps://github.com/westes/flex">fle</a> <br />
<a href="https://www.freedesktop.org/wiki/Software/fontconfig/">fontconfig</a> <br />
<a href="https://www.freetype.org">freetype</a> <br />
<a href="https://software.broadinstitute.org/gatk/">GATK</a> Toolkit with a primary focus on variant discovery and genotyping<br />
<a href="http://gcc.gnu.org">GCC</a> <br />
<a href="https://github.com/easybuilders/easybuild-easyconfigs/tree/master/easybuild/easyconfigs/g/GCCcore">GCCcore</a> <br />
<a href="https://www.gnu.org/software/gettext/">gettext</a> <br />
<a href="https://gmplib.org">GMP</a> <br />
<a href="NA">gompi</a> <br />
<a href="http://www.brown.edu/Research/Istrail_Lab/resources/hapcompass_manual.html">hapcompass</a> A software package for haplotype assembly of diploid, polyploid, and tumor genomes<br />
<a href="https://github.com/vibansal/hapcut/blob/master/README.md">hapcut</a> A max-cut based algorithm for haplotype assembly that uses the mix of sequenced fragments from the two chromosomes of an individual<br />
<a href="https://www.gnu.org/software/help2man/">help2man</a> <br />
<a href="https://ccb.jhu.edu/software/hisat2/index.shtml">HiSAT</a> <br />
<a href="http://www.htslib.org/doc/#manual-pages">htslib</a> A C library for reading/writing high-throughput sequencing data<br />
<a href="https://www.open-mpi.org/projects/hwloc/">hwloc</a> <br />
<a href="http://mathgen.stats.ox.ac.uk/impute/impute_v2.html">impute2</a> IMPUTE version 2 [also known as IMPUTE2) is a genotype imputation and haplotype phasing program based on ideas from Howie et al. 2009<br />
<a href="https://www.ebi.ac.uk/~zerbino/velvet/">install velvet</a> It Assembles unmapped reads into longer contigs, to help identify their source.<br />
<a href="https://java.com/en/download/">java</a> <br />
<a href="https://github.com/comprna/Junckey">Junckey</a> <br />
<a href="https://pachterlab.github.io/kallisto/download.htm">Kallisto</a> <br />
<a href="http://people.virginia.edu/~wc9c/KING/manual.html">king</a> A toolset to explore genotype data from a genome-wide association study and a sequencing project<br />
<a href="https://github.com/davidaknowles/leafcutter">LeafCutter</a> <br />
<a href="http://www.libpng.org/pub/png/libpng.html">libpng</a> <br />
<a href="https://tiswww.case.edu/php/chet/readline/rltop.html">libreadline</a> <br />
<a href="https://www.gnu.org/software/libtool/">libtool</a> <br />
<a href="http://xmlsoft.org">libxml2</a> <br />
<a href="https://genome.ucsc.edu/util.html">LiftOver</a> <br />
<a href="https://github.com/arq5x/lumpy-sv/blob/master/README.md">lumpy</a> A probabilistic framework for structural variant discovery<br />
<a href="https://www.gnu.org/software/m4/m4.html">M4</a> <br />
<a href="https://majiq.biociphers.org/">MAJIQ</a> <br />
<a href="https://getmanta.com">manta</a> <br />
<a href="https://maven.apache.org">maven</a> <br />
<a href="https://bitbucket.org/uwlabmed/msings">msings</a> <br />
<a href="http://multiqc.info/docs/#manual-installation">MultiQC</a> MultiQC is a program that generates reports from the log files of common bioinformatics tools, and would be very good to have in the environment. It provides report creation, information aggregation functionalities.<br />
<a href="https://www.gnu.org/software/ncurses/">ncurses</a> <br />
<a href="https://linux.die.net/man/8/numactl">numactl</a> <br />
<a href="https://www.openblas.net">OpenBLAS</a> <br />
<a href="https://www.open-mpi.org">OpenMPI</a> <br />
<a href="https://pandoc.org/">Pandoc</a> Pandoc is a Haskell library for converting from one markup format to another, and a command-line tool that uses this library.<br />
<a href="https://www.gnu.org/software/parallel/">parallel</a> <br />
<a href="https://www.perl.org">perl</a> <br />
<a href="http://evolution.genetics.washington.edu/phylip.html">phylip</a> <br />
<a href="https://broadinstitute.github.io/picard/">picard</a> <br />
<a href="http://www.pixman.org">pixman</a> <br />
<a href="https://www.freedesktop.org/wiki/Software/pkg-config/">pkg-config</a> <br />
<a href="http://www.well.ox.ac.uk/platypus-doc">Platypus</a> A Haplotype-Based Variant Caller For Next Generation Sequence Data<br />
<a href="http://zzz.bwh.harvard.edu/plink/">PLINK</a> A whole genome association analysis toolset, designed to perform a range of basic, large-scale analyses in a computationally efficient manner<br />
<a href="https://www.python.org">python</a> <br />
<a href="https://www.r-project.org">R</a> <br />
<a href="http://rnaseq-mats.sourceforge.net/">rMATS</a> <br />
<a href="https://bioconductor.org/biocLite.R">RMySQL R package</a> <br />
<a href="https://github.com/RealTimeGenomics/rtg-tools">rtg-tools</a> Utilities for accurate VCF comparison and manipulation<br />
<a href="https://www.ruby-lang.org/en/">ruby</a> <br />
<a href="https://github.com/COMBINE-lab/salmon">Salmon</a> For direct transcript quantification from FastQ<br />
<a href="http://lomereiter.github.io/sambamba/index.html">Sambamba</a> Utilities for viewing, manipulating and merging bam files<br />
<a href="https://github.com/GregoryFaust/samblaster">samblaster</a> A tool to mark duplicates and extract discordant and split reads from sam files<br />
<a href="http://www.htslib.org/doc/samtools.html">samtools</a> Utilities for accessing and manipulating sam files<br />
<a href="https://www.osc.edu/resources/available_software/software_list/scalapack">ScaLAPACK</a> <br />
<a href="http://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html">SHAPEIT2</a> SHAPEIT is a fast and accurate method for estimation of haplotypes [aka phasing) from genotype or sequencing data.<br />
<a href="https://github.com/alexdobin/STAR">STAR</a> <br />
<a href="https://github.com/STAR-Fusion/STAR-Fusion/wiki">STAR-fusion</a> <br />
<a href="https://github.com/comprna/SUPPA">SUPPA</a> <br />
<a href="https://tug.org/texlive/">texlive</a> <br />
<a href="https://github.com/vcflib/vcflib/blob/master/README.md">vcflib</a> A C++ library for parsing and manipulating VCF files<br />
<a href="https://vcftools.github.io/index.html">vcftools</a> A program package designed for working with VCF files<br />
<a href="https://github.com/Ensembl/ensembl-vep">vep</a> Determines the effect of variants [SNPs, insertions, deletions, CNVs or structural variants) on genes, transcripts, and protein sequence, as well as regulatory regions<br />
<a href="https://github.com/statgen/verifyBamID/releases">verifybamid</a> <br />
<a href="http://www.lstmed.ac.uk/vtbuilder">vt</a> A tool for the inference of non-chimeric contigs from read data that has been sequenced from complex multi-isoformic transcriptomes<br />
<a href="NA">weCall</a> <br />
<a href="https://tukaani.org/xz/">xz</a> <br />
<a href="https://www.zlib.net">zlib</a></p>
<h1 id="desktop_applications">desktop_applications</h1>
<p><a href="https://atom.io/packages/atom-ide-ui">atom-ide-ui</a> <br />
<a href="xhttps://www.mozilla.org/en-US/firefox/new/">Firefo</a> <br />
<a href="https://atom.io/packages/ide-python">ide-python</a> requires server https://github.com/palantir/python-language-server<br />
<a href="https://www.libreoffice.org">LibreOffice</a> <br />
<a href="https://www.rstudio.com">RStudio</a></p>
<h1 id="websites">Websites</h1>
<p><a href="www.ncbi.nlm.nih.gov/clinvar/*">ClinVar</a> www.ncbi.nlm.nih.gov/clinvar/<br />
<a href="compbio.charite.de/hpoweb/*">Compbio HPO Browser</a> http://compbio.charite.de/hpoweb/<br />
<a href="www.ncbi.nlm.nih.gov/CCDS/*">Consensus CDS Project</a> www.ncbi.nlm.nih.gov/CCDS/<br />
<a href="cancer.sanger.ac.uk/wgs/*">COSMIC</a> http://cancer.sanger.ac.uk/cosmic/<br />
<a href="www.ncbi.nlm.nih.gov/snp/*">DBsnp</a> www.ncbi.nlm.nih.gov/snp/<br />
<a href="decipher.sanger.ac.uk/*">DECIPHER</a> http://decipher.sanger.ac.uk/<br />
<a href="www.ebi.ac.uk/*">EMBL EBI</a> www.ebi.ac.uk/<br />
<a href="www.ebi.ac.uk/interpro/*">EMBL EBI</a> <br />
<a href="www.ebi.ac.uk/wen_guidelines/*">EMBL EBI</a> <br />
<a href="static.ensembl.org/*">Ensembl</a> <br />
<a href="static.ensembl.org/minified/*">Ensembl</a> <br />
<a href="www.ensembl.org/id/*">Ensembl</a> <br />
<a href="ensembl.org/*">Ensembl Human</a> http://ensembl.org/Homo_sapiens/<br />
<a href="ensembl.org/Homo_sapiens/Gene/*">Ensembl Human</a> <br />
<a href="ensembl.org/Homo_sapiens/*">Ensembl Human</a> <br />
<a href="http://exac.broadinstitute.org">exAC Browser beta</a> http://exac.broadinstitute.org<br />
<a href="ghr.nlm.nih.gov/*">Genetics Home Reference Gene Browser</a> http://ghr.nlm.nih.gov/gene<br />
<a href="ghr.nlm.nih.gov/gene/*">Genetics Home Reference Gene Browser</a> <br />
<a href="ghr.nlm.nih.gov/images/*">Genetics Home Reference Gene Browser</a> <br />
<a href=".incoming01.genomicsplc.com">Genomics Plc Misc.</a> <br />
<a href="http://gnomad.broadinstitute.org">gnomAD Browser beta</a> http://gnomad.broadinstitute.org<br />
<a href="www.gstatic.com/charts/*">Google Misc.</a> <br />
<a href="www.genenames.org/*">HUGO Gene Nomenclature Committee</a> http://www.genenames.org/<br />
<a href="www.genenames.org/data/*">HUGO Gene Nomenclature Committee</a> <br />
<a href="www.genenames.org/sites/*">HUGO Gene Nomenclature Committee</a> <br />
<a href="www.genenames.org/css/*">HUGO Gene Nomenclature Committee</a> <br />
<a href="www.genenames.org/js/*">HUGO Gene Nomenclature Committee</a> <br />
<a href="rest.genenames.org/*">HUGO Gene Nomenclature Committee</a> <br />
<a href="www.human-phenotype-ontology.org/hpoweb/*">Human Phenotype Ontology</a> http://compbio.charite.de/hpoweb/showterm<br />
<a href="www.human-phenotype-ontology.org/*">Human Phenotype Ontology</a> <br />
<a href="human-phenotype-ontology.github.io/*">Human Phenotype Ontology</a> <br />
<a href="igv.broadinstitute.org/*">IGV Browser</a> <br />
<a href="igvdata.broadinstitute.org/*">IGV Browser</a> <br />
<a href="www.ncbi.nlm.nih.gov/portal*">NCBI</a> www.ncbi.nlm.nih.gov/portal<br />
<a href="www.nlm.nih.gov/core/*">NCBI</a> <br />
<a href=".nlm.nih.gov/*">NCBI</a> <br />
<a href="www.ncbi.nlm.nih.gov/gtr/tests/*">NCBI</a> <br />
<a href="www.ncbi.nlm.nih.gov/core/*">NCBI</a> <br />
<a href="www.ncbi.nlm.nih.gov/project/*">NCBI</a> <br />
<a href="www.ncbi.nlm.nih.gov/gene*">NCBI Gene</a> www.ncbi.nlm.nih.gov/gene<br />
<a href="www.ncbi.nlm.nih.gov/nuccore/*">NCBI Nucleotide</a> www.ncbi.nlm.nih.gov/nuccore/<br />
<a href="omim.org/*">OMIM</a> http://omim.org<br />
<a href="omim.org/entry/*">OMIM</a> <br />
<a href="omim.org/static/*">OMIM</a> <br />
<a href="omim.org/search/*">OMIM</a> <br />
<a href="api.europe.omim.org/api/*">OMIM</a> <br />
<a href="https://panelapp.genomicsengland.co.uk/">Panelapp</a> https://panelapp.genomicsengland.co.uk/<br />
<a href="static.pubmed.gov/*">Pubmed</a> www.ncbi.nlm.nih.gov/pubmed/<br />
<a href="www.ncbi.nlm.nih.gov/pubmed/*">Pubmed</a> <br />
<a href="dev-static.pubmed.gov/*">Pubmed</a> <br />
<a href="cancer.sanger.ac.uk/_asset/*">Sanger</a> <br />
<a href="cancer.sanger.ac.uk/cancergenome/*">Sanger</a> <br />
<a href="cancer.sanger.ac.uk/javascripts/*">Sanger</a> <br />
<a href="cancer.sanger.ac.uk/cosmic/*">Sanger</a> <br />
[SMART <a href="smart.embl-heidelberg.de/*">a Simple Modular Architecture Research Tool)</a> http://smart.embl-heidelberg.de<br />
<a href="https://www.sib.swiss/*">Swiss Institute of Bioinformatics</a> https://www.sib.swiss<br />
<a href="www.hgmd.cf.ac.uk/ac/*">The Human Gene Mutation Database</a> www.hgmd.cf.ac.uk<br />
<a href="www.hgmd.cf.ac.uk/*">The Human Gene Mutation Database</a> <br />
<a href="www.sequenceontology.org/miso/current_release/term/*">The Sequence Ontology  database</a> www.sequenceontology.org/<br />
<a href="www.sequenceontology.org/css/*">The Sequence Ontology  database</a> <br />
<a href="www.sequenceontology.org/js/*">The Sequence Ontology  database</a> <br />
<a href="www.sequenceontology.org/img/*">The Sequence Ontology  database</a> <br />
<a href="www.sequenceontology.org/browser/*">The Sequence Ontology  database</a> <br />
<a href="www.sequenceontology.org/*">The Sequence Ontology  database</a> <br />
<a href="www.genome.ucsc.edu/*">UCSC Genome Browser</a> <br />
[Xfam <a href="pfam.sanger.ac.uk/family/*">Pfam, Rfam, Dfam, Treefam, iPfam, Antifam)</a> http://xfam.org<br />
[Xfam <a href="pfam.sanger.ac.uk/*">Pfam, Rfam, Dfam, Treefam, iPfam, Antifam)</a> <br />
[Xfam <a href="xfam.org/*">Pfam, Rfam, Dfam, Treefam, iPfam, Antifam)</a></p>
</p>

  <h2> - </h2>
  <p><h1 id="genome-wide-assocciation-study">Genome wide assocciation study</h1>

<ul id="markdown-toc">
  <li><a href="#genome-wide-assocciation-study" id="markdown-toc-genome-wide-assocciation-study">Genome wide assocciation study</a></li>
  <li><a href="#abbreviations" id="markdown-toc-abbreviations">Abbreviations</a></li>
  <li><a href="#very-basic-overview" id="markdown-toc-very-basic-overview">Very basic overview</a></li>
  <li><a href="#benefits-and-limitations-of-genome-wide-association-studies" id="markdown-toc-benefits-and-limitations-of-genome-wide-association-studies">Benefits and limitations of genome-wide association studies</a></li>
  <li><a href="#sample-collection-and-genotyping" id="markdown-toc-sample-collection-and-genotyping">Sample collection and genotyping</a></li>
  <li><a href="#pre-imputation" id="markdown-toc-pre-imputation">Pre-imputation</a></li>
  <li><a href="#imputation" id="markdown-toc-imputation">Imputation</a>    <ul>
      <li><a href="#file-formats" id="markdown-toc-file-formats">File formats</a></li>
      <li><a href="#imputation-services" id="markdown-toc-imputation-services">Imputation services</a></li>
    </ul>
  </li>
  <li><a href="#information-score" id="markdown-toc-information-score">Information score</a></li>
  <li><a href="#get-snptest-summary-with-impute-information-score" id="markdown-toc-get-snptest-summary-with-impute-information-score">Get snptest summary with impute information score¬</a></li>
  <li><a href="#imputation-to-plink-format" id="markdown-toc-imputation-to-plink-format">Imputation to Plink format</a></li>
  <li><a href="#quality-control" id="markdown-toc-quality-control">Quality control</a>    <ul>
      <li><a href="#relatedness" id="markdown-toc-relatedness">Relatedness</a></li>
      <li><a href="#missingness" id="markdown-toc-missingness">Missingness</a></li>
      <li><a href="#genotype" id="markdown-toc-genotype">Genotype</a></li>
      <li><a href="#hwe" id="markdown-toc-hwe">HWE</a></li>
    </ul>
  </li>
  <li><a href="#phenotypes-and-covariates" id="markdown-toc-phenotypes-and-covariates">Phenotypes and covariates</a></li>
  <li><a href="#pca" id="markdown-toc-pca">PCA</a></li>
  <li><a href="#biological-interpretation" id="markdown-toc-biological-interpretation">Biological interpretation</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#command-line-example-code" id="markdown-toc-command-line-example-code">Command line example code</a></li>
</ul>

<h1 id="abbreviations">Abbreviations</h1>
<p>BWA (Burrows-Wheeler transformation aligner), 
GrCh38 (Genome Reference Consortium Human Build 38), 
VCF (variant call format).</p>

<h1 id="very-basic-overview">Very basic overview</h1>
<p>Genomewide Association Studies and Assessment of the Risk of Disease, <a href="https://www.nejm.org/doi/full/10.1056/NEJMra0905980">Manolio N Engl J Med 2010.</a></p>
<h1 id="benefits-and-limitations-of-genome-wide-association-studies">Benefits and limitations of genome-wide association studies</h1>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/31068683/">Tam et al. 2019</a>
<a href="https://www.gwern.net/docs/genetics/heritable/2019-tam.pdf">pdf</a></p>

<h1 id="sample-collection-and-genotyping">Sample collection and genotyping</h1>
<p>A good paper on the “Basic statistical analysis in genetic case-control studies” by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3154648/">Clarke et al. 2011</a>.
Genomic control: [wiki](https://en.wikipedia.org/wiki/Population_structure_(genetics)</p>

<h1 id="pre-imputation">Pre-imputation</h1>
<p>Before imputation with study genotypes, filter the data to remove low-quality variants and samples. 
Standard GWAS quality control filters are usually sufficient to prepare a dataset for imputation. 
It may also help to add an imputation-based QC step to the filtering process.</p>

<p><a href="https://academic.oup.com/bfg/article/15/4/298/2412127">Coleman et al. 2016</a></p>

<h1 id="imputation">Imputation</h1>

<h2 id="file-formats">File formats</h2>
<p>The file format required depends on the method chosen.
VCF file is the most common input type (e.g. Sanger imputation).
Plink format files (bim, bed, fam, or pgen, psam ) can be converted to VCF using Plink.
VCF may be converted to a gen file (e.g. Impute2).</p>

<p><strong>Example</strong>
Plink binary files to VCF.
https://www.cog-genomics.org/plink/1.9</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plink <span class="nt">--bfile</span> binary_fileset <span class="nt">--recode</span> vcf <span class="nt">--out</span> new_vcf
</code></pre></div></div>

<h2 id="imputation-services">Imputation services</h2>
<p>Online: Sanger Imputation server
<a href="https://www.sanger.ac.uk/tool/sanger-imputation-service/">sanger.ac.uk</a>
is a genotype imputation and phasing service provided by the Wellcome Sanger Institute. 
You can upload GWAS data in VCF or 23andMe format and receive imputed and phased genomes back. 
Optional pre-phasing is with EAGLE2 or SHAPEIT2 and imputation is with PBWT into a choice of reference panels including 1000 Genomes Phase 3, UK10K, and the Haplotype Reference Consortium.</p>

<p>Online: Michigan Imputation Server
<a href="https://imputationserver.sph.umich.edu/index.html#!">imputationserver.sph.umich.edu</a>
based on 
<a href="https://pubmed.ncbi.nlm.nih.gov/27571263/">Foreret al. 2016</a>
.
Open source, offers methods to build your own server.
Reference panels: 
HapMap Release 2.
1000 Genomes,
Phase 1 and 3,
CAAPA,
African American,
Haplotype Reference Consortium.</p>

<p>Local software: IMPUTE version 2 (also known as IMPUTE2) is a genotype imputation and haplotype phasing program based on ideas from 
<a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1000529">Howie et al. 2009</a>
but has features from additional publications.
From Impute2, the process is summed up as “the most common scenario in which imputation is used: 
unobserved genotypes (red question marks) in a set of study individuals are imputed (or predicted) using a set of reference haplotypes and genotypes from a SNP chip.</p>

<h1 id="information-score">Information score</h1>
<p>Since the imputation non-genotyped variants is based on a reference panel that
may not fully represent the ancestry of a study cohort, a quality score may be 
desired.
One tool is SNPTEST
<a href="https://mathgen.stats.ox.ac.uk/genetics_software/snptest/snptest.html#info_measures">mathgen.stats.ox.ac.uk</a>.
From mathgen.stats.ox.ac.uk, the IMPUTE info measure reflects the information in imputed genotypes relative to the information if only the allele frequency were known.</p>

<p>[\text{info} = 1 - \text{mean} (
\frac {
\text{ variance in imputed genotype} }
{ \text{variance if only allele frequency were known} }
)]</p>

<p>The numerator of this expression is computed over the imputed genotype distribution for each sample. The denominator is computed using the estimated allele frequency</p>

<p>[\theta = \sum_{i} 
\frac{
P(g_{i}=1)+2P(g_{i}=2)) }
{2\sum_{i,g}P(g_{i}=g) }]</p>

<p>and the assumption of Hardy-Weinberg equilibrium.
The info measure takes the value 1 if all genotypes are completely certain, 
and the value 0 if the genotype probabilities for each sample are completely uncertain in Hardy-Weinberg proportions 
(i.e. they equal
\((1-\theta)^{2}, 2\theta(1-\theta), \theta^{2}).\)
It is also possible for info to drop below zero.</p>

<p>Info is usually computed as if assuming all samples are diploid and that the genotype probabilities for each sample sum to one. This is what IMPUTE computes, and also what SNPTEST computes when you use a method other than newml.
Haploid samples, e.g. for males on the X chromosome, will be treated a little differently.
This can be done with -method newml (maximum likelihood test). 
Discussion is not warrented here but can be read at
<a href="https://mathgen.stats.ox.ac.uk/genetics_software/snptest/snptest.html#info_measures">snptest measures</a> and
<a href="https://mathgen.stats.ox.ac.uk/genetics_software/snptest/snptest.v2.pdf">snptest.v2.pdf</a>.</p>

<h1 id="get-snptest-summary-with-impute-information-score">Get snptest summary with impute information score¬</h1>
<p>Here is an example of a script that might get this value for all genotype files.
The cohort of 1,000 individuals may have data split into 22 files (one per chromosome),
and each chromosome split into managable sizes of 100,000 SNPs giving maybe 600 individual files in the format:
Chr1.pos10024053-15008865.impute2.
The input -data files will be (1) the genotype gen file and (2) the sample list.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use 22 cores to run in parallel</span>
<span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..22<span class="o">}</span>
<span class="k">do
for </span>file <span class="k">in </span>Chr<span class="nv">$i</span>.<span class="k">*</span>impute2
<span class="k">do</span>
›   ~/tool/snptest_v2.5.4-beta3_<span class="se">\</span>
linux_x86_64_dynamic/snptest_v2.5.4-beta3 <span class="se">\</span>
›   <span class="nt">-data</span> <span class="nv">$file</span> <span class="se">\</span>
›   Samples_IDs <span class="se">\</span>
›   <span class="nt">-filetype</span> gen <span class="se">\</span>
›   <span class="nt">-summary_stats_only</span> <span class="se">\</span>
›   <span class="nt">-o</span> <span class="nv">$file</span><span class="se">\_</span>snptest
<span class="k">done</span> &amp;
<span class="k">done
</span><span class="nb">wait</span>
</code></pre></div></div>
<p>The output might look something like this (with only 4 columns shown - the real output would have much more information).
A threshold will be set to decide what quality will be used for your analysis, 
e.g. &gt;0.7.</p>

<table>
  <thead>
    <tr>
      <th>chr</th>
      <th>rsid</th>
      <th>position</th>
      <th>A1</th>
      <th>A2</th>
      <th>info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>rs70998334</td>
      <td>10027728</td>
      <td>T</td>
      <td>TA</td>
      <td>0.990047</td>
    </tr>
    <tr>
      <td>1</td>
      <td>rs191096997</td>
      <td>10027884</td>
      <td>A</td>
      <td>G</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<h1 id="imputation-to-plink-format">Imputation to Plink format</h1>
<p>File formats output</p>

<h1 id="quality-control">Quality control</h1>
<h2 id="relatedness">Relatedness</h2>
<h2 id="missingness">Missingness</h2>
<h2 id="genotype">Genotype</h2>
<h2 id="hwe">HWE</h2>

<h1 id="phenotypes-and-covariates">Phenotypes and covariates</h1>

<h1 id="pca">PCA</h1>

<h1 id="biological-interpretation">Biological interpretation</h1>

<h1 id="conclusion">Conclusion</h1>

<h1 id="command-line-example-code">Command line example code</h1>
<p><strong>Whole exome analysis</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

</code></pre></div></div>
</p>

  <h2> - </h2>
  <p><h1 id="pharmacogenomics-for-personal-medicine">Pharmacogenomics for personal medicine</h1>
<p class="meta">26 Apr 2020</p>

<ul id="markdown-toc">
  <li><a href="#pharmacogenomics-for-personal-medicine" id="markdown-toc-pharmacogenomics-for-personal-medicine">Pharmacogenomics for personal medicine</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#preparing-an-example-vcf" id="markdown-toc-preparing-an-example-vcf">Preparing an example VCF</a></li>
  <li><a href="#comparing-annotated-genetic-data-to-drug-lists" id="markdown-toc-comparing-annotated-genetic-data-to-drug-lists">Comparing annotated genetic data to drug lists</a>    <ul>
      <li><a href="#small-example-check-of-gene-list-versus-drug-gene-list" id="markdown-toc-small-example-check-of-gene-list-versus-drug-gene-list">Small example check of gene list versus drug-gene list</a></li>
    </ul>
  </li>
  <li><a href="#a-real-example-of-merging-genetic-and-pharmacogenomic-data" id="markdown-toc-a-real-example-of-merging-genetic-and-pharmacogenomic-data">A real example of merging genetic and pharmacogenomic data</a></li>
  <li><a href="#drug-indication" id="markdown-toc-drug-indication">Drug indication</a></li>
  <li><a href="#annotation" id="markdown-toc-annotation">Annotation</a>    <ul>
      <li><a href="#optimising-vcf-annotation" id="markdown-toc-optimising-vcf-annotation">Optimising VCF annotation</a></li>
      <li><a href="#how-to-get-coordinates-for-a-gene-list" id="markdown-toc-how-to-get-coordinates-for-a-gene-list">How to get coordinates for a gene list</a></li>
      <li><a href="#extracting-regions-from-a-vcf-using-a-bed-file" id="markdown-toc-extracting-regions-from-a-vcf-using-a-bed-file">Extracting regions from a VCF using a bed file</a></li>
    </ul>
  </li>
  <li><a href="#unknown-variants" id="markdown-toc-unknown-variants">Unknown variants</a></li>
  <li><a href="#gene-dosage" id="markdown-toc-gene-dosage">Gene dosage</a></li>
  <li><a href="#drug-indication-1" id="markdown-toc-drug-indication-1">Drug indication</a></li>
  <li><a href="#a-large-scale-example-summary" id="markdown-toc-a-large-scale-example-summary">A large scale example summary</a></li>
  <li><a href="#funding-strategy" id="markdown-toc-funding-strategy">Funding strategy</a></li>
  <li><a href="#legal-requirements" id="markdown-toc-legal-requirements">Legal requirements</a></li>
  <li><a href="#more-questions" id="markdown-toc-more-questions">More questions</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h1 id="introduction">Introduction</h1>
<p>With the popularisation of commercial genetics services, more and more people are now able to “decode” their genetic data.
Questions that might arise from this information include “do I have potentially disease-causing variants that can be treated with a drug?”, or “am I taking a drug that will be affected by my genetics?”.
To tackle such questions with an example, we use public data in combination with pharmacogenomics.
Outside of genotype data (offered by <a href="https://www.23andme.com">23andMe</a> for example), the most common file type will be VCF:
<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format">What is a vcf and how should I interpret it?</a>.</p>

<p>As an example input, try download Craig Venter’s genome VCF:
<a href="ftp://ftp.ensembl.org/pub/release-75/variation/vcf/homo_sapiens/Venter.vcf.gz">ftp://ftp.ensembl.org/pub/release-75/variation/vcf/homo_sapiens/Venter.vcf.gz</a>.</p>

<p>When I wrote this post, I used a data source with different genetic data files;
<a href="https://my.pgp-hms.org/public_genetic_data">https://my.pgp-hms.org/public_genetic_data</a>.
To check that it works OK, I tried a quick version of this challenge.
I picked the first whole genome VCF file that I saw (hu24385B 2019-04-07.vcf.g_z)
<a href="https://my.pgp-hms.org/profile/hu24385B">https://my.pgp-hms.org/profile/hu24385B</a>. 
The VCF has 3,461,639 variants.
VCF files can contain a large range of information for each variant, however only the first 7 column are strictly neccessary; Chromosome, position, ID, Reference, Alternate, Qulaity, Filter, info. 
<a href="https://gatkforums.broadinstitute.org/gatk/discussion/1268/what-is-a-vcf-and-how-should-i-interpret-it">The details are explained on this GATK forum post</a>.
Annotation information about the gene name (or related diseases) is often not present when the VCF is generated and only added later.
Therefore the most common input source may be lacking gene symbols.
To get the gene names of a single file, the simplest way was is to upload a VCF (or a part of it) to <a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/">Variant Effect Predictor</a> to get the gene symbol (and any other information that you wish).</p>

<p><img src="https://dylanlawlessblog.files.wordpress.com/2019/05/screenshot-2019-05-07-at-17.01.45.png" width="100%" /></p>

<p><img src="https://dylanlawlessblog.files.wordpress.com/2019/05/screenshot-2019-05-07-at-17.01.58.png" width="100%" /></p>

<p>To reduce the time and output you can limit the options.
Split the file and run in batches to save time.
Here I tried the first ~1800 variants.</p>

<p><br />
<code class="language-plaintext highlighter-rouge">head -2000 56001801068861_WGZ.snp.vcf &gt; test.vcf</code></p>

<p><br />
And then annotated that extract with <a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/">Variant Effect Predictor.</a>
The results would be retained by a URL address such as this, for a few days, but will be deleted by the time your read this.<br />
<br />
<a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/Results?db=core;tl=jNYYW5ONeVFYnaMM-5265700">http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/Results?db=core;tl=jNYYW5ONeVFYnaMM-5265700</a> <br />
<br />
<img src="https://dylanlawlessblog.files.wordpress.com/2019/05/screenshot-2019-05-07-at-17.01.10.png" width="100%" /><br />
<br />
Make certain that you use the same reference genome as used on the input data.
The VCF file was made using reference genome GRCh37.
Therefore the Ensembl/VEP website URL should be for that genome build (grch37, not the default GRCh38).</p>

<h1 id="preparing-an-example-vcf">Preparing an example VCF</h1>
<p>If you would like to try this using a whole genome using the Ensembl web 
interface you will need to split your VCF into smaller block first.
For routine usage the command-line version of VEP and it’s databases should be 
installed on run locally.
There are several bioinformatics tools that are commonly used for manipulating 
genetic file formats such as VCFtools. 
To get a real understanding of the data type, I inlcude here a method using 
command line bash to split a VCF file into smaller blocks. 
A bash script is printed below where I use very mainstream traditional 
command-line tools to wrangle data, including 
<a href="https://en.wikipedia.org/wiki/Gzip">gunzip</a>
to unzip compressed files, 
<a href="https://en.wikipedia.org/wiki/wc_(Unix)">wc</a>
to count lines, 
<a href="https://en.wikipedia.org/wiki/Cat_(Unix)">cat</a>
to print a file, 
<a href="https://en.wikipedia.org/wiki/Head_(Unix)">head</a>
to read the top of a file, 
<a href="https://en.wikipedia.org/wiki/Sed">sed</a>
to edit lines, 
<a href="https://en.wikipedia.org/wiki/AWK">awk</a>
for data extraction, and
<a href="https://en.wikipedia.org/wiki/Grep">grep</a>
which is not used here but it fits well with these other tools - for text search.
Creating a file containing the code below and ending with the filename extension with “.sh” will allow it to be run by your terminal, in this case using the bash language.
I encourage you to read each line and figure out what should happen. If it makes sense then it is reasonable to swap such a manual method with a more efficient specialised tool.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c"># VEP accept files of &lt;50MB size.</span>
<span class="c"># We will split our large VCF into smaller files.</span>
<span class="c"># Each file requires the same original </span>
<span class="c"># headers and file extension ".vcf"</span>

<span class="c"># Unzip the VCF.gz</span>
<span class="nb">gunzip </span>56001801068861_WGZ.snp.vcf.gz

<span class="c"># Count the number of lines in vcf</span>
<span class="nb">wc</span> <span class="nt">-l</span> 56001801068861_WGZ.snp.vcf

<span class="c"># How should a vcf file look?</span>
<span class="c"># See the links posted in this tutorial above</span>

<span class="c"># Take a look at the header</span>
<span class="c"># This VCF has 140 lines of header metadata (beginning with "#")</span>
<span class="c"># Line 141 shows the column headers: CHROM	POS	ID	REF	ALT...</span>
<span class="c"># Line 142 starts with the first variant</span>
<span class="nb">head</span> <span class="nt">-142</span> 56001801068861_WGZ.snp.vcf

<span class="c"># Print the header to a new file for later</span>
<span class="nb">head</span> <span class="nt">-141</span> 56001801068861_WGZ.snp.vcf <span class="o">&gt;</span> header
<span class="c"># Print everything else (the body) to </span>
<span class="c"># a new file that we will then split.</span>
<span class="nb">sed</span> <span class="s1">'1,141d'</span> 56001801068861_WGZ.snp.vcf <span class="o">&gt;</span> body.vcf

<span class="c"># Make a new directory for the next step</span>
<span class="nb">mkdir </span>split_files
<span class="c"># Move the large file inside</span>
<span class="nb">mv </span>body.vcf split_files/
<span class="nb">cd </span>split_files
<span class="c"># Now split the body.vcf into smaller </span>
<span class="c"># files of 200,000 lines each</span>
<span class="nb">split</span> <span class="nt">-l</span> 150000 body.vcf

<span class="c"># You will now how ~10 files "xaa, xab, etc."</span>
<span class="c"># Add the header back onto all of these files to make them VCFs again.</span>
<span class="c"># This "for loop" will do the following for each file:</span>
<span class="c"># Print the header and the vcf body to </span>
<span class="c"># a file with the same name, </span>
<span class="c"># adding a file extension ".vcf".</span>
<span class="c"># Then remove the vcf body file that </span>
<span class="c"># does not have the ".vcf" extension</span>
<span class="c"># leaving you with the original whole genome VCF split</span>
<span class="c"># into smaller files, each with the same headers.</span>

<span class="k">for </span>file <span class="k">in</span> ./x<span class="k">*</span> <span class="p">;</span> 
    <span class="k">do </span><span class="nb">cat</span> ../header <span class="nv">$file</span> <span class="o">&gt;&gt;</span> <span class="nv">$file</span>.vcf <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nv">$file</span> <span class="p">;</span>
<span class="k">done</span>

<span class="c"># These should be small enough to run on VEP online.</span>
<span class="c"># You could edit the split command to make a </span>
<span class="c"># reasonable number of files, </span>
<span class="c"># uploading &gt;10 is not efficient.</span>

</code></pre></div></div>

<h1 id="comparing-annotated-genetic-data-to-drug-lists">Comparing annotated genetic data to drug lists</h1>
<p>Uploading either a small example or your split-whole-genome example, VEP will process the data and annotate it will whatever features you require, including gene names, variant consequence, pahtnogenicy prediction, etc.
The next aim will be to see if any of your output genes are also present in your drug-gene database.
The method will require merging both dataset (gene and drug datasets) based on shared features. 
A simple sanity test would be useful first:</p>

<h2 id="small-example-check-of-gene-list-versus-drug-gene-list">Small example check of gene list versus drug-gene list</h2>
<p>From the VEP output I extracted the gene symbols column and compared against a list of druggable target genes from 
<a href="https://www.drugbank.ca">DrugBank</a> 
(because I happen to have their data on hand, FDA may be more reliable).
I used another command-line method to do this efficienctly:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cut</span> <span class="nt">-f1</span> <span class="nt">-d</span> <span class="s2">","</span> vep_output_file.csv | <span class="nb">uniq</span> <span class="o">&gt;</span> unique.genes.txt
</code></pre></div></div>

<ul>
  <li>Cut column 1 (f1)</li>
  <li>with a delimiter comma (,)</li>
  <li>from the vep output csv file (or tsv, or text file)</li>
  <li>then pipe (|) that result into another program (sort) to sort the result in alphabetic order</li>
  <li>pipe (|) again this result into(uniq)</li>
  <li>so that only one unique gene name is output</li>
  <li>then (&gt;) write the output into the new file “unique.genes.txt”.<br />
<br />
Repeat the same type of method on the DrugBank dataset to get a list of the gene names contained in DrugBank into a file called “unique.druggable.txt”
The next command will then compare both lists.
<br /></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sort </span>unique.genes.txt unique.druggable.txt | <span class="nb">uniq</span> <span class="nt">-c</span> <span class="nt">-i</span> | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'1 '</span>
</code></pre></div></div>

<p>This command also used “uniq -c” to count how many times each gen name occurs and then “grep -v ‘1 ‘” meaning ignore genes that are only present 1 time. 
We want the genes that are present twice, once in each list.
The genes which were in present in both the variant list and DrugBank list are:
From a 2,000 line VCF file:
<a href="https://www.drugbank.ca/bio_entities/BE0003599">GABRD</a>,
<a href="https://www.drugbank.ca/bio_entities/BE0004895">PRKCZ</a>,
<a href="https://www.drugbank.ca/bio_entities/BE0000495">SCNN1D</a><br />
From a 10,000 VCF line file = 
<a href="https://www.drugbank.ca/bio_entities/BE0003599">GABRD</a>,
<a href="https://www.drugbank.ca/bio_entities/BE0004895">PRKCZ</a>,
<a href="https://www.drugbank.ca/bio_entities/BE0000495">SCNN1D</a>,
<a href="https://www.drugbank.ca/bio_entities/BE0008994">TP73</a>.</p>

<h1 id="a-real-example-of-merging-genetic-and-pharmacogenomic-data">A real example of merging genetic and pharmacogenomic data</h1>
<p>Now that a small example has shown us the logic of the process, we can try a more complex real-world example. 
The following R language script is used to merge the VEP annotated VCF file with a DrugBank database based on the gene names that are common to both datasets.
Read each line and try to understand the process. 
The are many alternative ways to do the same thing in different programming languages. 
This example is done using R. 
I recommending installing R and then installing R studio to edit and run your commands.</p>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Comment lines are ignored because of "#" symbol.</span><span class="w">
</span><span class="c1"># Command lines are run by clicking "Run" or "command+enter" on Mac</span><span class="w">

</span><span class="c1"># csv = comma sep file</span><span class="w">
</span><span class="c1"># tsv = tab spaced</span><span class="w">
</span><span class="c1"># txt = white space</span><span class="w">

</span><span class="c1">#///////////////////////////////</span><span class="w">
</span><span class="c1"># To do</span><span class="w">
</span><span class="c1">#///////////////////////////////</span><span class="w">
</span><span class="c1"># Files: vepfile, drugs</span><span class="w">
</span><span class="c1"># merge based on Gene symbol</span><span class="w">

</span><span class="c1">#///////////////////////////////</span><span class="w">
</span><span class="c1"># import the VEP file</span><span class="w">
</span><span class="c1">#///////////////////////////////</span><span class="w">

</span><span class="c1"># Important note:</span><span class="w">
</span><span class="c1"># The VEP file will start with a header line </span><span class="w">
</span><span class="c1"># that begins with "#" symbol. But this is being ignored by R.</span><span class="w">
</span><span class="c1"># Open the file with text edit and remove that symbol.</span><span class="w">
</span><span class="c1"># Maybe there is an R command to do this on import, whatever is faster.</span><span class="w">

</span><span class="c1"># Split vcf into ~ 10 files. </span><span class="w">
</span><span class="c1"># file 1 "xaa" was anylised on VEP, </span><span class="w">
</span><span class="c1"># download the TXT version, </span><span class="w">
</span><span class="c1"># or unzip my provided example one - cfKJCLRm0eKXsaEG.txt.zip</span><span class="w">
</span><span class="c1"># https://grch37.ensembl.org/Homo_sapiens/Tools/VEP/</span><span class="w">

</span><span class="c1"># Import the VEP output</span><span class="w">
</span><span class="n">vepfile</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.table</span><span class="p">(</span><span class="w">
  </span><span class="n">file</span><span class="o">=</span><span class="s2">"cfKJCLRm0eKXsaEG.txt"</span><span class="p">,</span><span class="w">
  </span><span class="n">na.strings</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span><span class="w"> </span><span class="s2">"NA"</span><span class="p">),</span><span class="w">
  </span><span class="n">sep</span><span class="o">=</span><span class="s2">"\t"</span><span class="p">,</span><span class="w">
  </span><span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">

</span><span class="c1"># Import drugbank table</span><span class="w">
</span><span class="c1"># the "fill=TRUE" is needed because not all </span><span class="w">
</span><span class="c1"># file lines have the same number of elements.</span><span class="w">
</span><span class="n">drugs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.table</span><span class="p">(</span><span class="w">
  </span><span class="n">file</span><span class="o">=</span><span class="s2">"all.txt"</span><span class="p">,</span><span class="w">
  </span><span class="n">na.strings</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span><span class="w"> </span><span class="s2">"NA"</span><span class="p">),</span><span class="w">
  </span><span class="n">sep</span><span class="o">=</span><span class="s2">"\t"</span><span class="p">,</span><span class="w">
  </span><span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
  </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="w"> </span><span class="p">)</span><span class="w">


</span><span class="c1"># We can merge these two files based on 1 common column.</span><span class="w">
</span><span class="c1"># However, the gene name column does not have the same name.</span><span class="w">
</span><span class="c1"># One of them needs to be renamed:</span><span class="w">
</span><span class="c1"># vepfile="SYMBOL"</span><span class="w">
</span><span class="c1"># drugs="Gene.Name"</span><span class="w">

</span><span class="c1"># colnames(df)[colnames(df) == 'oldName'] &lt;- 'newName'</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">vepfile</span><span class="p">)[</span><span class="n">colnames</span><span class="p">(</span><span class="n">vepfile</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"SYMBOL"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Gene.Name"</span><span class="w">

</span><span class="c1"># Merge keeping only matches</span><span class="w">
</span><span class="n">merged</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">merge</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vepfile</span><span class="p">,</span><span class="w">
                </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">drugs</span><span class="p">,</span><span class="w">
                </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Gene.Name"</span><span class="p">,</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">


</span><span class="c1"># Remove empty data "NA"</span><span class="w">
</span><span class="c1"># Install packeges once (comment out then)</span><span class="w">
</span><span class="c1"># Load library each time to use "%&gt;%" (command join) and filtering</span><span class="w">
</span><span class="n">install.packages</span><span class="p">(</span><span class="s2">"tidyr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyr</span><span class="p">)</span><span class="w">
</span><span class="n">install.packages</span><span class="p">(</span><span class="s2">"dplyr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span><span class="w">
</span><span class="n">df1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">merged</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">drop_na</span><span class="p">(</span><span class="n">Drug.IDs</span><span class="p">)</span><span class="w">

</span><span class="c1"># Make a list of benign variant types that should be removed</span><span class="w">
</span><span class="n">filter_out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> 
    </span><span class="s1">'synonymous_variant|UTR|NMD_transcript\
	|non_coding|downstream|upstream\
	|intron|mature_miRNA_variant'</span><span class="w">

</span><span class="c1"># Then filter out anything matching these terms.</span><span class="w">
</span><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df1</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">filter_all</span><span class="p">(</span><span class="n">all_vars</span><span class="p">(</span><span class="o">!</span><span class="n">grepl</span><span class="p">(</span><span class="n">filter_out</span><span class="p">,</span><span class="n">.</span><span class="p">)))</span><span class="w">

</span><span class="c1"># Save an output tsv file for Excel, etc.</span><span class="w">
</span><span class="n">write.table</span><span class="p">((</span><span class="n">df2</span><span class="p">),</span><span class="w"> </span><span class="n">file</span><span class="o">=</span><span class="s1">'./output.tsv'</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">"\t"</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="w">
</span><span class="n">quote</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">row.names</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>If you complete this process the output will contain a perfectly merged dataset.
So in this simple example it takes just 5 minutes to get from a real genome VCF to possibly druggable target genes (see further note on <em>drug indication</em> below).
The difficulty lies downstream in interpreting which variants can have an effect that would justify the use of the drug.
Anyone implementing a usable version of this method will incur several obstacles;
e.g. are non-coding or synonymous variants worth reporting?, genes have multiple transcripts which means one variant can be both coding and non-coding depending on transcript splicing, etc.
Other sources of sequence data, including the sequences of Watson and Venter;<br />
<a href="http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/">http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/</a><br />
23andMe open snp data; <a href="https://opensnp.org/genotypes">https://opensnp.org/genotypes</a>.
There are many layers to a this problem to create a usable product.
For example, how to integrate pharmacodynamics, covariats to drug response, contraindications, variant pathogenicity, etc.
However, this is a good start as a learning experience.</p>

<h1 id="drug-indication">Drug indication</h1>
<p>My example used <a href="https://www.drugbank.ca">DrugBank</a> for pharmacogenomic information.
However, it may be safest to use the <a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling">FDA information</a> as the primary source, but including <a href="https://www.drugbank.ca">DrugBank</a> info is no problem.
Drugs might be either a treatment for a genetic determinant, or a warning for drug usage in someone who also has a genetic variation that might effect their treatment.
The “Labelling Section” listed by FDA might offer the best information.</p>

<p><a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling">https://www.fda.gov/drugs/</a>
For example, if we go and check the Prescribing Information PDF to compare two drugs we see that</p>

<p><br />
<strong>(1)</strong> One is used to directly block a gene product,<br />
<strong>(2)</strong> The second warns about use with certain genetic complications.</p>

<p><br />
<strong>Drug 1</strong>: <a href="https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm?event=overview.process&amp;varApplNo=761034">Atezolizumab</a> (1),<br />
<strong>Gene</strong>: <a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling"><em>CD274</em></a> <a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling">(PD-L1)</a><br />
<strong>Labeling</strong>: Indications and Usage<br />
<strong>PRESCRIBING</strong> <strong>INFORMATION</strong>: TECENTRIQ (Atezolizumab) is a programmed death-ligand 1 (PD-L1) blocking antibody indicated for the treatment of patients with…
<a href="https://www.accessdata.fda.gov/drugsatfda_docs/label/2016/761034Orig1s000lbl.pdf">linked PDF</a>.<br />
<strong>Explained</strong>: Genetic disorder and the drug to treat it, exactly what you want.</p>

<p><br />
<strong>Drug 2</strong>: Avatrombopag (3)<br />
<strong>Gene</strong>: <a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling"><em>PROC</em></a><br />
<strong>Labeling</strong>: Warnings and Precautions<br />
<strong>PRESCRIBING INFORMATION</strong>: Thrombotic/Thromboembolic Complications: DOPTELET is a thrombopoietin (TPO) receptor agonist… Monitor platelet counts and for thromboembolic events
<a href="https://www.accessdata.fda.gov/drugsatfda_docs/label/2019/210238s002lbl.pdf">linked PDF</a>.<br />
<strong>Explained</strong>: Atezolizumab is used to treat thrombocytopenia (low levels of thrombocytes).<br />
You <em>do not want to give</em> this to someone who has <a href="https://omim.org/entry/176860?search=proc&amp;highlight=proc"><em>PROC</em></a><a href="https://omim.org/entry/176860?search=proc&amp;highlight=proc"> deficiency</a>;
their disease is <a href="https://en.wikipedia.org/wiki/Thrombophilia">Thrombophilia</a> (hypercoagulability, or <a href="https://en.wikipedia.org/wiki/Thrombosis">thrombosis</a>).
With this in mind, perhaps an application doing this job could work two ways.
(1) If someone has a genetic disorder, the drug, gene, and Indicated usage appears.
(2) If someone is prescribed a drug a suggestion appears to check their genetics, with a link to the gene and Warnings and Precautions.</p>

<h1 id="annotation">Annotation</h1>
<p><a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/">Variant Effect Predictor (VEP)</a> is very useful.
During variant annotation, VEP supplies a “consequence” column.
Consequences are general and based on translation of genetic code in humans. 
The Loss-of-function (LoF) consequence is the simplest example (splice, stop mutations).
The variant consequence may be one of the defining criteria by which variants can 
be included in analysis since they are <em>interpretable</em> or of ostensibly <em>known significance</em>.
<em>Note: Using this alone could introduce spurious results so it is  best to have a solid criteria 
for selecting consequences of interest</em>.
The consequences provided by VEP are too long to discuss in detail here.
The table from the ensembl website is worth reading; the HIGH impact variants 
might be a simple method for selecting candidates:
<a href="https://grch37.ensembl.org/info/genome/variation/prediction/predicted_data.html#consequences">Ensembl Variation - Calculated variant consequences</a>.<br />
<img src="/images/VEP_consequences.jpg" width="100%" /></p>

<p><em>Note: For a real product, the code should be run offline (a perl program with a few local library dependencies). The databases/cache that it uses are a bit too large to include on in a user software. In the real world you would have to send anonymised packets from the user via an API for accessing the genomic databases hosted on your servers. Make sure to check their license to see if you can use oftware and databases in a commercial product</em>.
<a href="http://www.ensembl.org/info/about/legal/code_licence.html">http://www.ensembl.org/info/about/legal/code_licence.html</a></p>

<p>Running the software:</p>

<ul>
  <li>Using VEP is a vital part of converting the DNA variant information (genome position and nucleotide change) into annotated variant effects (protein coding change, gene name, predicted pathogenicity).</li>
  <li>It requires the VEP code to run and requires a copy of the database files (reference genome, gene information, etc.).</li>
  <li>You can upload a small number of variants to the online VEP web server to do this, or you can download the database and code to run on your own computer/server.</li>
</ul>

<p>So to process your customer/patient data, you have to choose one of these methods:</p>

<ol>
  <li>Customer must upload their entire file to your server that runs VEP (1GB - 30GB per individual genome data).</li>
  <li>Customer must download the database and VEP code to run on their own computer (complex and large download for them, not recommended).</li>
</ol>

<p>Number 1 is better. But sending one large file often has problems.
If they have a VCF file, you could:</p>

<ul>
  <li>Break it into small equal sized blocks to upload the data to you. Anonymisation is normal for all internet connections now, but you could just mention that some method of anonymising these blocks is important since someone “hacker” might try to steal information if most of the network data being sent to you contains small VCF format files.</li>
  <li>You could also run a very small piece of code on the cusotmers software application that could extract just the main parts of the VCF file that you need, instead of sending everything. This is explained in sections 7-9. You could say this, but don’t need to actually have working. i.e. the drugbank information only includes a certain number of human genes so perhaps you could just extract these using a list of genome coordinates before processing with VEP.</li>
</ul>

<p>For the license:</p>

<ul>
  <li>Anyone is free to download and use VEP code.</li>
  <li>However, if you modify or reuse the code commercially it might affect the possibility of getting a patent for your product.</li>
  <li>Your product uses VEP as an intermediate step, so you probably only need to include credit, or other legal info to say you have used it.</li>
  <li>If there were a reason to prevent you using the software commercially, you might be able to make a simple replacement that could give the minimum outputs that you need - gene name and mutation type. If the topic happens to interest you, you can read about <a href="https://en.wikipedia.org/wiki/Reverse_engineering#Software">reverse engineering software</a>.</li>
  <li>As an aside, you could also decide that you don’t want to commercialise and offer this tool for free which would prevent bigger companies (like Google) from offering this service in return for harvesting the public’s genetic data.</li>
</ul>

<h2 id="optimising-vcf-annotation">Optimising VCF annotation</h2>
<p>The slowest part of the method is VCF annotation.
You can significantly increase the speed by first reducing the input to contain only regions of interst.
That is, prepare a list of coordinates for each gene, and select for those regions in your input VCF or genotype data before annotation (VEP).</p>

<h2 id="how-to-get-coordinates-for-a-gene-list">How to get coordinates for a gene list</h2>
<p>Use Biomart.
Their main server was down when I tried, so I went via Ensembl, data access section:<br />
<a href="http://www.ensembl.org/info/data/biomart/index.html">http://www.ensembl.org/info/data/biomart/index.html</a><br />
Then to use the BioMart data mining tool<br />
<a href="http://www.ensembl.org/biomart/martview/28fdaf82da6c02dc5892f99b757e2c44">http://www.ensembl.org/biomart/martview/</a><br />
I actually needed the positions using GRCh37 (rather than 38), so I switched to the old Ensembl using<br />
<a href="http://www.ensembl.org/info/website/tutorials/grch37.html">http://www.ensembl.org/info/website/tutorials/grch37.html</a><br />
to get to <a href="http://grch37.ensembl.org/index.html">http://grch37.ensembl.org/index.html</a> 
then the Biomart section<br />
<a href="http://grch37.ensembl.org/biomart/martview/04f009257dadbafbe595155ba910eb5e">http://grch37.ensembl.org/biomart/martview/</a></p>

<p>Choose DataBase: Genes 93 Dataset: Human Filter -&gt; Gene -&gt; Input external ref ID list -&gt; (change dropdown) Gene
Name paste your list.
e.g. VPS45 PSMB8 BLNK NEFL NLRP7 SMAD4 PSMB9<br />
To set the output type: Attributes -&gt; Gene -&gt; select “gene start”, “gene stop”, “gene name”, or anything extra.
Select the “Results” button at the top and export.
The results can be tsv or csv.
You would have to figure out how to extract the regions from the vcf (sed, grep, awk, R code, etc.).
When I needed this, I used my own tools which required converting to format like this “X:1-2000”, and ordered by number and alphabetic (some positions in the reference genome were patches added later and have an alphanumeric instead of the normal chromosome).
If you use this list to extract regions from a VCF, remember to include all the original VCF header information.</p>

<h2 id="extracting-regions-from-a-vcf-using-a-bed-file">Extracting regions from a VCF using a bed file</h2>
<p>The early part of this tutorial shows how old-school command line tools can be used to extract data. 
Indeed, this may be computationally most efficient but there are some specialised tools that make the process easier in general.
You can use VCFtools to extract specified regions.<br />
<a href="https://vcftools.github.io/man_latest.html">https://vcftools.github.io/man_latest.html</a><br />
You could use a list of defined genome position to reduce the size of your dataset. 
The defined genomic coordinates are generally supplied in a file format called the (BED file](https://en.wikipedia.org/wiki/BED_(file_format))
Note that sometimes the bed file “chrom” ID - the name of the chromosome (e.g. chr3) does not match if the VCF file uses “3” instead of “chr3”.
You might need to edit the bed.
My bed file was like this:<br />
(tab spaced), ref.bed<br />
<br />
chrom    chromStart    chromEnd<br />
1    3549    13555<br />
<br />
And this command ran OK for me to give “output_prefix.recode.vcf”<br /></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$:</span>~/tools/vcftools_0.1.13/bin <span class="se">\</span>
./vcftools <span class="se">\</span>
<span class="nt">--vcf</span> ~/input.vcf <span class="se">\</span>
<span class="nt">--bed</span> ~/ref.bed <span class="se">\</span>
<span class="nt">--out</span> output_prefix <span class="se">\</span>
<span class="nt">--recode</span> <span class="nt">--keep-INFO-all</span>
</code></pre></div></div>

<p>This new VCF will now only contain gene regions that are potentially “druggable”, or at least included on the FDA list.
VCF annotation will be <em>much faster</em> than annotation of the whole genome.</p>

<h1 id="unknown-variants">Unknown variants</h1>
<p>In the majority of situations you will be stuck with <em>variants of unknown significance</em>.
In the absence of tailored analysis and interpretation of each invidual variant, one must often rank unknown variants based on a predicted pathogenicity.
Carefully consider that predictions can be completed wrong and address how such an annotation should be presented. 
One can rank unknown variants based on PHRED-scaled CADD score, highest being more predicted pathogenic.
https://cadd.gs.washington.edu/info<br />
<a href="http://genetics.bwh.harvard.edu/pph2/">Polyphen</a> gives a predicted outcome label and a probability score 0-1 from benign to probably damaging.
See what other pathogenicity prediction tools you can find and estimate how widespread/accepted their usage is.</p>

<h1 id="gene-dosage">Gene dosage</h1>
<p>An important cosideration of variant effect depends on gene dosage.
A <a href="https://en.wikipedia.org/wiki/Dominance_(genetics)">dominant gene</a> may be affected by a single heterozgous variant while a recessive gene may be able to compensate against the negative effect of a heterozyous variant due the presence of a second functional gene copy.
Therefore, the presence of heterozygous or homozygous allele is an important consideration.
Some genes may be sensitive to a <a href="https://en.wikipedia.org/wiki/Zygosity">hemizygous</a> effect, low frequency <a href="https://en.wikipedia.org/wiki/Somatic_(biology)">somatic variants</a>,
<a href="https://en.wikipedia.org/wiki/Mosaic_(genetics)">mosaisism</a>, etc.
<a href="https://en.wikipedia.org/wiki/SNV_calling_from_NGS_data">SNV calling in NGS</a> is a broad topic, but it is safe to say that at least the allele dosage (generally heterozygous or homozygous) should be included in result summary.
If possible, when a gene is linked to a specific disease then the <a href="https://en.wikipedia.org/wiki/Heredity">inheritance type</a> associated with that gene-disease should also be included. 
For example, <a href="https://www.omim.org">https://www.omim.org</a> is a good place to see examles.
The genetic disease <a href="https://www.omim.org/entry/219700?search=cystic%20fibrosis&amp;highlight=cystic%20fibrosi">cystic fibrosis</a> is shown with an inheritance type AR (autosomal recessive) meaning that damaging variants on both gene alleles are required to cause disease. 
The gene <em>cftr</em>, which is the genetic determinant of cystic fibrosis, also has an <a href="https://www.omim.org/entry/602421?search=cftr&amp;highlight=cftr">OMIM page <em>cftr</em></a> that also lists AR inheritance.
An excellent resource for matching gene to disease is the <a href="https://panelapp.genomicsengland.co.uk">https://panelapp.genomicsengland.co.uk</a>.
Individual genes can be explored, or “panels” of disease-specific gene lists can be explored. For example, here is the “<a href="https://panelapp.genomicsengland.co.uk/panels/545/">Bleeding and platelet disorders</a>” panel. 
This shows the “Mode of inheritance” and colour-coded confidence in the disease-gene relationship.
Integrating this type of expert-curated open datasets can be extremely useful.</p>

<h1 id="drug-indication-1">Drug indication</h1>
<p>The indication or warning can be difficult to automate.
For the example drug<br />
<a href="https://www.drugbank.ca/drugs/DB11595">https://www.drugbank.ca/drugs/DB11595</a><br />
the section “Pharmacology” “Indication” has the Indication info.<br />
The FDA label is contained as a PDF attachment in the section “REFERENCES” FDA label Download (245 KB).
If I had to automate the process I would add a URL link for each drug:<br />
for gene name CD274<br />
the drugbank column Drug IDs has these:<br />
DB11595; DB11714; DB11945<br />
and for each ID you could append the ID onto the drugbank URL to link to the webpage
<a href="https://www.drugbank.ca/drugs/">https://www.drugbank.ca/drugs/</a>.
You can do this in R with some technical how-to reading, or do it manually for a quick example like this and removing space to create a web URL.<br />
URL				Drug IDs<br />
https://www.drugbank.ca/drugs/	DB00303<br />
https://www.drugbank.ca/drugs/	DB00114<br />
https://www.drugbank.ca/drugs/	DB00142<br />
https://www.drugbank.ca/drugs/	DB01839<br />
https://www.drugbank.ca/drugs/	DB00125</p>

<h1 id="a-large-scale-example-summary">A large scale example summary</h1>
<p>I do not suggest this for a small project, but if I was to automate subsection requests for real:</p>
<ul>
  <li>[1] Download the whole database (probably a big table sized &gt;100MB) and</li>
  <li>[2] For every query (the Drug ID) extract the sections of interest (indication,  Biologic Classification, Description,  FDA label, etc.)</li>
  <li>[3] Display each section as additional columns in candidate genes table.<br />
<br /></li>
  <li>[1] Would be here: <a href="https://www.drugbank.ca/releases/latest">https://www.drugbank.ca/releases/latest</a></li>
  <li>[2] Would be like this: <a href="https://www.w3schools.com/xml/default.asp">https://www.w3schools.com/xml/default.asp</a><br />
Look at example 2, your database request might be something like:
[get food name = Belgian Waffles, description] or
[get drug ID = DB11595, indication,  Biologic Classification, Description,  FDA label.]
The database request problem can be tricky to optimise but not especially difficult with some experience in SQL-type management.</li>
  <li>[3] For every line in the gene candidate table, do this query request and output the result into the same row.<br />
The final table would be something that includes colunm headers like:<br />
Gene, consequence, variant, amino acid, genome position, CADD, DrugBank ID, Description, Indication, FDA label PDF link, etc.
This table could be ranked based on consequence, CADD score.
The top couple of rows then might be converted into a more readable format like a PDF.</li>
</ul>

<h1 id="funding-strategy">Funding strategy</h1>
<p>University-based start-ups ususally follow a plan with three or four funding stages before coming to market. 
It is also possible to get investors from day 1, but it is more usual to follow 
the steps outlined here.
It is also possible to partner with early investors for their guidance rather 
than for financial investment.</p>

<h3 id="example-funding-stages">Example funding stages:</h3>

<ul>
  <li>A - Fundamental research (e.g. SNSF)</li>
  <li>B - Tech development (gap between the basic research and usable product)</li>
  <li>C - Product development (e.g. industry, Innosuisse funding)</li>
</ul>

<h3 id="example-funding-sources-per-stage">Example funding sources per stage:</h3>

<ol>
  <li>[A] Ignite grant
    <ul>
      <li><a href="https://www.epfl.ch/innovation/startup/grants/ignition-grants/">https://www.epfl.ch/innovation/startup/grants/ignition-grants/</a></li>
      <li>30K - 6 month, salary/consumables</li>
    </ul>
  </li>
  <li>[A] Innogrant
    <ul>
      <li>&lt;https://www.epfl.ch/innovation/startup/grants/innogrants/</li>
      <li>100K - 1 year, salary for startup founder.</li>
    </ul>
  </li>
  <li>[B] BRIDGE Proof of concept
    <ul>
      <li><a href="https://www.bridge.ch/en/proof-of-concept/">https://www.bridge.ch/en/proof-of-concept/</a></li>
      <li>130K - 1 year</li>
    </ul>
  </li>
  <li>[B] BRIDGE Discovery
    <ul>
      <li><a href="https://www.bridge.ch/en/discovery/">https://www.bridge.ch/en/discovery/</a></li>
      <li>(alternative to Proof of concept, more for experienced researchers).</li>
    </ul>
  </li>
  <li>[C] Innosuisse
    <ul>
      <li>Federal funding for startups of social benefit, etc.</li>
      <li><a href="https://www.innosuisse.ch/inno/en/home/start-and-grow-your-business/startup-coaching.html">https://www.innosuisse.ch/inno/en/home/start-and-grow-your-business/startup-coaching.html</a></li>
    </ul>
  </li>
  <li>[C] Other investors, venture capital, or investing from big companies like J&amp;J, Pfizer, &amp;c. For example, in a recent J&amp;J meeting the start-up-related experts discussed how they work with startups.</li>
</ol>
<p><a href="https://advancesindrugdiscovery.splashthat.com">https://advancesindrugdiscovery.splashthat.com</a>
Basically, the “innovation” department experts help you to figure out what stage you are at. You can contact them as soon as you can disclose your tech non-confidentially (either you have patent protection or do not need it). If you were taking this path you would probably have competed steps 1-4.</p>

<h1 id="legal-requirements">Legal requirements</h1>
<h3 id="swiss-law">Swiss law</h3>
<p>I include both the English and French translations here as the original source does not always include full English translation. 
Swiss law contains specific provisions on genetic testing in humans.
The Federal Council is divided into <a href="https://www.admin.ch/gov/fr/accueil.html">7 departments</a> and one chancellory. 
Each department contains their relevant offices (usually fewer than 10). 
For our interests, the governing hierarchy order is as follows:</p>

<ul>
  <li>Le Conseil fédéral</li>
  <li>The Federal Council
    <ul>
      <li>Département fédéral de l’intérieur (DFI),</li>
      <li>Federal Department of Home Affair (FDHI),
        <ul>
          <li>Office fédéral de la santé publique (OFSP).</li>
          <li>Federal Office of Public Health (FOPH).</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>This office is then responsible for their relevant ordinances as organised under internal law:
<a href="https://www.fedlex.admin.ch/en/cc/internal-law/8">https://www.fedlex.admin.ch/en/cc/internal-law/8</a>.
A direct weblink to our area of interest is available on <a href="https://www.bag.admin.ch/bag/fr/home/gesetze-und-bewilligungen/gesetzgebung/gesetzgebung-mensch-gesundheit/gesetzgebung-genetische-untersuchungen.html">Législation Analyses génétiques</a>, 
but it is useful to view the legal framework in context instead of abstractly.</p>

<ul>
  <li>Internal law (1-9 sec)</li>
  <li>Droite interne (1-9 sec)</li>
  <li>Sec 8..: (81-86 subsections) Health - Employment - Social security</li>
  <li>Sec 8..: (81-86 subsections) Santé - Travail - Sécurité sociale</li>
  <li>Sec 81.: Health: (810-819 subsubsections)</li>
  <li>Sec 81.: Santé: (810-819 subsubsections)</li>
  <li>Sec 810: Medicine and human dignity</li>
  <li>Sec 810: Médecine et dignité humaine</li>
  <li>Sec 810.1: Medically assisted reproduction and genetic engineering in the human field</li>
  <li>Sec 810.1: Procréation médicalement assistée et génie génétique dans le domaine humain</li>
  <li>Sec 810.12: Federal Act of 8 October 2004 on Human Genetic Testing (HGTA)</li>
  <li>Sec 810.12: Loi fédérale du 8 octobre 2004 sur l’analyse génétique humaine (LAGH)<br />
This contains section (810.12) contains 10 sections with 44 articles covering the initial regulations.</li>
</ul>

<p>Three ordinance then include further details (with several sections, articles, or annexes each):</p>

<ul>
  <li>Sec 810.122.1: Ordinance of 14 February 2007 on Human Genetic Analysis (OAGH)</li>
  <li>Sec 810.122.1: Ordonnance du 14 février 2007 sur l’analyse génétique humaine (OAGH)</li>
  <li>Sec 810.122.122: Ordinance of the Federal Department of Home Affairs of February 14, 2007 on Human Genetic Analysis (OAGH-DFI)</li>
  <li>Sec 810.122.122: Ordonnance du DFI du 14 février 2007 sur l’analyse génétique humaine (OAGH-DFI)</li>
  <li>Sec 810.122.2: Ordinance of February 14, 2007 on DNA profiling in civil and administrative matters (OACA)</li>
  <li>Sec 810.122.2: Ordonnance du 14 février 2007 sur l’établissement de profils d’ADN en matière civile et administrative (OACA)</li>
</ul>

<p>The details are then listed individually at:
<a href="https://www.fedlex.admin.ch/fr/cc/internal-law/81#810.12">https://www.fedlex.admin.ch/fr/cc/internal-law/81#810.12</a>
and as stated, includes authorisation of “Pharmacogenetic tests performed to determine the effects of a planned therapy”, 
“analyses pharmacogénétiques effectuées dans le but de déterminer les effets d’une thérapie prévue”.</p>

<h3 id="accreditation">Accreditation</h3>
<p><a href="https://www.iso.org/standard/56115.html">ISO 15189</a> is a commonly sought standard accreditation for genetic analysis labs, 
which is carried out by recognized accreditation services like <a href="https://www.finas.fi/Sivut/default.aspx">FINAS</a>.
Here it is mentioned for the Geneva health 2030 genome center for clinical grade sequencing:
<a href="https://www.health2030genome.ch/dna-sequencing-platform/">https://www.health2030genome.ch/dna-sequencing-platform/</a>.
Other additional ISO accreditation standard concern 
<a href="https://www.iso.org/search.html?q=Genomic%20information%20representation&amp;hPP=10&amp;idx=all_en&amp;p=0&amp;hFR%5Bcategory%5D%5B0%5D=standard">Genomic information representation</a>,
including
<a href="https://www.iso.org/standard/75859.html">23092-4 Reference software</a> or 
<a href="https://www.iso.org/standard/79882.html">23092 Transport and storage of genomic information</a>.</p>

<p>GA4GH provides other information about many <a href="https://www.ga4gh.org/genomic-data-toolkit/regulatory-ethics-toolkit/">legal and ethic topics</a>.
BlueprintGenomics is a good example company for comparison:
<a href="https://blueprintgenetics.com/certifications/">https://blueprintgenetics.com/certifications/</a>.</p>

<h1 id="more-questions">More questions</h1>

<p>Q: Do we have to infer that in the future everybody will have his genome sequenced ?<br />
You do not have to assume this. It may become true. There could be privacy concerns or social problems arising from genetic prejudice, etc.</p>

<p>Q: Before using our algorithm, patient will have to sequence a part of their genome and thus this is a weakness of our algorithm?<br />
Your tool will provide a service based on genetics.<br />
Option [1] One has their genetics already and will use it for personal medicine.<br />
Option [2] they are prescribed a drug and want to only sequence the genes of interest that could affect this drug.<br />
Option [3] they do not want any genetic info and therefor your product is irrelevant.<br />
Option [4] they do not want their personal genetics, but are willing to estimate their relatedness to others in a genetic database and therefore calculate a probability of accuracy for this drug-gene information. e.g. both parents are Swiss and therefore based on the population they have probability of X that their genotype is Y.</p>

<p>Q: Is it realistic to assume that it will be feasible based on the fact that the sequencing cost is decreasing ?<br />
Irrelevant in this case, but yes, whole genome seq is sometimes below 200CHF will likely be common soon.</p>

<p>Q:  We plan to use polyphen and/or sift in order to discriminate between those types of variants. Is that a good idea?<br />
That is a good start. CADD score is also pretty well known among physicians.
In my opinion, I do not trust the scores often.
However, it is common that for processing a large amount of data, such prediction tools are useful in general.
For example, I might [1] rank first on VEP variant “consequences”; stop mutations with most importance.
[2] Then rank secondly with these values since you cannot interpret most with consequence = missense variant.</p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://www.fda.gov/drugs/science-research-drugs/table-pharmacogenomic-biomarkers-drug-labeling">https://www.fda.gov/drugs/science-research-drugs/</a></li>
  <li><a href="https://www.pharmgkb.org/view/drug-labels.do">https://www.pharmgkb.org/view/drug-labels.do</a></li>
  <li>Mary V. Relling &amp; William E. Evans. Pharmacogenomics in the clinic. <em>Nature</em> 2015; 526, 343–350. doi: 10.1038/nature15817</li>
  <li>Yip VL, Hawcutt DB, Pirmohamed M. Pharmacogenetic Markers of Drug Efficacy and Toxicity. <em>Clin Pharmacol Ther.</em> 2015;98(1):61-70. doi: 10.1002/cpt.135.</li>
  <li>David R. Adams, M.D., Ph.D.,  and Christine M. Eng, M.D. Next-Generation Sequencing to Diagnose Suspected Genetic Disorders N Engl J Med Oct 2018 doi: 10.1056/NEJMra1711801</li>
</ul>

</p>

  <h2> - </h2>
  <p><h1 id="quantification-of-plof">Quantification of pLoF</h1>

<ul id="markdown-toc">
  <li><a href="#quantification-of-plof" id="markdown-toc-quantification-of-plof">Quantification of pLoF</a></li>
  <li><a href="#identification-of-plof-variants" id="markdown-toc-identification-of-plof-variants">Identification of pLoF variants</a>    <ul>
      <li><a href="#variant-effect-predictor" id="markdown-toc-variant-effect-predictor">Variant Effect Predictor</a></li>
      <li><a href="#loftee" id="markdown-toc-loftee">LOFTEE</a></li>
      <li><a href="#gencode" id="markdown-toc-gencode">GENCODE</a></li>
      <li><a href="#gene-ontology-go" id="markdown-toc-gene-ontology-go">Gene Ontology (GO)</a></li>
    </ul>
  </li>
  <li><a href="#published-example" id="markdown-toc-published-example">Published example</a>    <ul>
      <li><a href="#methods" id="markdown-toc-methods">Methods</a></li>
      <li><a href="#results" id="markdown-toc-results">Results</a></li>
    </ul>
  </li>
  <li><a href="#the-future" id="markdown-toc-the-future">The future</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h1 id="identification-of-plof-variants">Identification of pLoF variants</h1>
<p>As reported in “Sequencing of 53,831 diverse genomes from the NHLBI TOPMed Program” [0],
<!-- taliun2021sequencing -->
predicted loss-of-function (pLoF) variants can be identified using 
<!-- curly-percent cite KonradLOFTEE curly-percent ccurly-percent cite mclaren2016ensembl curly-percent -->
Variant Effect Predictor (VEP) [1]
and Loss Of Function Transcript Effect Estimator (LOFTEE) [2],
with accurate genomic coordinates from GENCODE [3].
An enrichment of share biological function in affected genes can then be tested using Gene Ontology (GO) [4].</p>

<p>A note here about the pLoF acronym.
I believe the “p” was originally for <em>predicted</em> loss-of-function,
and has more recently changed to <em>putative</em> loss-of-function.
The former is more transparent and preferable, I believe.</p>

<h2 id="variant-effect-predictor">Variant Effect Predictor</h2>
<p>Generally a local version of
<a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP/">Variant Effect Predictor</a> 
(VEP) software and databases are run for analysis.
However, one can try out the online version using the ensembl VEP URL.
An example output is shown here:<br />
<img src="/images/VEP_example.png" width="100%" /><br />
<br />
An obvious error that can occur is using mismatched genome builds.
Make certain that you use the same reference genome as used on the input data.
The Ensembl/VEP website URL should be for the same genome build (GRCh37, or the default GRCh38).
Local software and databases will also use the appropriate versions.</p>

<p>In variant annotation, VEP supplies a “consequence” column.
Consequences are general and based on translation of genetic code in humans. 
The Loss-of-function (LoF) consequence is the simplest example (splice, stop mutations).
For the topic of variant collapsing, used in areas such as burden testing, 
variant consequence defines which variants can be included in analysis since they are <em>interpretable</em> or of ostensibly <em>known significance</em> [4].
<!-- povysil2019rare -->
This could introduce spurious results so it is  best to have a solid criteria for selecting consequences of interest. 
The consequences provided by VEP are too long to discuss in detail. 
The table from the ensembl website is worth reading:
<a href="https://grch37.ensembl.org/info/genome/variation/prediction/predicted_data.html#consequences">Ensembl Variation - Calculated variant consequences</a>.<br />
<img src="/images/VEP_consequences.jpg" width="100%" /></p>

<h2 id="loftee">LOFTEE</h2>
<p>The <a href="https://github.com/konradjk/loftee">LOFTEE github</a> repo shows the code and examples of usage.
It functions as a VEP plugin for 3 LoF consequences:</p>
<ul>
  <li>stop-gained</li>
  <li>frameshift variants</li>
  <li>splice site disrupting</li>
</ul>

<p>There are some additional smart features that make LOFTEE more useful than simply the VEP consequences.
These include known features about how transcripts will be affected by variants 
(e.g. stop variants near the end of a transcript),
known splicing sequence mechanisms,
and other flags including splicing prediction that may be less reliable but still valuable.</p>

<h2 id="gencode">GENCODE</h2>
<p>Accurate annotation depends on correctly mapping positions based on the genome reference.
The genomic coordinates of coding elements may be based on <a href="https://www.gencodegenes.org/human/">GENCODE</a> 
[3].
<!-- frankish2019gencode --></p>

<h2 id="gene-ontology-go">Gene Ontology (GO)</h2>
<p><a href="http://geneontology.org">Gene Ontology (GO)</a> is a valuable database of known gene function and
can also be used to perform enrichment analysis on gene sets 
[5, 6].
For example, given a set of genes that are up-regulated under certain conditions, 
an enrichment analysis will find which GO terms are over-represented (or under-represented) using annotations for that gene set.
This description was taken directly from 
<a href="http://geneontology.org/docs/go-enrichment-analysis/">geneontology.org</a> where a longer explanation is shown. 
Using the web interface, an example query for 4 genes from the VDJ recombination pathway were queried.
The output is shown here. 
The reference database has 20595 IDs. 
My 4 gene IDs were then tested for all known interactions - the number of shared GO terms.
There were 9038 terms checked in total.
The output table shows the GO process “V(D)J recombination” as the strongest association;</p>
<ul>
  <li>all 4 genes shared this process</li>
  <li>for 4 random genes we would expect none to share the same GO process</li>
</ul>

<p>The fold enrichment and strong P-value indicate a true association of shared biological pathway.<br />
<img src="/images/GO_enrich.png" width="100%" /></p>

<h1 id="published-example">Published example</h1>
<h2 id="methods">Methods</h2>
<p>In Taliun et al [0], each of these tools are used in their analysis to target variants:</p>
<ul>
  <li>stop-gained</li>
  <li>frameshift</li>
  <li>splice-site-disturbing variants
    <ul>
      <li>annotated as high-confidence pLOF</li>
    </ul>
  </li>
  <li>remove pLOF with allele frequency &gt; 0.5%</li>
  <li>remove pLOF within regions masked due to poor accessibility</li>
</ul>

<p>These last two additionally ignore variants that are likely of minor consequence to human health but still passed the basic pLoF filter. 
Taliun et al. evaluated enrichment and depletion of pLOF variants 
(allele frequency $&lt;$ 0.5%) in gene sets (that is, terms) from Gene Ontology (GO) 
[5, 6].
For each gene annotated with a particular GO term, 
they computed the number of pLOF variants per</p>
<ul>
  <li>protein-coding base pair, L, and</li>
  <li>proportion of singletons, S.</li>
</ul>

<p>They then tested for lower or higher mean L and S in a GO term 
using bootstrapping (1,000,000 samples) 
with adjustment for the gene length of the protein-coding sequence (CDS):</p>
<ol>
  <li>Sort all genes by CDS length in ascending order and divide them into equal-size bins (1,000 genes each);</li>
  <li>Count how many genes from a GO term are in each bin;</li>
  <li>From each bin, sample with replacement the same number of genes and compute the average L and S;</li>
  <li>Count how many times sampled L and S were lower or higher than observed values.</li>
</ol>

<p>The P-values were computed as the proportion of bootstrap samples that exceeded the observed values. 
The fold change of average L and S was computed as a ratio of observed values 
to the average of sampled values. 
They tested all 12,563 GO terms that included more than one gene. 
The P-value significance threshold was thus ~2e-6. 
The enrichment and depletion of pLOF variants in public gene databases was tested in a similar way.</p>

<h2 id="results">Results</h2>
<p>Taliun et al. wanted to see if any gene sets had enrichment or depletion of rare pLoF.
In the first 53,831 TOPMed samples, 
they detected more than 400 million variants:</p>
<ul>
  <li>single-nucleotide variants</li>
  <li>insertions or deletions</li>
</ul>

<p>Many novel variants will have been detected because they include</p>
<ul>
  <li>assembly of unmapped reads and</li>
  <li>customized analysis in highly variable loci.</li>
</ul>

<p>Among the more than 400 million detected variants,</p>
<ul>
  <li>97% have frequencies of less than 1% and</li>
  <li>46% are singletons that are present in only one individual.</li>
</ul>

<p>The 46% is pretty surprising but the number of private variant per person is probably not extremely high.
In clinical exomes we usually expect approximately $&lt;$100 novel variants compared to the <em>in-house sequence database</em>.
We also expect aprrox. $&lt;$10 <em>de novo</em> variants in the same sample if parents/family were also sequenced. 
The number will be much larger for non-coding genome, but since SNVs will be largely non-interpretable it is currently ignored for clinical diagnosis.</p>

<p>A notable class of variants is the 
228,966 putative loss-of-function (pLOF) variants 
that were observed in 18,493 (95.0%) GENCODE genes 
(Extended Data Table 5 and Supplementary Fig. 12). 
This class includes the highest proportion of singletons among all of the variant classes that was examined. 
An average individual carried 2.5 unique pLOF variants. 
They identified more pLOF variants per individual than in previous surveys 
based on exome sequencing; an increase that was mainly driven by</p>
<ul>
  <li>identification of additional frameshift variants (Table S6)</li>
  <li>and more uniform and complete coverage of protein-coding regions (Fig. S13, S14).</li>
</ul>

<p>It is worth noting that the <a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03205-y/MediaObjects/41586_2021_3205_MOESM3_ESM.pdf">referenced figures (S13,14)</a> don’t show specifically pLoF, 
but rather sequence depth per gene.
They show that TopMed has better coverage/depth than ExAC, including for known disease genes.
I would have expected them to show the same results specifically for pLoF variants to support their statement.</p>

<p>The extract from Table S7 shows the comparison of pLoF versus other rare variants in GO terms (protein pathways). 
The comparison is basically: 
Random sampling provides the number of <em>expected</em> variants, which is then compared to the <em>observed</em> number of variants.
There are four categories used:</p>
<ul>
  <li>expected pLoF</li>
  <li>observed pLoF</li>
  <li>expected singleton</li>
  <li>observed singleton</li>
</ul>

<p>The top result, DNA-binding genes, showed rare variants (singletons) observed/expected = 1, but pLoF observed/expected = 0.5.
This comparison is made to show that:</p>
<ul>
  <li>This biological mechanism cannot tollorate damaging pLoF variants (pLoF/bp).</li>
  <li>And even though pLoF are usually very rare, 
this does not account for the lack of observations - 
rare/novel variants that are non-pLoF are present (proportion of singletons).</li>
</ul>

<p><img src="/images/plof_enrichment_eg.png" width="100%" /></p>

<p>They searched for gene sets with fewer rare pLOF variants than expected based on gene size. 
The gene sets with strong functional constraint included genes that encode DNA- and RNA-binding proteins, 
spliceosomal complexes, 
translation initiation machinery and 
RNA splicing and processing proteins (Supplementary Table 7). 
They found fewer rare pLOF variants than expected (each comparison P $&lt;$ 10−4) for 
Genes associated with human disease in</p>
<ul>
  <li>COSMIC [7] (31% depletion),</li>
  <li>GWAS catalogue [8] (around 8% depletion),</li>
  <li>OMIM19 [9] (4% depletion) and</li>
  <li>ClinVar [10] (4% depletion).</li>
</ul>

<h1 id="the-future">The future</h1>
<p>With very large scale genome sequencing we will start to association studies for extremely rare variants (eventually there will be no novel SNVs). 
This provokes a few possibilities.</p>
<ol>
  <li>Predicting probably of all SNVs.
    <ul>
      <li>CADD predicts <em>pathogenicity</em> for all SNVs but currently I don’t know of any <em>mutation probability</em> projects. Ratio of obs/exp will have valuable insight.</li>
    </ul>
  </li>
  <li>All coding variants will be reported.
    <ul>
      <li>functional prediction accuracies can be validated.</li>
    </ul>
  </li>
  <li>Novel non-coding variants will become the new variants of unknown significance (VUS). 
Will we slowly trudge through the same system again or will there be a more sophisticated approach for the non-coding genome in clinical genomics?</li>
</ol>

<h1 id="references">References</h1>
<hr />

<!-- curly-percent bibliography --cited curly-percent -->
<p>[0]  Taliun, Daniel, et al. Sequencing of 53,831 diverse genomes from the NHLBI TOPMed Program. Nature 590.7845 (2021): 290-299.
<a href="https://doi.org/10.1038/s41586-021-03205-y">https://doi.org/10.1038/s41586-021-03205-y</a><br />
[1] McLaren, W. et al. The Ensembl Variant Effect Predictor. Genome Biol. 17, 122 (2016).<br />
[2] Karczewski, K. J. et al. loftee. GitHub https://github.com/konradjk/loftee (2015).<br />
[3] Frankish, A. et al. GENCODE reference annotation for the human and mouse genomes. Nucleic Acids Res. 47 (D1), D766–D773 (2019).<br />
[4] Povysil, Gundula, et al. “Rare-variant collapsing analyses for complex traits: guidelines and applications.” Nature Reviews Genetics 20.12 (2019): 747-759.<br />
[5] The Gene Ontology Consortium. Gene ontology: tool for the unification of biology. Nat. Genet. 25, 25–29 (2000).<br />
[6] The Gene Ontology Consortium. Expansion of the Gene Ontology knowledgebase and resources. Nucleic Acids Res. 45 (D1), D331–D338 (2017).<br />
[7] Forbes, S. A. et al. COSMIC: exploring the world’s knowledge of somatic mutations in human cancer. Nucleic Acids Res. 43, D805–D811 (2015).<br />
[8] Welter, D. et al. The NHGRI GWAS Catalog, a curated resource of SNP–trait associations. Nucleic Acids Res. 42, D1001–D1006 (2014).<br />
[9] Hamosh, A., Scott, A. F., Amberger, J. S., Bocchini, C. A. &amp; McKusick, V. A. Online Mendelian Inheritance in Man (OMIM), a knowledgebase of human genes and genetic disorders. Nucleic Acids Res. 33, D514–D517 (2005).<br />
[10] Landrum, M. J. et al. ClinVar: improving access to variant interpretations and supporting evidence. Nucleic Acids Res. 46 (D1), D1062–D1067 (2018).\</p>
</p>

  <h2> - </h2>
  <p><h1 id="polygenic-risk-score">Polygenic risk score</h1>

<ul id="markdown-toc">
  <li><a href="#polygenic-risk-score" id="markdown-toc-polygenic-risk-score">Polygenic risk score</a></li>
  <li><a href="#qc-base-and-target-cohort" id="markdown-toc-qc-base-and-target-cohort">QC: base and target cohort</a></li>
  <li><a href="#base-only" id="markdown-toc-base-only">Base only</a></li>
  <li><a href="#target-only" id="markdown-toc-target-only">Target only</a></li>
  <li><a href="#combined" id="markdown-toc-combined">Combined</a></li>
  <li><a href="#prs" id="markdown-toc-prs">PRS</a></li>
  <li><a href="#shrinkage-of-effect-size-estimate" id="markdown-toc-shrinkage-of-effect-size-estimate">Shrinkage of effect size estimate</a></li>
  <li><a href="#ld-control" id="markdown-toc-ld-control">LD control</a></li>
  <li><a href="#prs-unit" id="markdown-toc-prs-unit">PRS unit</a></li>
  <li><a href="#population-structure" id="markdown-toc-population-structure">Population structure</a></li>
  <li><a href="#multi-prs" id="markdown-toc-multi-prs">Multi PRS</a></li>
  <li><a href="#plot" id="markdown-toc-plot">Plot</a></li>
  <li><a href="#assocciation-and-goodness-of-fit" id="markdown-toc-assocciation-and-goodness-of-fit">Assocciation and goodness of fit</a></li>
  <li><a href="#plotting" id="markdown-toc-plotting">Plotting</a></li>
  <li><a href="#clinical-application" id="markdown-toc-clinical-application">Clinical application</a></li>
  <li><a href="#interpret" id="markdown-toc-interpret">Interpret</a></li>
  <li><a href="#distribution" id="markdown-toc-distribution">Distribution</a></li>
  <li><a href="#overfitting" id="markdown-toc-overfitting">Overfitting</a></li>
  <li><a href="#power" id="markdown-toc-power">Power</a></li>
</ul>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/30926966/">Martin, A.R.. et al. Clinical use of current polygenic risk scores may exacerbate health disparities. Nature Genetics. 2019; 51: 584-591</a></p>
<h1 id="qc-base-and-target-cohort">QC: base and target cohort</h1>
<h1 id="base-only">Base only</h1>
<h1 id="target-only">Target only</h1>
<h1 id="combined">Combined</h1>
<h1 id="prs">PRS</h1>
<h1 id="shrinkage-of-effect-size-estimate">Shrinkage of effect size estimate</h1>
<h1 id="ld-control">LD control</h1>
<h1 id="prs-unit">PRS unit</h1>
<h1 id="population-structure">Population structure</h1>
<h1 id="multi-prs">Multi PRS</h1>
<h1 id="plot">Plot</h1>
<h1 id="assocciation-and-goodness-of-fit">Assocciation and goodness of fit</h1>
<h1 id="plotting">Plotting</h1>
<h1 id="clinical-application">Clinical application</h1>
<h1 id="interpret">Interpret</h1>
<h1 id="distribution">Distribution</h1>
<h1 id="overfitting">Overfitting</h1>
<h1 id="power">Power</h1>

</p>

  <h2> - </h2>
  <p><h1 id="pharmacogenomic-stargazing">Pharmacogenomic stargazing</h1>

<ul id="markdown-toc">
  <li><a href="#pharmacogenomic-stargazing" id="markdown-toc-pharmacogenomic-stargazing">Pharmacogenomic stargazing</a></li>
  <li><a href="#stargazer-genotyping" id="markdown-toc-stargazer-genotyping">Stargazer genotyping</a>    <ul>
      <li><a href="#stargazer-summary" id="markdown-toc-stargazer-summary">Stargazer summary</a></li>
      <li><a href="#star-alleles" id="markdown-toc-star-alleles">Star alleles</a></li>
    </ul>
  </li>
  <li><a href="#published-example" id="markdown-toc-published-example">Published example</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<p><em>Note:
Manual curation of gene-drug interaction is not recommended and therefore 
simplification of nomenclature is not advised. 
Relying on star allele labelling goes against the recommended 
<a href="http://varnomen.hgvs.org/recommendations/general/">HGVS sequence variant nomenclature</a>.
The following protocol for is provided as one step in a larger process
of annotation in genomic analysis.</em></p>

<h1 id="stargazer-genotyping">Stargazer genotyping</h1>
<p>As reported in “Sequencing of 53,831 diverse genomes from the NHLBI TOPMed Program” [0],
(missing reference).</p>

<p><em>Background note: Haplotypes are group of alleles that are inherited together 
from a single parent. 
They are sequenced from individual DNA strands. 
These strands can be phased to reconstruct the inheritence pattern.</em></p>

<p>Phased haplotype (from <a href="https://www.10xgenomics.com">10Xgenomics.com</a>):</p>

<p><img src="/images/haplotype.jpeg" width="60%" /></p>

<ul>
  <li>GATK-HaplotypeCaller
    <ul>
      <li>SNVs and indels in were assessed from a VCF file generated using GATK-HaplotypeCaller <a class="citation" href="#mckenna2010genome">(McKenna et al., 2010)</a>.</li>
    </ul>
  </li>
  <li>Phase Beagle
    <ul>
      <li>The VCF file was phased using the program <a href="https://faculty.washington.edu/browning/beagle/beagle.html">Beagle</a> <a class="citation" href="#browning2007rapid">(Browning &amp; Browning, 2007)</a> and
  the 1000 Genomes Project haplotype reference panel.</li>
    </ul>
  </li>
  <li>Star alleles (<a href="#star-alleles">described below</a>)
    <ul>
      <li>Phased SNVs and indels were then matched to star alleles.</li>
    </ul>
  </li>
</ul>

<p>In parallel,</p>
<ul>
  <li>GATK-DepthOfCoverage
    <ul>
      <li>Read depth was calculated from BAM files using GATK-DepthOfCoverage <a class="citation" href="#mckenna2010genome">(McKenna et al., 2010)</a>.</li>
    </ul>
  </li>
  <li>Copy number
    <ul>
      <li>Read depth was converted to copy number by performing intra-sample normalization <a class="citation" href="#lee2019stargazer">(Lee et al., 2019)</a>.</li>
    </ul>
  </li>
  <li>Structural variants
    <ul>
      <li>After normalization,
  structural variants were assessed by testing all possible pairwise combinations
  of pre-defined copy number profiles
  against the observed copy number profile of the sample.</li>
    </ul>
  </li>
  <li>Changepoint
    <ul>
      <li>For new SVs,
  breakpoints were statistically inferred using changepoint <a class="citation" href="#killick2014changepoint">(Killick &amp; Eckley, 2014)</a>.</li>
    </ul>
  </li>
  <li>Output
    <ul>
      <li>Information regarding new SVs was stored and
  used to identify subsequent SVs in copy number profiles.</li>
      <li>Output data included individual diplotypes,
  copy number plots and
  a VCF of SNVs and indels that were not used to define star alleles.</li>
    </ul>
  </li>
</ul>

<h2 id="stargazer-summary">Stargazer summary</h2>
<p>From <a href="https://stargazer.gs.washington.edu/stargazerweb/index.html">Stargazer homepage</a> - quote:</p>

<blockquote>
  <p>“Stargazer is a bioinformatics tool for calling star alleles (haplotypes) in PGx genes using data from NGS or SNP array. Stargazer can accept NGS data from both WGS and TS.
“ Stargazer identifies star alleles by detecting SNVs, indels, and SVs. Stargazer can detect complex SVs including gene deletions, duplications, and hybrids by calculating paralog-specific copy number from read depth.”</p>
</blockquote>

<h2 id="star-alleles">Star alleles</h2>
<p>From <a href="https://bredagenetics.com/star-allele-nomenclature/">bredagenetics.com</a> - quote:</p>

<blockquote>
  <p>“Genetic variants identifiable as pharmacogenomic markers are described by utilizing a special nomenclature, which is not elsewhere used in genetics. It is the so-called star allele nomenclature. In this nomenclature, alleles aren’t identified by their cDNA or genomic position (as it usually happens with all other genetic variants – see HGVS nomenclature), but through the means of numbers and letters, separated from the gene name by a star (star allele nomenclature). For example: CYP3A5*2 identifies the genetic variant in the CYP3A5 gene at the genomic position g.27289C&gt;A, which leads to the amino acid substitution p.T398N. The star allele nomenclature is thought to be faster and easier for non-specialized professionals in identifying important pharmacogenetic alleles, helping them avoid transcription mistakes which may be more frequent by using the standard HGVS nomenclature.</p>
</blockquote>

<blockquote>
  <p>“Alleles are marked with a star (*).</p>
</blockquote>

<blockquote>
  <p>“A patient with ultrarapid drug metabolism harbors double or multiple copies of an allele with normal or increased functionality, whereas patients with intermediate or poor drug metabolism have one or more alleles with reduced functionality (these alleles are typically consistent with inactivating mutations or large gene deletions). The term extensive metabolizer is used instead to describe those individuals with two standard copies of the normally functional allele. Extensive metabolizers are therefore carrying the wild-type allele, also called consensus allele, which corresponds to the allele *1 in the star allele nomenclature. The numbers *2, *3, *4 and so on represent alleles with altered functionality which may lead to profiles of increased or reduced drug metabolism.</p>
</blockquote>

<blockquote>
  <p>“By using one single star allele one can identify not just a single variant, but even a group of variants.”</p>
</blockquote>

<p>A full list of cytochrome P450 (CYP) alleles with star notation can be found via the
<a href="https://www.pharmvar.org">Pharmacogene Variation (PharmVar)</a> consortium,
a central repository for PGx variation that focuses on 
haplotype structure and allelic variation.</p>

<h1 id="published-example">Published example</h1>
<p>Taliun et al.
(missing reference)
<a class="citation" href="#zhou2009polymorphism">(Zhou, 2009)</a>
<a class="citation" href="#crews2014clinical">(Crews et al., 2014)</a>.
More than 150 <em>CYP2D6</em> haplotypes have been described,
some involving a gene conversion with its nearby non-functional
but highly similar paralogue <em>CYP2D7</em>.</p>

<p>CYP2D6 interaction (from <a href="miro.medium.com">miro.medium.com</a>):</p>

<p><img src="/images/CYP2D6.png" width="50%" /></p>

<p>They performed <em>CYP2D6</em> haplotype analysis for all 53,831 TOPMed individuals 
<a class="citation" href="#lee2019stargazer">(Lee et al., 2019)</a>
<a class="citation" href="#lee2019calling">(Lee et al., 2019)</a>.
Called a total of 99 alleles (66 known and 33 novel) representing:</p>
<ul>
  <li>increased function,</li>
  <li>decreased function and</li>
  <li>loss of function (Supplementary Table 12).</li>
</ul>

<p>Nineteen known alleles and
all novel alleles
were defined by structural variants,
including complex CYP2D6-CYP2D7 hybrids and
extensive copy number variation,
which ranged from zero to eight gene copies (Supplementary Figs. 27, 28).</p>

<p><a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03205-y/MediaObjects/41586_2021_3205_MOESM3_ESM.pdf">figures (S27)</a> 
<img src="/images/FigS27.png" width="100%" /></p>

<blockquote>
  <p>Supplementary Figure 27. Examples of CYP2D6 star alleles (haplotypes) with structural variation detected by the Stargazer program. Each panel displays Stargazer’s copy number profile (left) and allele fraction profile (right) for an individual sample (N=6). Also shown are CYP2D6 diplotypes and phenotype predictions from Stargazer. Gray dots indicate the sample’s per-base copy number estimates computed from read depth. The navy solid line and the cyan dashed line represent copy number profiles for each haplotype. The red line represents the copy number profile for both haplotypes combined. Navy dots and cyan dots indicate allele fraction estimates computed from allelic read depth for each haplotype. More examples can be found in the Database of Pharmacogenomic Structural Variants or DPSV \url{https://stargazer.gs.washington.edu/stargazerweb/res/dpsv.html}</p>
</blockquote>

<p><a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03205-y/MediaObjects/41586_2021_3205_MOESM3_ESM.pdf">figures (S28)</a> 
<img src="/images/FigS28.png" width="100%" /></p>

<blockquote>
  <p>Supplementary Figure 28. Summary of CYP2D6 haplotype analysis using the Stargazer program. Population-specific frequencies for (A) common CYP2D6 star alleles, (B) haplotype activity, (C) SV-defined haplotypes, and (D) predicted metabolism phenotypes. Abbreviations: hAS, haplotype activity score; dAS, diplotype activity score; N, number; SV, structural variation; del, whole gene deletion; hyb, CYP2D6/CYP2D7 hybrid.</p>
</blockquote>

<h1 id="references">References</h1>
<ol class="bibliography"><li><span id="mckenna2010genome">McKenna, A., Hanna, M., Banks, E., Sivachenko, A., Cibulskis, K., Kernytsky, A., Garimella, K., Altshuler, D., Gabriel, S., Daly, M., &amp; others. (2010). The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data. <i>Genome Research</i>, <i>20</i>(9), 1297–1303.</span></li>
<li><span id="browning2007rapid">Browning, S. R., &amp; Browning, B. L. (2007). Rapid and accurate haplotype phasing and missing-data inference for whole-genome association studies by use of localized haplotype clustering. <i>The American Journal of Human Genetics</i>, <i>81</i>(5), 1084–1097.</span></li>
<li><span id="lee2019stargazer">Lee, S.-been, Wheeler, M. M., Patterson, K., McGee, S., Dalton, R., Woodahl, E. L., Gaedigk, A., Thummel, K. E., &amp; Nickerson, D. A. (2019). Stargazer: a software tool for calling star alleles from next-generation sequencing data using CYP2D6 as a model. <i>Genetics in Medicine</i>, <i>21</i>(2), 361–372.</span></li>
<li><span id="killick2014changepoint">Killick, R., &amp; Eckley, I. (2014). changepoint: An R package for changepoint analysis. <i>Journal of Statistical Software</i>, <i>58</i>(3), 1–19.</span></li>
<li><span id="zhou2009polymorphism">Zhou, S.-F. (2009). Polymorphism of human cytochrome P450 2D6 and its clinical significance. <i>Clinical Pharmacokinetics</i>, <i>48</i>(12), 761–804.</span></li>
<li><span id="crews2014clinical">Crews, K. R., Gaedigk, A., Dunnenberger, H. M., Leeder, J. S., Klein, T. E., Caudle, K. E., Haidar, C. E., Shen, D. D., Callaghan, J. T., Sadhasivam, S., &amp; others. (2014). Clinical Pharmacogenetics Implementation Consortium guidelines for cytochrome P450 2D6 genotype and codeine therapy: 2014 update. <i>Clinical Pharmacology &amp; Therapeutics</i>, <i>95</i>(4), 376–382.</span></li>
<li><span id="lee2019calling">Lee, S.-been, Wheeler, M. M., Thummel, K. E., &amp; Nickerson, D. A. (2019). Calling star alleles with stargazer in 28 pharmacogenes with whole genome sequences. <i>Clinical Pharmacology &amp; Therapeutics</i>, <i>106</i>(6), 1328–1337.</span></li></ol>
</p>

  <h2> - </h2>
  <p><h1 id="burden-testing-with-variant-collapse">Burden testing with variant collapse</h1>
<ul id="markdown-toc">
  <li><a href="#burden-testing-with-variant-collapse" id="markdown-toc-burden-testing-with-variant-collapse">Burden testing with variant collapse</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a>    <ul>
      <li><a href="#to-do" id="markdown-toc-to-do">To do</a></li>
    </ul>
  </li>
  <li><a href="#main-papers-in-order" id="markdown-toc-main-papers-in-order">Main papers in order</a>    <ul>
      <li><a href="#major-classes-of-tests" id="markdown-toc-major-classes-of-tests">Major Classes of Tests</a></li>
      <li><a href="#burden-tests-so-far" id="markdown-toc-burden-tests-so-far">Burden Tests So Far</a></li>
    </ul>
  </li>
  <li><a href="#li-and-leal-2008" id="markdown-toc-li-and-leal-2008">Li and Leal 2008</a>    <ul>
      <li><a href="#background" id="markdown-toc-background">Background</a></li>
      <li><a href="#genetic-model" id="markdown-toc-genetic-model">Genetic model</a></li>
      <li><a href="#single-marker-test" id="markdown-toc-single-marker-test">Single-marker test</a></li>
      <li><a href="#multiple-marker-test" id="markdown-toc-multiple-marker-test">Multiple-marker test</a></li>
      <li><a href="#basic-collapsing-method" id="markdown-toc-basic-collapsing-method">Basic collapsing method</a></li>
      <li><a href="#cmc-method" id="markdown-toc-cmc-method">CMC method</a></li>
      <li><a href="#power-of-cmc-method" id="markdown-toc-power-of-cmc-method">Power of CMC method</a></li>
      <li><a href="#misclassification" id="markdown-toc-misclassification">Misclassification</a></li>
      <li><a href="#effects-of-linkage-disequilibrium-ld" id="markdown-toc-effects-of-linkage-disequilibrium-ld">Effects of Linkage Disequilibrium (LD)</a></li>
      <li><a href="#evaluation-of-type-i-error-rate" id="markdown-toc-evaluation-of-type-i-error-rate">Evaluation of Type I Error Rate</a></li>
      <li><a href="#problems-with-this-paper" id="markdown-toc-problems-with-this-paper">Problems with this paper</a></li>
    </ul>
  </li>
  <li><a href="#madsen-and-browning-2009" id="markdown-toc-madsen-and-browning-2009">Madsen and Browning 2009</a>    <ul>
      <li><a href="#background-1" id="markdown-toc-background-1">Background</a></li>
      <li><a href="#main-theory" id="markdown-toc-main-theory">Main theory</a></li>
      <li><a href="#methods" id="markdown-toc-methods">Methods</a></li>
      <li><a href="#encode-data" id="markdown-toc-encode-data">ENCODE data</a></li>
      <li><a href="#results" id="markdown-toc-results">Results</a></li>
      <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a></li>
      <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
    </ul>
  </li>
  <li><a href="#price-2010" id="markdown-toc-price-2010">Price 2010</a>    <ul>
      <li><a href="#methods-1" id="markdown-toc-methods-1">Methods</a></li>
      <li><a href="#results-and-discussion" id="markdown-toc-results-and-discussion">Results and Discussion</a></li>
    </ul>
  </li>
  <li><a href="#neale-2011" id="markdown-toc-neale-2011">Neale 2011</a>    <ul>
      <li><a href="#c-alpha-tests" id="markdown-toc-c-alpha-tests">C-alpha tests</a></li>
    </ul>
  </li>
  <li><a href="#skat" id="markdown-toc-skat">SKAT</a>    <ul>
      <li><a href="#introduction-1" id="markdown-toc-introduction-1">Introduction</a></li>
      <li><a href="#methods-2" id="markdown-toc-methods-2">Methods</a></li>
      <li><a href="#skat-is-a-generalization-of-the-c-alpha-test" id="markdown-toc-skat-is-a-generalization-of-the-c-alpha-test">SKAT Is a Generalization of the C-Alpha Test</a></li>
    </ul>
  </li>
  <li><a href="#lee-2012" id="markdown-toc-lee-2012">Lee 2012</a>    <ul>
      <li><a href="#introduction-2" id="markdown-toc-introduction-2">Introduction</a></li>
      <li><a href="#methods-3" id="markdown-toc-methods-3">Methods</a></li>
    </ul>
  </li>
  <li><a href="#protein-pathway-analysis" id="markdown-toc-protein-pathway-analysis">Protein pathway analysis</a>    <ul>
      <li><a href="#zhang-2021-ashg" id="markdown-toc-zhang-2021-ashg">Zhang 2021 ASHG</a></li>
      <li><a href="#problems-with-this-paper-1" id="markdown-toc-problems-with-this-paper-1">Problems with this paper</a></li>
    </ul>
  </li>
  <li><a href="#itan--casanova-contributions" id="markdown-toc-itan--casanova-contributions">Itan &amp; Casanova contributions</a>    <ul>
      <li><a href="#historical-review" id="markdown-toc-historical-review">Historical review</a></li>
    </ul>
  </li>
  <li><a href="#burden-test-power-calculation" id="markdown-toc-burden-test-power-calculation">Burden test power calculation</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>In this series I will go over methods and theory for gene burden testing.
I am publishing this live as I work since there are several heavy papers to get through.
<!--For the working writeup see: pri_net_manuscript/pre_print_md/detailed_methods/statistics.md--></p>

<h2 id="to-do">To do</h2>

<p>Running code on test data: Remake the gVCF as BP_RESOLUTION to list a site for every position. 
Filter: If variants are MAF &gt;1.1 in gnomAD then run a filter to remove variants that are not sequenced in controls.
Justification: If we ran that filter for every singleton it would remove the very rare variants that would have been a true positive if it had been sequenced in the controls.</p>

<h1 id="main-papers-in-order">Main papers in order</h1>

<ul>
  <li>Methods for detecting associations with rare variants for common diseases: application to analysis of sequence data
<a class="citation" href="#li2008methods">(Li &amp; Leal, 2008)</a>.</li>
  <li>A groupwise association test for rare mutations using a weighted sum statistic.
(missing reference).</li>
  <li>An evaluation of statistical approaches to rare variant analysis in genetic association studies.
<a class="citation" href="#morris2010evaluation">(Morris &amp; Zeggini, 2010)</a>.</li>
  <li>Pooled association tests for rare variants in exon-resequencing studies.
<a class="citation" href="#price2010pooled">(Price et al., 2010)</a>.</li>
  <li>Testing for an unusual distribution of rare variants.
(missing reference).</li>
  <li>Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test.
(missing reference).</li>
  <li>Optimal tests for rare variant effects in sequencing association studies.
<a class="citation" href="#Lee2012Optimal">(Lee et al., 2012)</a>.</li>
  <li>Optimal Unified Approach for Rare-Variant Association Testing with Application to Small-Sample Case-Control Whole-Exome Sequencing Studies.
<a class="citation" href="#Lee2012Optimalunified">(Lee et al., 2012)</a>.</li>
  <li>Sequence Kernel Association Tests for the Combined Effect of Rare and Common Variants.
<a class="citation" href="#IonitaLaza2013Sequence">(Ionita-Laza et al., 2013)</a></li>
</ul>

<h2 id="major-classes-of-tests">Major Classes of Tests</h2>

<ul>
  <li>Burden/Collapsing tests</li>
  <li>Supervised/Adaptive Burden/Collapsing tests</li>
  <li>Variance component (similarity) based tests</li>
  <li>Omnibus tests: hedge against difference scenarios</li>
</ul>

<h2 id="burden-tests-so-far">Burden Tests So Far</h2>

<h3 id="tests">Tests</h3>

<ul>
  <li>Binary Collapsing: CAST</li>
  <li>CMC</li>
  <li>Count Collapsing: MZ (GRANVIL)</li>
  <li>Weighted Sum Test</li>
</ul>

<h3 id="power-of-burden-tests-depends-on">Power of burden tests depends on</h3>

<ul>
  <li>Number of associated variants</li>
  <li>Number of non-associated variants</li>
  <li>Direction of the effects.</li>
  <li>Powerful if most variants are causal and have effects in the same direction.</li>
</ul>

<h1 id="li-and-leal-2008">Li and Leal 2008</h1>
<ul>
  <li>
    <p>Methods for detecting associations with rare variants for common diseases: application to analysis of sequence data
<a class="citation" href="#li2008methods">(Li &amp; Leal, 2008)</a></p>
  </li>
  <li>The collapsing method, which involves collapsing genotypes across variants and applying a univariate test, is powerful for analyzing rare variants.</li>
  <li>The multivariate analysis is robust against inclusion of non-causal variants.</li>
  <li>Both methods are superior to analyzing each variant individually with univariate tests.</li>
  <li>Combined Multivariate and Collapsing (CMC) method unifies the advantages of both collapsing and multiple-marker tests.</li>
</ul>

<h2 id="background">Background</h2>

<p>Genotype phenotype association may be tested by:</p>

<ul>
  <li>A single market test (i.e. GWAS) may use standard univariate statistical tests
(e.g., chi-squared test, Fisher’s exact test, or Cochran Armitage test for trend) 
and with the family-wise error rate (FWER) controlled by a multiple-comparison correction (e.g., Bonferroni, permutation).</li>
  <li>A multiple-marker test,
    <ul>
      <li>which tests multiple variant sites simultaneously with the use of multivariate methods,</li>
      <li>such as the Fisher product method,</li>
      <li>Hotelling’s T test 
or logistic regression.</li>
    </ul>
  </li>
  <li>Collapsing variants can increase power.</li>
  <li>Classification of variants can be a major problem.</li>
  <li>If classified correct power of causal detection is higher than single- and multiple-marker testing.</li>
  <li>If miss-classified, non-functional variants could introduce error.</li>
</ul>

<h2 id="genetic-model">Genetic model</h2>

<ul>
  <li>In a locus M variants can independently cause disease.</li>
  <li>A = allele</li>
  <li>1-M = allele label</li>
  <li>p = allele frequency</li>
  <li>Gk = 0/1/2 genotype</li>
  <li>Fki = penertance of geno for ith variant.</li>
  <li>Relative risk of each variant i in models: additive, multiplicative, dominant, and recessive.</li>
  <li>Prevalence of disease caused by each individual variant is calculated.</li>
  <li>Prevalence of disease caused by entire locus can therefore be calculated.</li>
  <li>Total prevalence can be approximated by the sum of the individual prev.</li>
  <li>Same pheno can be due to different causal variants.</li>
  <li>The proportion of cases as a result of variant i can be ascertained.</li>
  <li>These cases are members of group i.</li>
  <li>There is a total of M groups.</li>
  <li>For group i the frequency of variant i can also be produced for 0,1,2.</li>
  <li>Then, the expected freq of genotype G at variant i across all M groups of cases can be found.</li>
  <li>Controls expected genotype freq at i variant can be found.</li>
  <li>The expected freqs are used to calculate the power to detect assoc in this study.</li>
  <li>Their focus is the omnibus test, which provides an association test of the entire locus and is not focused on any specific variant within the locus.</li>
</ul>

<h2 id="single-marker-test">Single-marker test</h2>

<ul>
  <li>One approach of association studies is to test each variant site individually with the use of a univariate test and assess the significance of the <em>omnibus test</em> (chi-squared test or F test) after correction for multiple comparisons.</li>
  <li>For univariate tests, a contingency table can be constructed to compare genotype frequencies at each variant site in cases and controls.</li>
  <li>Because an observation of individuals that are homozygous for the high-risk rare allele is extremely rare, AA genotypes are collapsed with Aa genotypes, and a table is constructed.</li>
  <li>For an equal number of cases and controls, the classical Pearson chi-squared statistic for testing equal genotype frequencies in cases and controls is used.</li>
</ul>

<h2 id="multiple-marker-test">Multiple-marker test</h2>

<p>Another option is to test all variants simultaneously by multivariate test</p>

<ul>
  <li>e.g. Fisher product method, Hotelling’s T-squared test, or multiple logistic regression.</li>
  <li>(This is not the same as one regression run for every single variant with multiple covariates, as done in GWAS sometimes).</li>
  <li>The authors give an example using Xiong et. al.,  (2002). Generalized T2 test for genome association studies. Am. J. Hum. Genet.</li>
  <li><em>Note: Hotellings T-squared tests the differences between the (multivariate) means of different populations, where tests for univariate problems would make use of a t-test. The distribution is named for Harold Hotelling, who developed it as a generalization of Student’s t-distribution.</em></li>
  <li>Rejecting the null hypothesis would indicate that at least one of the variants is assocciated with disease.</li>
</ul>

<h2 id="basic-collapsing-method">Basic collapsing method</h2>

<p>Since variants are expected to be very rare, 
genotypes across all variants are collapsed.
An individual is coded once if they have any one variant for the locus.</p>

<ul>
  <li>1 = rare variants present.</li>
  <li>0 = no rare variants.
The classic Pearson chi-squared statistic can be used to test the summed proportion of variants in cases vs controls. 
The power can be calculated as shown by the authors.</li>
</ul>

<h2 id="cmc-method">CMC method</h2>

<p>Unified method that combines collapsing and multivariate testing.</p>

<ul>
  <li>Markers are divided into subgroups (e.g. allele frequency).</li>
  <li>Within group, markers are collapsed.</li>
  <li>A multivariate test is then used (Hotelling’s T-squared).</li>
</ul>

<p>e.g. M markers in a locus are split into K groups.
There are n markers in group g, and so on for each group.
The multivariate test is done where for each group, the  individuals are coded with either 1 (a carrier of one or more variants) or 0 (wild-type).</p>

<h2 id="power-of-cmc-method">Power of CMC method</h2>

<p>Results:</p>

<ul>
  <li>Freq below 0.01 collapsed.</li>
  <li>Freq above 0.01 not collapsed.</li>
  <li>With misclassification, power is much better with CMC method compared to collapsing method
    <ul>
      <li>particularly when with a high frequency of the non-causal variant.</li>
    </ul>
  </li>
  <li>Slight (very slight I think) loss of power when <em>causal</em> variants are high frequency compared to collapsing.
    <ul>
      <li>This scenario is unlikely otherwise single-marker test may be possible to detect.</li>
    </ul>
  </li>
</ul>

<h2 id="misclassification">Misclassification</h2>

<p>Two types of miss-classifications are considered:</p>

<ul>
  <li>inclusion of non-functional variants and</li>
  <li>exclusion of functional variants.</li>
  <li>There is a large section on results of <em>Excluding Functional Variants</em> and <em>Inclusion of Nonfunctional Variants</em>.</li>
</ul>

<p><em>This section can be read for detail but is probably familiar enough for us to skip.</em></p>

<h2 id="effects-of-linkage-disequilibrium-ld">Effects of Linkage Disequilibrium (LD)</h2>

<p>A simulation is done in this section:</p>

<ul>
  <li>The locus has six variants, with a total allele frequency of 0.05.</li>
  <li>Four of the variants have an allele frequency of 0.01 and are on different haplotypes.</li>
  <li>Each of the remaining two variants, with allele frequencies of 0.005, is on one of the haplotypes where a variant with allele frequency of 0.01 resides;
    <ul>
      <li>there is complete LD between these variants (r 2 z0:5).</li>
    </ul>
  </li>
  <li>For comparison purposes, a second simulation was carried out, in which all variants were on separate haplotypes.</li>
  <li>One thousand replicates were generated, and the power was evaluated for an a level of 0.001.</li>
</ul>

<p>Results:</p>

<ul>
  <li>In the presence of LD, the power for the single-marker test, Hotelling’s T2 test, and the collapsing method is
    <ul>
      <li>0.075, 0.63, and 0.85, respectively.</li>
    </ul>
  </li>
  <li>Data generated with each variant on a separate haplotype, the corresponding powers are
    <ul>
      <li>0.011, 0.451, and 0.737, respectively.</li>
    </ul>
  </li>
</ul>

<h2 id="evaluation-of-type-i-error-rate">Evaluation of Type I Error Rate</h2>

<ul>
  <li>Simulation was used to generate data under the null hypothesis of no association between variants and disease status.</li>
  <li>This process was repeated for 5000 replicates.</li>
  <li>It was then evaluated whether or not each replicate had a p value % 0.05.</li>
  <li>The type I error rate was estimated by the proportion of replicates with a p value below 0.05.</li>
  <li>A type I error rate above 0.05 signifies a higher false-positive rate, and conversely, a type I error rate below 0.05 indicates a conservative test.</li>
</ul>

<p>Result:</p>

<ul>
  <li>Hotelling’s T2 test and the collapsing method:
    <ul>
      <li><em>well controlled and slightly conservative.</em></li>
    </ul>
  </li>
  <li>Logistic regression for multiple-marker test and the likelihood-ratio test performed on the basis of an asymptotic chi-squared distribution:
    <ul>
      <li><em>not well controlled.</em></li>
      <li><em>The inflation increases with decreasing allele frequencies.</em></li>
    </ul>
  </li>
  <li>CMC method, with multivariate Hotelling’s T2 test or logistic regression:
    <ul>
      <li><em>well controlled</em>.</li>
    </ul>
  </li>
</ul>

<h2 id="problems-with-this-paper">Problems with this paper</h2>

<ul>
  <li>The main problem with collapsing method is when single individuals have more than one causal variant being only counted as “1”. This more likely to occur for our protein-pathway collapse than a single gene/locus collapse.</li>
  <li>Reason 1: dosage is not counted. Someone may have homozygous and only counts for 1 rather than 2 (or some other weight).</li>
  <li>Reason 2: someone with more than one variant is only counted as 1 (if it is in the same allele frequency group for collapse). This may be rare in a single gene but is more likely in a protein network collapse. Usually it would be OK particularly if the second variant is in LD with the first and therefore <em>should</em> only be counted once.</li>
  <li>CMC code - maf threshold: In the R code, those variants with minor allele frequency below the specified maf threshold are collapsed into a single super variant. Can we group data into several frequency groups or is one <em>above/below</em> threshold only possible?</li>
</ul>

<h1 id="madsen-and-browning-2009">Madsen and Browning 2009</h1>

<ul>
  <li>A groupwise association test for rare mutations using a weighted sum statistic
<a class="citation" href="#madsen2009groupwise">(Madsen &amp; Browning, 2009)</a></li>
</ul>

<h2 id="background-1">Background</h2>

<ul>
  <li>
    <p>CAST: Cohort allelic sums test - an existing grouping method in which the number of individuals with one or more mutations in a group (e.g. gene) is compared between affected and unaffected individuals.</p>
  </li>
  <li>Cites three papers:
    <ul>
      <li>[Cohen JC, Kiss RS, Pertsemlidis A, Marcel YL, McPherson R, et al. (2004) Multiple rare alleles contribute to low plasma levels of HDL cholesterol. Science 305: 869–872.]</li>
      <li>[Li and Leal 2008]</li>
      <li>[Morgenthaler S, Thilly WG (2007) A strategy to discover genes that carry multi- allelic or mono-allelic risk for common diseases: A cohort allelic sums test (CAST). Mutation Research/Fundamental and Molecular Mechanisms of Mutagenesis 615: 28–56.]</li>
    </ul>
  </li>
  <li>
    <p>CMC: Combined Multivariate and Collapsing - the alternative method for grouping variants.
All rare variants are collapsed, 
as in the CAST method, 
and the collapsed variants are treated as a single common variant which is analysed together with the other common variants using multivariate analysis. 
In the CMC version used in [Li and Leal], 
rare variants are defined as those having a minor allele frequency (MAF) of at most 1%.</p>
  </li>
  <li>
    <p>In this study, they presume a group of candidate functional variants.</p>
  </li>
  <li>Propose a weighted-sum method in which mutations are
    <ul>
      <li>grouped according to function (e.g. gene),</li>
      <li>and each individual is scored by a weighted sum of the mutation counts.</li>
    </ul>
  </li>
  <li>To test for an excess of mutations in affected individuals, they use permutation of disease status among affected and unaffected individuals.
    <ul>
      <li>Using permutation adjusts for the weighting of the mutations and the requirement that a mutation must be observed to be included in the study.</li>
    </ul>
  </li>
</ul>

<p><em>Note that permutation of disease status results in correct type I error even in the presence of LD [Cheverud 2001, Churchill 1994], 
although relatively low LD is expected between rare variants [Li and Leal 2008, Pritchard 2001,2001].</em></p>

<h2 id="main-theory">Main theory</h2>

<ul>
  <li>
    <p>The weighted-sum method deviates from the CAST method [5,27]:
weighting the variants differently when determining the genetic load of an individual. 
By weighting the signals from each mutation, 
the weighted sum method accentuates mutations that
are rare in the unaffected individuals, 
so that the test is not completely dominated by common mutations.</p>
  </li>
  <li>In the CAST method,
    <ul>
      <li>common variants have a high impact on the group signal,</li>
      <li>and if many common mutations are present in a group, 
almost all individuals will have one or more mutations.</li>
      <li>To avoid this effect a threshold on the mutation-frequencies may be used,
as suggested in the CMC method [Li and Leal 2008].</li>
      <li>May be difficulty to select biological meaningful threshold, affecting test outcome.</li>
    </ul>
  </li>
  <li>In the weighted-sum method,
    <ul>
      <li>include mutations of all frequencies,</li>
      <li>but mutations are weighted according to their frequency in the unaffected individuals.</li>
    </ul>
  </li>
</ul>

<h2 id="methods">Methods</h2>
<h3 id="weighted-sum-method">Weighted-Sum Method</h3>
<p>Compares the number of mutations in a group of variants between case/control. 
Designed to identify an excess of mutations in case, compared to controls. 
Each variant belongs to a group (gene, pathway, etc.) and, 
for a group with L variants, the method is comprised of the following steps:</p>

<ul>
  <li>(A)
    <ul>
      <li>For each variant, choose ALT/minor allele</li>
      <li>define number in cases/controls.</li>
      <li>calculate the weight for a variant.</li>
      <li>It is used to down-weight mutation counts in constructing the weighted-sum score; see (B) and (C) below</li>
    </ul>
  </li>
  <li>Eqn 1: Weight
    <ul>
      <li>qi = ( ((no. mut allele in control) + 1)/(2(no. controls) +2) )</li>
      <li>Wi = root (total samples x qi(1-qi))</li>
      <li>For 10 case (7 mut), 10 control (5 mut),
weight for variant is 0.447</li>
    </ul>
  </li>
  <li>Mutation freq of controls is used so that true signal in cases is not deflated by using to total number.</li>
  <li>A drawback when variance of scaled mut-freq, hence loss of power when mutation freq is high.</li>
  <li>
    <p>The <em>one</em> and <em>two</em> to the numerator and denominator, respectively, avoids zero estimates - used on next steps.</p>
  </li>
  <li>(B)
    <ul>
      <li>Genetic score of each individual calculated.</li>
      <li>j - Genetic score of individual.</li>
      <li>Iij - number of mutations for variant i in individual j.</li>
      <li>Generic model uses 0/1/2.</li>
      <li>Recessive model only homozygous are assigned 1.</li>
      <li>Dominant model both het and homo are assigned 1.</li>
    </ul>
  </li>
  <li>(C)
    <ul>
      <li>All sample combined are ranked according to genetic scores.</li>
      <li>The sum of ranks for cases is calculated.</li>
      <li>Under null-hypothesis, normal distribution of random variables using a ranking procedure equivalent to that in Wilcoxon test.</li>
    </ul>
  </li>
  <li>(D)
    <ul>
      <li>Case/control status is permuted</li>
      <li>steps (A)-(C) repeated k times to sampled X1,..Xk.</li>
    </ul>
  </li>
  <li>(E)
    <ul>
      <li>The average and sample standard deviation of X1,…,Xk are calculated and standardized score-sum is found (z).</li>
      <li>Under the null hypothesis, this has an approximately standard normal distribution.</li>
      <li>Thus, a p-value for association test can be obtained by comparing z in the quantiles of standard normal.</li>
    </ul>
  </li>
  <li>
    <p>An alternative p-value calculation is also provided using a standard permutation with a stopping rule (slighly slower for their power similations). That also gives uniform (0,1) distributed p-value, which might be useful for further analysis.</p>
  </li>
  <li>Permutation of case/control labels maintains the LD structure.</li>
</ul>

<h3 id="power-simulations">Power simulations</h3>
<p>Comparison of:</p>

<ul>
  <li>Weighted-sum method,</li>
  <li>CAST,</li>
  <li>CMC,</li>
  <li>and variant-by-variant methods,</li>
</ul>

<p>For each set of parameters,</p>

<ul>
  <li>100 datasets are simulated,</li>
  <li>the four methods are applied,</li>
  <li>and the proportions of significant outcomes used as the power estimates.</li>
</ul>

<p>To mimic a genome wide study of about 20,000 fairly independent human genes, 
we calculate a p-value for each gene, 
and use a significance threshold of 0.05/20000 = 2.561026 in all power simulations.</p>

<p>Genetic Models:</p>

<ul>
  <li>Recessive, Additive and Dominant models:
    <ul>
      <li>the disease-related variants act independently,</li>
    </ul>
  </li>
  <li>Recessive-Set model:
    <ul>
      <li>outcome of a mutation at one variant depends on the presence of a mutation at another variant.</li>
    </ul>
  </li>
</ul>

<p>Frequency spectra:</p>

<ul>
  <li>Wright’s formula used to sample the unaffected population frequency spectrum of the mutations at each variant
for the Recessive, Additive and Dominant models. 
e.g. <em>The mutation probability is calculated such that the probability (pM) that a haplotype contains at least one disease-risk mutation is fixed in unaffected individuals</em>.</li>
</ul>

<p>A method for sampling is provided and ignored in this summary.</p>

<p>A method is provided to compare models with damaging variants and benign variants.</p>

<p>NB. Tested Variants.</p>

<ul>
  <li>The mutation probabilities (p) can be very low for some of the sampled variants.
This means that some variants contain no mutations in any of the sampled individuals, and these variants are hence omitted in the tests.
    <h2 id="encode-data">ENCODE data</h2>
    <p>The method was tested on rare variants with the frequency-spectrum of a naturally occurring population using the ENCODE resequencing data.</p>
  </li>
</ul>

<h2 id="results">Results</h2>

<h3 id="proportion-of-variants-containing-mutations">Proportion of Variants Containing Mutations</h3>
<p>The mutation frequencies are sampled according to Wright’s formula, 
and hence mutations are very rare for some variants. 
Using 1000 affected and 1000 unaffected individuals, 
mutations are on average observed at only 49.4% of the variants (sd: 4.9%). 
This level is in concordance with the level from human resequencing studies.</p>

<p>Skipping the section: Power under Varying Model Parameters.</p>

<h2 id="discussion">Discussion</h2>

<p>Analysis of pathways can be done in two different ways. 
One way is to use the pathway as a group, and run the test on the entire pathway. 
On the other hand, for large pathways, it may be beneficial to use a method that allows a gene with a strong signal to have a high impact on the combined pathway test-statistic (T). 
If a pathway contains G non-overlapping genes, a method to do this is to use the weighted-sum method on each gene, and combine the resulting p-values (p1,…,pG) with the Fisher product test statistic.</p>

<h2 id="summary">Summary</h2>

<ul>
  <li>Weight based on frequency of variat in the controls.</li>
  <li>Sum of ranks in cases.</li>
  <li>Case/control labels permuted n times, mean, SD, standardised score-sum found (z).</li>
  <li>p-value for association test obtained by comparing z in the quantiles of standard normal.</li>
  <li>Alternative p-value using a standard permutation with a stopping rule gives uniform (0,1) distributed p-value, which might be useful for further analysis.</li>
</ul>

<h1 id="price-2010">Price 2010</h1>

<ul>
  <li>Pooled association tests for rare variants in exon-resequencing studies.
<a class="citation" href="#price2010pooled">(Price et al., 2010)</a></li>
  <li>The approach is based on the regression of
    <ul>
      <li>phenotypic values</li>
      <li>on individuals’ genotype scores</li>
      <li>subject to a variable allele-frequency threshold,</li>
      <li>incorporating computational predictions of the functional effects of missense variants.</li>
    </ul>
  </li>
  <li>Statistical significance is assessed by permutation testing with variable thresholds.</li>
</ul>

<h2 id="methods-1">Methods</h2>

<h3 id="simulation-framework">Simulation Framework</h3>
<p>Simplified summary:</p>

<ul>
  <li>Model of European ancestry to recapitulate the site-frequency spectrum of non-synonymous human SNPs.</li>
  <li>9kb for 10K individuals.</li>
  <li>Missense only.</li>
  <li>Phenotypes
    <ul>
      <li>quantitative normal distribution</li>
      <li>carrier and non-carrier same variance</li>
      <li>carriers shifted by \(\delta\) SD</li>
    </ul>
  </li>
</ul>

<h3 id="weighted-approaches-correspond-to-implicit-assumptions-about-log-odds-ratios">Weighted Approaches Correspond to Implicit Assumptions about Log Odds Ratios</h3>
<p>(missing reference)
	- Based on the frequency in controls.
	- Relationship between log odds ratio and allele frequency the same as Madsen 2009.</p>

<h3 id="fixed-threshold-approach">Fixed-Threshold Approach</h3>
<p>(missing reference)</p>

<ul>
  <li>i indexes SNPs,</li>
  <li>Ci is the reference allele count of SNP i in cases,</li>
  <li>and xi (\(\xi_i\)) is equal to 1 if the frequency of SNP i is below a specified threshold (1% or 5%)</li>
  <li>
    <p>and is equal to 0 otherwise.</p>
  </li>
  <li>They generalise this for quantitative phenotypes.
    <ul>
      <li>add the term: pj (\(\pi_j\)) - the phenotype of sample j.
  -
I need to compare these two papers here in more detail 
(genetic score section).
(missing reference)</li>
      <li>Generic model uses 0/1/2.</li>
      <li>Recessive model only homozygous are assigned 1.</li>
      <li>Dominant model both het and homo are assigned 1.</li>
    </ul>
  </li>
</ul>

<h3 id="weighted-approach">Weighted Approach</h3>
<p>(missing reference)</p>
<ul>
  <li>Also generalise by adding \(\pi_j\) for a quantitative phenotype value.</li>
</ul>

<h3 id="variable-threshold-approach">Variable-Threshold Approach</h3>
<ul>
  <li>There exists some (unknown) threshold T for which variants with a minor allele frequency (MAF) below T are substantially more likely to be functional than are variants with an MAF above T.</li>
  <li>z-score of a regression across samples of phenotypes versus counts of mutations meeting the allele-frequency threshold T.</li>
</ul>

<h3 id="cheating-approach-to-incorporating-varphip-phip">Cheating Approach to Incorporating \(\varphi(p)\) (“phi(p)”)</h3>
<ul>
  <li>Weight variants according to the probability \(\varphi(p)\)
    <ul>
      <li>that an allele of frequency p is functional,</li>
      <li>as inferred by using the same simulated data used to evaluate power.</li>
    </ul>
  </li>
</ul>

<h3 id="incorporation-of-computational-predictions-of-functional-effects">Incorporation of Computational Predictions of Functional Effects</h3>
<ul>
  <li>Tested if incorporation of PolyPhen-2 scores improves statistical test.</li>
  <li>To asses, simulated PolyPhen-2 predictions of damaging and neutral mutations.</li>
</ul>

<h3 id="application-to-empirical-data-sets">Application to Empirical Data Sets</h3>
<p>Applied to some real data.</p>

<h2 id="results-and-discussion">Results and Discussion</h2>
<ul>
  <li>Skipping this.</li>
  <li>The methods are an improvement.
(missing reference)</li>
  <li>and additionaly adds a method for the quantitative variable.</li>
</ul>

<h1 id="neale-2011">Neale 2011</h1>

<ul>
  <li>Testing for an unusual distribution of rare variants.
(missing reference)</li>
</ul>

<h2 id="c-alpha-tests">C-alpha tests</h2>
<ul>
  <li>They propose here the C-alpha test statistic as a novel approach for testing for
    <ul>
      <li>the presence of this mixture of effects across a set of rare variants.</li>
    </ul>
  </li>
  <li>Unlike existing burden tests, C-alpha, by testing the variance rather than the mean, maintains consistent power when the target set contains both risk and protective variants.</li>
</ul>

<h1 id="skat">SKAT</h1>

<p>Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test
(missing reference)</p>

<h2 id="introduction-1">Introduction</h2>

<ul>
  <li>They propose the sequence kernel association test (SKAT),
    <ul>
      <li>regression method to test for</li>
      <li>association between genetic variants (common and rare)</li>
      <li>in a region</li>
      <li>and a continuous or dichotomous trait</li>
      <li>while easily adjusting for covariates.</li>
    </ul>
  </li>
  <li>As a score-based variance-component test, SKAT can
    <ul>
      <li>quickly calculate p values analytically by</li>
      <li>fitting the null model containing only the covariates,</li>
      <li>and so can easily be applied to genome-wide data.</li>
    </ul>
  </li>
  <li>A limitation for previous burden tests is that they implicitly assume that 
all rare variants influence the phenotype in the same direction 
and with the same magnitude of effect (after incorporating known weights).</li>
  <li>However, one would expect most variants (common or rare) within a sequenced region 
to have little or no effect on phenotype,</li>
  <li>whereas some variants are protective and others deleterious,</li>
  <li>and the magnitude of each variant’s effect is likely to vary (e.g., rarer variants might have larger effects).</li>
  <li>Collapsing across all variants is likely to introduce substantial noise.</li>
  <li>Burden tests require either specification of thresholds for collapsing</li>
  <li>or the use of permutation to estimate the threshold.</li>
</ul>

<h2 id="methods-2">Methods</h2>

<h3 id="sequencing-kernel-association-test">Sequencing Kernel Association Test</h3>
<p>*SKAT is a supervised test 
	- for the joint effects of multiple variants 
	- in a region 
	- on a phenotype. 
	-</p>
<ul>
  <li>For each region, SKAT analytically calculates a p value for association while adjusting for covariates.</li>
  <li>Adjustments for multiple comparisons are necessary for analyzing multiple regions,</li>
  <li>for example with the Bonferroni correction or FDR control.</li>
</ul>

<p>Notation:</p>

<ul>
  <li>n subjects</li>
  <li>p variants</li>
  <li>covariates</li>
  <li>\(y_i\) phenotype for sample i</li>
  <li>\(X_i\) covariats</li>
  <li>\(G_i\) genotypes (0,1,2 general)</li>
</ul>

<h3 id="skat-model-and-test-for-linear-snp-effects">SKAT Model and Test for Linear SNP Effects</h3>
<p>Eqn 1 and 2:</p>

<ul>
  <li>linear regression and</li>
  <li>logistic regression</li>
</ul>

<p>Eqn 3:</p>

<ul>
  <li>
    <p>variance-component score statistic</p>
  </li>
  <li>The weight is adjusted based on the MAF
    <ul>
      <li>if rarer variants are expected to be more likely to have larger effects.</li>
      <li>still putting decent nonzero weights for variants with MAF 1%–5%.</li>
    </ul>
  </li>
  <li>A special case of SKAT arises when the outcome is dichotomous, no covariates are included, and all \(W_j\) = 1.</li>
  <li>Under these conditions, we show in Appendix A that the SKAT test statistic Q is equivalent to the C-alpha test statistic T.</li>
</ul>

<h3 id="relationship-between-linear-skat-and-individual-variant-test-statistics">Relationship between Linear SKAT and Individual Variant Test Statistics</h3>
<ul>
  <li>One needs to fit the null model only a single time to be able to compute the Sj for all individual variants j as well as all regions to be tested.</li>
  <li>Similarly, if multiple regions are under consideration, then the same mb0 can be used to compute the SKAT Q statistics for each region.</li>
</ul>

<h3 id="accommodating-epistatic-effects-and-prior-information-under-the-skat">Accommodating Epistatic Effects and Prior Information under the SKAT</h3>
<p>Ability to model the epistatic effects of sequence variants on the phenotype within the flexible kernel machine regression framework.</p>

<p>They replace Gi’b by a more flexible function f(Gi) in the linear and logistic models (1) and (2) where f(Gi) allows for rare variant by rare variant and common variant by rare-variant interactions</p>

<h2 id="skat-is-a-generalization-of-the-c-alpha-test">SKAT Is a Generalization of the C-Alpha Test</h2>

<ul>
  <li>The recently proposed the C-alpha test has advantages over burden tests in that
    <ul>
      <li>it explicitly models the possibility that minor alleles can be deleterious or protective.</li>
    </ul>
  </li>
  <li>However, it does not currently allow for the analysis of quantitative outcomes or the inclusion of covariates and p value calculation requires permutation.</li>
  <li>They demonstrate that for a dichotomous trait in the absence of covariates,
    <ul>
      <li>the C-alpha test statistic is equivalent to the SKAT statistic with unweighted linear kernel,</li>
      <li>which is the same as the kernel machine test in Wu et al.</li>
    </ul>
  </li>
</ul>

<h1 id="lee-2012">Lee 2012</h1>
<h2 id="introduction-2">Introduction</h2>
<p>SKAT-O</p>

<ul>
  <li>
    <p>Optimal tests for rare variant effects in sequencing association studies.
<a class="citation" href="#Lee2012Optimal">(Lee et al., 2012)</a></p>
  </li>
  <li>
    <p>A class of tests that include burden tests and SKAT as special cases, and derive an optimal test within this class that maximizes power.</p>
  </li>
</ul>

<h2 id="methods-3">Methods</h2>
<ul>
  <li>They show the SKAT method</li>
  <li>They show the buden testing methods</li>
  <li>The show a method for:
    <ul>
      <li>\(Q_p\) = (1 - \(p\))\(Q_{SKAT}\) + \(pQ_{burden}\)</li>
      <li>The resulting optimal test corresponds to a best linear combination of SKAT and burden tests that maximizes power.</li>
    </ul>
  </li>
</ul>

<h1 id="protein-pathway-analysis">Protein pathway analysis</h1>
<h2 id="zhang-2021-ashg">Zhang 2021 ASHG</h2>

<p>Zhang et al. provide and excellent example of the same problem that we are
assessing. 
<a class="citation" href="#zhang2021computational">(Zhang et al., 2021)</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0002929721001543?dgcid=author">A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity</a></p>

<p>I have never had a paper so similar to a project that we are currently working on.
Basically the only difference is:</p>

<ol>
  <li>the cluster size method (theirs might work better, using total edge weights instead of protein count),</li>
  <li>cluster separation by NHC instead of MCL,</li>
  <li>using KEGG+REACTOME to additionally define the description of the cluster (but this can be done at the end).</li>
  <li>The method in main analysis is carrier count instead of SKAT style (we have compared both).</li>
</ol>

<p>Same cohort size. Really nice to see it in ASHG. Will have to do a comparison to per-gene SKAT-O to show the improvement, as they do.</p>

<h2 id="problems-with-this-paper-1">Problems with this paper</h2>

<h3 id="cluster-method">Cluster method</h3>
<p>I surprised to see them apply their own novel clustering method (NHC) without some formal methods paper first - so many already exist, including 10 that can be used with their String data. 
In theory it sound good but there is no real evidence.</p>

<h3 id="carrier-counts-instead-of-allele-dosage">Carrier counts instead of allele dosage</h3>
<p>Their main analysis is:</p>

<ul>
  <li>(a) with PC-adj = glm(Pheno ~ Carrier-status + PCs, family=binomial).
    <ul>
      <li>The information for carrier status is missing, presumably 0/1 resulting in a sort of burden test.</li>
    </ul>
  </li>
  <li>(b) without PC-adj = fisher exact test.
    <ul>
      <li>When doing this we got great results with for our earlier tests but thought it might be too simplistic.</li>
    </ul>
  </li>
  <li>Using pathway SKAT-O (accounts for frequency/dosage) they got poorer results.</li>
</ul>

<p>Main problems here:</p>

<p>One count per gene (as data$CARRIER in analysis) presumes that any variant (homozygous or heterozygous, compound het, etc) is deleterious in the individual.
In restricted to LoF then OK, but missense variants are included in the study (and will usually be the majority of candidates).
Filters are applied to get a high quality list, but there will still be a majority of missense VUS.</p>

<p>In the section “Application to an HSE cohort (V): 
Comparison with a burden test on the HSE cohort”, SKAT-O is not a burden test; 
while their method is actually more similar to a burden test since they are labelling an individual if they carry a qualifying variant in a gene. 
This is just a terminology error but it indicates that maybe the key differences in pathway testing have not been considered, as written up here in our review.</p>

<p>One could argue that only counting once per gene could help prevent problems due to LD.
Although, the WES/WGS data would have the phasing information included to prune out LD if that was the argument.
Basically, I think this is just a simplification rather than an advantage. 
If SKAT had happened to work better they would have used those results.</p>

<p>e.g. In Fig 3, TLR3 variants = 7 cases, 1 Hom, 9 Het.
This seems to amount to a carrier status of 7 in their dataset for the glm and fisher exact.</p>

<p>Their main analysis:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># call R command to run pc-adj enrichment</span>
ro.r<span class="o">(</span><span class="s2">"data &lt;- read.table('temp_pc.txt', header=T, sep='</span><span class="se">\t</span><span class="s2">')"</span><span class="o">)</span>
ro.r<span class="o">(</span><span class="s2">"fit &lt;- glm(data</span><span class="nv">$PHENOTYPE</span><span class="s2"> ~ data</span><span class="nv">$CARRIER</span><span class="s2">+data</span><span class="nv">$PC1</span><span class="s2">+data</span><span class="nv">$PC2</span><span class="s2">+data</span><span class="nv">$PC3</span><span class="s2">, family='binomial')"</span><span class="o">)</span>
ro.r<span class="o">(</span><span class="s2">"adjusted.pval &lt;- anova(fit, test='LRT')[2, 5]"</span><span class="o">)</span>
r_pvalue <span class="o">=</span> ro.r<span class="o">(</span><span class="s2">"adjusted.pval"</span><span class="o">)</span>
pvalue <span class="o">=</span> r_pvalue[0]
pvalue <span class="o">=</span> float<span class="o">(</span><span class="s1">'%.3E'</span> % Decimal<span class="o">(</span>pvalue<span class="o">))</span>
file_out.write<span class="o">(</span>str<span class="o">(</span>pvalue<span class="o">)</span> + <span class="s1">'\t'</span><span class="o">)</span>

<span class="c"># pathway enrichment</span>
this_case_pathway_hit <span class="o">=</span> dict<span class="o">()</span>
<span class="k">for </span>each_pathway <span class="k">in </span>pathway_gene_set_dict.keys<span class="o">()</span>:
	pathway_gene_set <span class="o">=</span> pathway_gene_set_dict[each_pathway]
	case_pathway_overlap <span class="o">=</span> this_case_gene_set &amp; pathway_gene_set
	case_in <span class="o">=</span> len<span class="o">(</span>case_pathway_overlap<span class="o">)</span>
	case_out <span class="o">=</span> len<span class="o">(</span>this_case_gene_set<span class="o">)</span> - case_in
	pathway_in <span class="o">=</span> len<span class="o">(</span>pathway_gene_set<span class="o">)</span>
	pathway_out <span class="o">=</span> len<span class="o">(</span>pathway_genes<span class="o">)</span> - pathway_in
	<span class="k">if </span>case_in <span class="o">!=</span> 0:
		odd, pvalue <span class="o">=</span> stats.fisher_exact<span class="o">([[</span>case_in, case_out], 
		<span class="o">[</span>pathway_in, pathway_out]], <span class="nv">alternative</span><span class="o">=</span><span class="s1">'two-sided'</span><span class="o">)</span>
		adj_pvalue <span class="o">=</span> pvalue <span class="k">*</span> pathway_size
		<span class="k">if </span>adj_pvalue &lt; 0.00001:
			adj_pvalue <span class="o">=</span> float<span class="o">(</span><span class="s1">'%.3E'</span> % Decimal<span class="o">(</span>adj_pvalue<span class="o">))</span>
			this_case_pathway_hit[each_pathway] <span class="o">=</span> adj_pvalue

<span class="c"># They do not show any code with the SKAT parameters, presumably defaults using R.</span>
</code></pre></div></div>

<h1 id="itan--casanova-contributions">Itan &amp; Casanova contributions</h1>
<h2 id="historical-review">Historical review</h2>

<p>We are tackling this problem of protein pathway analysis from the viewpoint of 
rare immune disease and infection.
Historically, several topics in bioinformatic and functional analysis have 
been required before we could achieve our current position of 
statistically-robust genetic discovery for rare disease:</p>

<ol>
  <li>Candidate variant select for individual genomes</li>
  <li>Compiling reliable cohorts of patients with shared phenotypes</li>
  <li>Protein-protein interactions</li>
  <li>Variant collapse</li>
  <li>Protein pathway analysis</li>
  <li>Functional validation</li>
</ol>

<p>Therefore, a historical review of the timeline is beneficial to illustrate the 
technical successes that allow us to reliably produce candidate variants by
genome sequencing and to validate statistically-driven results by <em>“traditional”</em>
functional validation. 
These steps [1, 2 and 6 in our list] are exemplified by the following 
historical review. 
The complete list of steps 1-6 are touched on, 
but full validation of each step is the culmination of what we are currently 
working on and will be explicitly reviewed when we have completed our study.</p>

<p>As one of the leaders in this field, Casanova lab has provided a lot of insider
history to the story in a great twitter thread
<a href="https://twitter.com/casanova_lab/status/1397539593608695808">https://twitter.com/casanova_lab/status/1397539593608695808</a>.
The literature for discussion is first listed here to facilitate downloading 
but sources are referenced as usual throughout.</p>

<hr />

<p>2013 PNAS. The human gene connectome as a map of short cuts for morbid allele discovery.
<a class="citation" href="#itan2013human">(Itan et al., 2013)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/23509278/">https://pubmed.ncbi.nlm.nih.gov/23509278/</a></p>

<p>2014 BMC Gen. HGCS: an online tool for prioritizing disease-causing gene variants by biological distance.
<a class="citation" href="#itan2014hgcs">(Itan et al., 2014)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/24694260/">https://pubmed.ncbi.nlm.nih.gov/24694260/</a></p>

<p>2015 Front. Novel primary immunodeficiency candidate genes predicted by the human gene connectome.
<a class="citation" href="#itan2015novel">(Itan &amp; Casanova, 2015)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/25883595/">https://pubmed.ncbi.nlm.nih.gov/25883595/</a>,</p>

<p>2015 PNAS. The human gene damage index as a gene-level approach to prioritizing exome variants.
<a class="citation" href="#itan2015human">(Itan et al., 2015)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/26483451/">https://pubmed.ncbi.nlm.nih.gov/26483451/</a></p>

<p>2016 NatMet. The mutation significance cutoff: gene-level thresholds for variant predictions.
<a class="citation" href="#itan2016mutation">(Itan et al., 2016)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/26820543/">https://pubmed.ncbi.nlm.nih.gov/26820543/</a></p>

<p>2015 PNAS. Can the impact of human genetic variations be predicted?
<a class="citation" href="#itan2015can">(Itan &amp; Casanova, 2015)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/26351682/">https://pubmed.ncbi.nlm.nih.gov/26351682/</a></p>

<p>2018 Bioinf. PopViz: a webserver for visualizing minor allele frequencies and damage prediction scores of human genetic variations.
<a class="citation" href="#zhang2018popviz">(Zhang et al., 2018)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/30535305/">https://pubmed.ncbi.nlm.nih.gov/30535305/</a></p>

<p>2019 PNAS. Blacklisting variants common in private cohorts but not in public databases optimizes human exome analysis.
<a class="citation" href="#maffucci2019blacklisting">(Maffucci et al., 2019)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/30591557/">https://pubmed.ncbi.nlm.nih.gov/30591557/</a></p>

<p>2019 NAR. SeqTailor: a user-friendly webserver for the extraction of DNA or protein sequences from next-generation sequencing data.
<a class="citation" href="#zhang2019seqtailor">(Zhang et al., 2019)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/31045209/">https://pubmed.ncbi.nlm.nih.gov/31045209/</a>.</p>

<p>2020 Hum Gen. The human genetic determinism of life-threatening infectious diseases: genetic heterogeneity and physiological homogeneity?
<a class="citation" href="#casanova2020human">(Casanova &amp; Abel, 2020)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/32462426/">https://pubmed.ncbi.nlm.nih.gov/32462426/</a></p>

<p>2021 JCI. Herpes simplex encephalitis in a patient with a distinctive form of inherited IFNAR1 deficiency.
<a class="citation" href="#bastard2021herpes">(Bastard et al., 2021)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/32960813/">https://pubmed.ncbi.nlm.nih.gov/32960813/</a></p>

<p>2021 JCI. TLR3 controls constitutive IFN-β antiviral immunity in human fibroblasts and cortical neurons.
<a class="citation" href="#gao2021tlr3">(Gao et al., 2021)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/33393505/">https://pubmed.ncbi.nlm.nih.gov/33393505/</a></p>

<p>2021 AJHG. A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity
<a class="citation" href="#zhang2021computational">(Zhang et al., 2021)</a>
<a href="https://pubmed.ncbi.nlm.nih.gov/34015270/">https://pubmed.ncbi.nlm.nih.gov/34015270/</a></p>

<hr />

<p>To date, the main paper that implements protein pathway analysis for rare 
immune disease is that by
Peng Zhang and 
Yuval Itan <a class="citation" href="#zhang2021computational">(Zhang et al., 2021)</a>.</p>

<p>The history begins with determining methods for candidate variant selection - 
the main challenge in human genomics, 
especially for individual patients who can benefit from precision medicine. 
Over the last decade, we have reached a point where we can now reasonably 
discern individual candidate-causal variants from the background noise of 
genomic variability.</p>

<p>From the authors’ perspective, the project began around 2011 and its first 
step was concluded in 2013 with 
Yuval Itan’s
first “Human Gene Connectome” paper 
while he was a post-doc with Casanova lab. 
<a class="citation" href="#itan2013human">(Itan et al., 2013)</a>.
This software connected genes like streets in a map, 
based on their physiological relatedness.
It was soon followed by methodological development 
<a class="citation" href="#itan2014hgcs">(Itan et al., 2014)</a>
and application to inborn errors of immunity 
<a class="citation" href="#itan2015novel">(Itan &amp; Casanova, 2015)</a>
or both 
<a class="citation" href="#itan2015human">(Itan et al., 2015)</a>,
and a couple of necessary detours 
<a class="citation" href="#itan2016mutation">(Itan et al., 2016)</a>
and 
<a class="citation" href="#maffucci2019blacklisting">(Maffucci et al., 2019)</a>.
A review was also written by two of the main authors during the same period
<a class="citation" href="#itan2015can">(Itan &amp; Casanova, 2015)</a>.</p>

<p>When Peng Zhang joined the Casanova lab as post-doc, 
Yuval Itan had started his own lab. 
However, the pair worked together to continue producing the papers on variant
interpretation and data processing
<a class="citation" href="#zhang2018popviz">(Zhang et al., 2018)</a>
and
<a class="citation" href="#zhang2019seqtailor">(Zhang et al., 2019)</a>.</p>

<p>After completing this period of work, 
they renamed “Human Gene Connectome II” the 
“Network-based Heterogeneity Clustering”.
At this point, their aims were defined as being generally indistinguishable 
from ours. 
That is, <em>“the detection of physiological homogeneity in a cohort of patients 
sharing a clinical phenotype but with high genetic heterogeneity - 
a hallmark of severe infectious diseases”</em> (Casanova via twitter), 
as presented in their next paper on this topic
<a class="citation" href="#casanova2020human">(Casanova &amp; Abel, 2020)</a>.</p>

<p>Shen-Ying Zhang came on board as senior author on the next two papers.
With an excellent database of immune disorders and infections, 
the team could gradually build their software.
Exomes from patients with HSV-1 encephalitis were used for testing successive 
versions in
<a class="citation" href="#bastard2021herpes">(Bastard et al., 2021)</a> 
and 
<a class="citation" href="#gao2021tlr3">(Gao et al., 2021)</a>.</p>

<p>Quoting Casanova <em>“When they were capable of detecting the known TLR3-IFN needles in the HSE stack, they installed camp 1, rested a bit and reported to me on the radio, while I was watching them from the basecamp with binoculars. I encouraged them to push for the final ascent and they did.”</em></p>

<p>With the same goal as our own - 
producing unbiased methods for detection of biologically-connected causal 
genetic variation - 
they found new gene variants that interact via the TLR3-IFN protein pathway,
in individual patients. 
Shen-Ying Zhang found them to be biochemically deleterious, 
an important factor for validation of genetic-first aproaches. 
In this case, Zhang <em>et al</em> get as close to the <em>“gold-standard”</em> 
as anyone to date.</p>

<p>The functional validation of candidate variants in disease then provided a proof-of-principle indication that they could detect physiological homogeneity in the midst of genetic heterogeneity 
<a class="citation" href="#zhang2021computational">(Zhang et al., 2021)</a>.</p>

<p>Quoting Casanova 
<em>“A computational approach for detecting physiological homogeneity in the midst of genetic heterogeity.
That was terrific!”</em>.</p>

<hr />

<blockquote>
  <p>An aside on what I call the <em>“gold-standard”</em> for our field should be:</p>
  <ol>
    <li>Unbiased statistical detection of a genetic phenomenon.</li>
    <li>Validation by functional models under systematic control.</li>
  </ol>

  <p>Part [1] Depends on patient cohorts that are large enough to detect the effect based on the phenotype strength - difficult for <em>rare disease</em>.<br />
Part [2] Depends on independently testing biological mechanisms.</p>

  <p>This second step generally consists of two hurdles:</p>
  <ul>
    <li>If the same researchers perform (1) genetic stats and (2) functional work, 
there is a bias that is difficult to avoid when trying to functionally 
validate statistically positive results.</li>
    <li>If the statistical genetic associations happen to contain a false positive 
for something like severe rare immune disease, 
the sensitive functional models may detect a damaging response. 
One might find a truly damaging biological mechanism, 
but if the statistical genetic association is not correct then this 
biological mechanism should not be deemed causal; 
back-tracking at this stage would be very difficult due to self-imposed bias.</li>
  </ul>

  <p>Ideally, in the future we hope to see a separation of the two steps 
(stat genetics and wet-lab) such that each are performed independently. 
The wet-lab would also ideally focus their routines on a particular protein 
pathway/system with SOPs that improve accuracy and precision 
(e.g. clinical diagnostics labs, clinical trials) rather than setting up 
models for each new study.</p>
</blockquote>

<hr />

<p>Returning to our historical review, 
we have been producing our protocols similarly in parallel.
With patient cohorts of comparable sizes and phenotypes we will soon 
have a complementary validation of protocols.
However, great care is also being taken to test and select the most reliable 
statistical methods for association testing - 
an improvement to the fine work by
<a class="citation" href="#zhang2021computational">(Zhang et al., 2021)</a>.</p>

<p>Best practices in candidate variant selection protocols are basically 
standardised as of 2021, 
so the main remaining task is standardisation of the protein-pathway 
annotation and association testing methods - 
steps which we will soon be ready to publish after peer-review.</p>

<h1 id="burden-test-power-calculation">Burden test power calculation</h1>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">This</span><span class="w"> </span><span class="n">code</span><span class="w"> </span><span class="n">seems</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">work</span><span class="w">
</span><span class="c1"># This script tests then the minimum number of heterozygous mutations that can exist in a test set to reach significance.</span><span class="w">

</span><span class="c1"># Required inputs, can be modified to read data variable</span><span class="w">
</span><span class="c1"># SAMPLES (equal case and control)</span><span class="w">
</span><span class="c1"># SNPs (the number of SNPs in the test pathway, can modify to loop every pathway)</span><span class="w">
</span><span class="c1"># CMC settings may need adjustment to match your model</span><span class="w">

</span><span class="n">library</span><span class="p">(</span><span class="n">AssotesteR</span><span class="p">)</span><span class="w">

</span><span class="c1"># Pathway size of 5 SNPs</span><span class="w">
</span><span class="c1"># 100 case and 100 controls</span><span class="w">

</span><span class="c1"># for (SNPs in 1:3) {</span><span class="w">
 </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">SNPs</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">10</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">

  </span><span class="n">SAMPLES</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w">
  </span><span class="n">TOTAL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SAMPLES</span><span class="o">*</span><span class="n">SNPs</span><span class="w">

</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">TOTAL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># cases</span><span class="w">
    </span><span class="n">val_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="m">0</span><span class="p">)</span><span class="w">
    </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">TOTAL</span><span class="o">-</span><span class="n">i</span><span class="p">)</span><span class="w">
    </span><span class="n">val_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="m">0</span><span class="p">)</span><span class="w">
    
    </span><span class="c1"># cases</span><span class="w">
    </span><span class="n">val_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="m">0</span><span class="p">)</span><span class="w">
    </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">TOTAL</span><span class="o">-</span><span class="n">i</span><span class="p">)</span><span class="w">
    </span><span class="n">val_4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">

    </span><span class="c1"># combine</span><span class="w">
    </span><span class="n">mat1.data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">val_1</span><span class="p">,</span><span class="w"> </span><span class="n">val_2</span><span class="p">,</span><span class="w"> </span><span class="n">val_3</span><span class="p">,</span><span class="w"> </span><span class="n">val_4</span><span class="p">))</span><span class="w">
    
    </span><span class="c1"># contols then cases</span><span class="w">
    </span><span class="n">genotype</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">mat1.data</span><span class="p">,</span><span class="n">nrow</span><span class="o">=</span><span class="p">(</span><span class="n">SAMPLES</span><span class="o">*</span><span class="m">2</span><span class="p">),</span><span class="n">ncol</span><span class="o">=</span><span class="n">SNPs</span><span class="p">,</span><span class="n">byrow</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="c1">#print(genotype)</span><span class="w">
    
    </span><span class="n">stat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">genotype</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">outer</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">genotype</span><span class="p">),</span><span class="w"> </span><span class="n">rownames</span><span class="p">(</span><span class="n">genotype</span><span class="p">),</span><span class="w"> </span><span class="n">FUN</span><span class="o">=</span><span class="n">paste</span><span class="p">)),</span><span class="w"> </span><span class="kc">NULL</span><span class="p">))</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="s2">"for"</span><span class="p">,</span><span class="w"> 
                </span><span class="n">SAMPLES</span><span class="p">,</span><span class="w"> </span><span class="s2">"cases and "</span><span class="p">,</span><span class="w">
                </span><span class="n">SAMPLES</span><span class="p">,</span><span class="w"> </span><span class="s2">"controls:"</span><span class="p">))</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="s2">"with"</span><span class="p">,</span><span class="w"> </span><span class="n">SNPs</span><span class="p">,</span><span class="w"> </span><span class="s2">"candidate pathway SNPs"</span><span class="p">))</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">stat</span><span class="p">),</span><span class="w">
                 </span><span class="s2">"mutations per"</span><span class="p">,</span><span class="w"> </span><span class="n">TOTAL</span><span class="p">,</span><span class="w"> </span><span class="s2">"total nucleotides in cases"</span><span class="p">))</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="w">
                 </span><span class="s2">"0 mutation per"</span><span class="p">,</span><span class="w"> </span><span class="n">TOTAL</span><span class="p">,</span><span class="w"> </span><span class="s2">"total nucleotides in controls."</span><span class="w">
                 </span><span class="p">))</span><span class="w">

    </span><span class="c1"># number of cases</span><span class="w">
    </span><span class="n">cases</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SAMPLES</span><span class="w">
    
    </span><span class="c1"># number of controls</span><span class="w">
    </span><span class="n">controls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SAMPLES</span><span class="w">
    
    </span><span class="c1"># total (cases + controls)</span><span class="w">
    </span><span class="n">total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cases</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">controls</span><span class="w">
    
    </span><span class="c1"># phenotype vector</span><span class="w">
    </span><span class="n">phenotype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">controls</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">cases</span><span class="p">))</span><span class="w">
    </span><span class="c1">#print(phenotype)</span><span class="w">
    
    </span><span class="c1">#mycmc = CMC(phenotype, genotype, maf=0.0000001, perm=100)</span><span class="w">
    </span><span class="c1">#print(mycmc)</span><span class="w">
    </span><span class="n">myskat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SKAT</span><span class="p">(</span><span class="n">phenotype</span><span class="p">,</span><span class="w"> </span><span class="n">genotype</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"linear"</span><span class="p">)</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">myskat</span><span class="p">[</span><span class="s2">"asym.pval"</span><span class="p">])</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>However, I am filling up SNPs columns so that all cases get the variant mutation. 
I believe SKAT will give a better score to 5 unique variants rather than 5 shared variants.
Therefore, I am currently revising the code.</p>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># SKAT: Sequence Kernel Association Test </span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># [1] "for 100 cases and  100 controls:"</span><span class="w">
</span><span class="c1"># [1] "with 5 candidate pathway SNPs"</span><span class="w">
</span><span class="c1"># [1] "18 mutations per 500 total nucleotides in cases"</span><span class="w">
</span><span class="c1"># [1] "0 mutation per 500 total nucleotides in controls."</span><span class="w">
</span><span class="c1"># $asym.pval</span><span class="w">
</span><span class="c1"># [1] 0.04799332</span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># [1] "for 100 cases and  100 controls:"</span><span class="w">
</span><span class="c1"># [1] "with 10 candidate pathway SNPs"</span><span class="w">
</span><span class="c1"># [1] "36 mutations per 1000 total nucleotides in cases"</span><span class="w">
</span><span class="c1"># [1] "0 mutation per 1000 total nucleotides in controls."</span><span class="w">
</span><span class="c1"># $asym.pval</span><span class="w">
</span><span class="c1"># [1] 0.04799332</span><span class="w">
</span></code></pre></div></div>
<p>You can view to genotype matrix constructions by uncommenting</p>
<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w"> </span><span class="c1"># print(genotype).</span><span class="w">
</span></code></pre></div></div>

<p>Exmple:</p>
<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="m">198</span><span class="p">,]</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">
</span><span class="p">[</span><span class="m">199</span><span class="p">,]</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">
</span><span class="p">[</span><span class="m">200</span><span class="p">,]</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">1</span><span class="w">    </span><span class="m">1</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"for 100 cases and  100 controls:"</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"with 5 candidate pathway SNPs"</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"2 mutations per 500 total nucleotides in cases"</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"0 mutation per 500 total nucleotides in controls."</span><span class="w">
</span><span class="o">$</span><span class="n">asym.pval</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="m">0.3165047</span><span class="w">
</span></code></pre></div></div>

<p>I will instead try to construct the test set with uniq variants rather than shared. I only realised the problem at the end.
An example of what we want instead is - checking the P-value and combinations of variants. 
Then we will find the real minimum variant count required to pass significance:</p>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># With a small test set</span><span class="w">
</span><span class="c1"># 2 case, 2 control, 4 positions</span><span class="w">
</span><span class="c1"># 1 control SNP, 3 case SNP</span><span class="w">

</span><span class="n">cases</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="n">controls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="n">phenotype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">controls</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">cases</span><span class="p">))</span><span class="w">

</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">expand.grid</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="n">geno1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">)]</span><span class="w">
</span><span class="n">geno2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="m">13</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">)]</span><span class="w">
</span><span class="n">geno3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="m">14</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">)]</span><span class="w">
</span><span class="n">geno4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="m">15</span><span class="p">),</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">)]</span><span class="w">

</span><span class="n">geno1</span><span class="w">
</span><span class="p">(</span><span class="n">SKAT</span><span class="p">(</span><span class="n">phenotype</span><span class="p">,</span><span class="w"> </span><span class="n">geno1</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"linear"</span><span class="p">)[</span><span class="s2">"asym.pval"</span><span class="p">])</span><span class="w">
</span><span class="n">geno2</span><span class="w">
</span><span class="p">(</span><span class="n">SKAT</span><span class="p">(</span><span class="n">phenotype</span><span class="p">,</span><span class="w"> </span><span class="n">geno2</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"linear"</span><span class="p">)[</span><span class="s2">"asym.pval"</span><span class="p">])</span><span class="w">
</span><span class="n">geno3</span><span class="w">
</span><span class="p">(</span><span class="n">SKAT</span><span class="p">(</span><span class="n">phenotype</span><span class="p">,</span><span class="w"> </span><span class="n">geno3</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"linear"</span><span class="p">)[</span><span class="s2">"asym.pval"</span><span class="p">])</span><span class="w">
</span><span class="n">geno4</span><span class="w">
</span><span class="p">(</span><span class="n">SKAT</span><span class="p">(</span><span class="n">phenotype</span><span class="p">,</span><span class="w"> </span><span class="n">geno3</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"linear"</span><span class="p">)[</span><span class="s2">"asym.pval"</span><span class="p">])</span><span class="w">


</span><span class="c1"># &gt; geno1</span><span class="w">
</span><span class="c1">#   Var1 Var2 Var3 Var4</span><span class="w">
</span><span class="c1"># 1    0    0    0    0</span><span class="w">
</span><span class="c1"># 2    1    0    0    0</span><span class="w">
</span><span class="c1"># 3    0    1    0    0</span><span class="w">
</span><span class="c1"># 4    1    1    0    0</span><span class="w">
</span><span class="c1"># $asym.pval [1] 0.0619688</span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># &gt; geno2</span><span class="w">
</span><span class="c1">#    Var1 Var2 Var3 Var4</span><span class="w">
</span><span class="c1"># 1     0    0    0    0</span><span class="w">
</span><span class="c1"># 2     1    0    0    0</span><span class="w">
</span><span class="c1"># 9     0    0    0    1</span><span class="w">
</span><span class="c1"># 13    0    0    1    1</span><span class="w">
</span><span class="c1"># $asym.pval [1] 0.0311075</span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># &gt; geno3</span><span class="w">
</span><span class="c1">#     Var1 Var2 Var3 Var4</span><span class="w">
</span><span class="c1"># 1      0    0    0    0</span><span class="w">
</span><span class="c1"># 2      1    0    0    0</span><span class="w">
</span><span class="c1"># 1.1    0    0    0    0</span><span class="w">
</span><span class="c1"># 14     1    0    1    1</span><span class="w">
</span><span class="c1"># $asym.pval [1] 0.0311075</span><span class="w">
</span><span class="c1"># </span><span class="w">
</span><span class="c1"># &gt; geno4</span><span class="w">
</span><span class="c1">#     Var1 Var2 Var3 Var4</span><span class="w">
</span><span class="c1"># 1      0    0    0    0</span><span class="w">
</span><span class="c1"># 2      1    0    0    0</span><span class="w">
</span><span class="c1"># 1.1    0    0    0    0</span><span class="w">
</span><span class="c1"># 15     0    1    1    1</span><span class="w">
</span><span class="c1"># $asym.pval [1] 0.0311075</span><span class="w">
</span></code></pre></div></div>

<h1 id="references">References</h1>

<ol class="bibliography"><li><span id="li2008methods">Li, B., &amp; Leal, S. M. (2008). Methods for detecting associations with rare variants for common diseases: application to analysis of sequence data. <i>The American Journal of Human Genetics</i>, <i>83</i>(3), 311–321.</span></li>
<li><span id="morris2010evaluation">Morris, A. P., &amp; Zeggini, E. (2010). An evaluation of statistical approaches to rare variant analysis in genetic association studies. <i>Genetic Epidemiology</i>, <i>34</i>(2), 188–193.</span></li>
<li><span id="price2010pooled">Price, A. L., Kryukov, G. V., de Bakker, P. I. W., Purcell, S. M., Staples, J., Wei, L.-J., &amp; Sunyaev, S. R. (2010). Pooled association tests for rare variants in exon-resequencing studies. <i>The American Journal of Human Genetics</i>, <i>86</i>(6), 832–838.</span></li>
<li><span id="Lee2012Optimal">Lee, S., Wu, M. C., &amp; Lin, X. (2012). Optimal tests for rare variant effects in sequencing association studies. <i>Biostatistics</i>, <i>13</i>(4), 762–775. https://doi.org/10.1093/biostatistics/kxs014</span></li>
<li><span id="Lee2012Optimalunified">Lee, S., Emond, M. J., Bamshad, M. J., Barnes, K. C., Rieder, M. J., Nickerson, D. A., Christiani, D. C., Wurfel, M. M., &amp; Lin, X. (2012). Optimal Unified Approach for Rare-Variant Association Testing with Application to Small-Sample Case-Control Whole-Exome Sequencing Studies. <i>The American Journal of Human Genetics</i>, <i>91</i>(2), 224–237. https://doi.org/https://doi.org/10.1016/j.ajhg.2012.06.007</span></li>
<li><span id="IonitaLaza2013Sequence">Ionita-Laza, I., Lee, S., Makarov, V., Buxbaum, J. D., &amp; Lin, X. (2013). Sequence Kernel Association Tests for the Combined Effect of Rare and Common Variants. <i>The American Journal of Human Genetics</i>, <i>92</i>(6), 841–853. https://doi.org/https://doi.org/10.1016/j.ajhg.2013.04.015</span></li>
<li><span id="madsen2009groupwise">Madsen, B. E., &amp; Browning, S. R. (2009). A groupwise association test for rare mutations using a weighted sum statistic. <i>PLoS Genet</i>, <i>5</i>(2), e1000384.</span></li>
<li><span id="zhang2021computational">Zhang, P., Cobat, A., Lee, Y.-S., Wu, Y., Bayrak, C. S., Boccon-Gibod, C., Matuozzo, D., Lorenzo, L., Jain, A., Boucherit, S., &amp; others. (2021). A computational approach for detecting physiological homogeneity in the midst of genetic heterogeneity. <i>The American Journal of Human Genetics</i>.</span></li>
<li><span id="itan2013human">Itan, Y., Zhang, S.-Y., Vogt, G., Abhyankar, A., Herman, M., Nitschke, P., Fried, D., Quintana-Murci, L., Abel, L., &amp; Casanova, J.-L. (2013). The human gene connectome as a map of short cuts for morbid allele discovery. <i>Proceedings of the National Academy of Sciences</i>, <i>110</i>(14), 5558–5563.</span></li>
<li><span id="itan2014hgcs">Itan, Y., Mazel, M., Mazel, B., Abhyankar, A., Nitschke, P., Quintana-Murci, L., Boisson-Dupuis, S., Boisson, B., Abel, L., Zhang, S.-Y., &amp; others. (2014). HGCS: an online tool for prioritizing disease-causing gene variants by biological distance. <i>BMC Genomics</i>, <i>15</i>(1), 1–8.</span></li>
<li><span id="itan2015novel">Itan, Y., &amp; Casanova, J.-L. (2015). Novel primary immunodeficiency candidate genes predicted by the human gene connectome. <i>Frontiers in Immunology</i>, <i>6</i>, 142.</span></li>
<li><span id="itan2015human">Itan, Y., Shang, L., Boisson, B., Patin, E., Bolze, A., Moncada-Vélez, M., Scott, E., Ciancanelli, M. J., Lafaille, F. G., Markle, J. G., &amp; others. (2015). The human gene damage index as a gene-level approach to prioritizing exome variants. <i>Proceedings of the National Academy of Sciences</i>, <i>112</i>(44), 13615–13620.</span></li>
<li><span id="itan2016mutation">Itan, Y., Shang, L., Boisson, B., Ciancanelli, M. J., Markle, J. G., Martinez-Barricarte, R., Scott, E., Shah, I., Stenson, P. D., Gleeson, J., &amp; others. (2016). The mutation significance cutoff: gene-level thresholds for variant predictions. <i>Nature Methods</i>, <i>13</i>(2), 109–110.</span></li>
<li><span id="itan2015can">Itan, Y., &amp; Casanova, J.-L. (2015). Can the impact of human genetic variations be predicted? <i>Proceedings of the National Academy of Sciences</i>, <i>112</i>(37), 11426–11427.</span></li>
<li><span id="zhang2018popviz">Zhang, P., Bigio, B., Rapaport, F., Zhang, S.-Y., Casanova, J.-L., Abel, L., Boisson, B., &amp; Itan, Y. (2018). PopViz: a webserver for visualizing minor allele frequencies and damage prediction scores of human genetic variations. <i>Bioinformatics</i>, <i>34</i>(24), 4307–4309.</span></li>
<li><span id="maffucci2019blacklisting">Maffucci, P., Bigio, B., Rapaport, F., Cobat, A., Borghesi, A., Lopez, M., Patin, E., Bolze, A., Shang, L., Bendavid, M., &amp; others. (2019). Blacklisting variants common in private cohorts but not in public databases optimizes human exome analysis. <i>Proceedings of the National Academy of Sciences</i>, <i>116</i>(3), 950–959.</span></li>
<li><span id="zhang2019seqtailor">Zhang, P., Boisson, B., Stenson, P. D., Cooper, D. N., Casanova, J.-L., Abel, L., &amp; Itan, Y. (2019). SeqTailor: a user-friendly webserver for the extraction of DNA or protein sequences from next-generation sequencing data. <i>Nucleic Acids Research</i>, <i>47</i>(W1), W623–W631.</span></li>
<li><span id="casanova2020human">Casanova, J.-L., &amp; Abel, L. (2020). <i>The human genetic determinism of life-threatening infectious diseases: genetic heterogeneity and physiological homogeneity?</i> Springer.</span></li>
<li><span id="bastard2021herpes">Bastard, P., Manry, J., Chen, J., Rosain, J., Seeleuthner, Y., AbuZaitun, O., Lorenzo, L., Khan, T., Hasek, M., Hernandez, N., &amp; others. (2021). Herpes simplex encephalitis in a patient with a distinctive form of inherited IFNAR1 deficiency. <i>The Journal of Clinical Investigation</i>, <i>131</i>(1).</span></li>
<li><span id="gao2021tlr3">Gao, D., Ciancanelli, M. J., Zhang, P., Harschnitz, O., Bondet, V., Hasek, M., Chen, J., Mu, X., Itan, Y., Cobat, A., &amp; others. (2021). TLR3 controls constitutive IFN-βantiviral immunity in human fibroblasts and cortical neurons. <i>The Journal of Clinical Investigation</i>, <i>131</i>(1).</span></li></ol>
</p>

  <h2> - </h2>
  <p><h1 id="fischers-exact-test">Fischer’s exact test</h1>
<ul id="markdown-toc">
  <li><a href="#fischers-exact-test" id="markdown-toc-fischers-exact-test">Fischer’s exact test</a></li>
</ul>

<p><br />
https://www.statology.org/fishers-exact-test/
Statology page</p>

<p>Fisher’s Exact Test is used to determine whether or not there is a significant association between two categorical variables. It is typically used as an alternative to the Chi-Square Test of Independence when one or more of the cell counts in a 2x2 table is less than 5.</p>

<p>Fisher’s Exact Test uses the following null and alternative hypotheses:</p>

<p>H0: (null hypothesis) The two variables are independent.
H1: (alternative hypothesis) The two variables are not independent.</p>

<p>Suppose we have the following 2x2 table:</p>

<p>Group 1	Group 2	Row Total
Category 1	a	b	a+b
Category 2	c	d	c+d
Column Total	a+c	b+d	a+b+c+d = n</p>

<p>The one-tailed p value for Fisher’s Exact Test is calculated as:</p>

<p>p = (a+b)!(c+d)!(a+c)!(b+d)! / (a!b!c!d!n!)</p>

<p>This produces the same p value as the CDF of the hypergeometric distribution with the following parameters:</p>

<p>population size = n
population “successes” = a+b
sample size = a + c
sample “successes” = a</p>

<p>The two-tailed p value for Fisher’s Exact Test is less straightforward to calculate and can’t be found by simply multiplying the one-tailed p value by two. To find the two-tailed p value, we recommend using the Fisher’s Exact Test Calculator.</p>

<p>Fisher’s Exact Test: Example</p>

<p>Suppose we want to know whether or not gender is associated with political party preference. We take a simple random sample of 25 voters and survey them on their political party preference. The following table shows the results of the survey:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Democrat	Republican	Total Male	4	9	13 Female	8	4	12 Total	12	13	25 Step 1: Define the hypotheses.
</code></pre></div></div>

<p>We will perform Fisher’s Exact Test using the following hypotheses:</p>

<p>H0: Gender and political party preference are independent.
H1: Gender and political party preference are not independent.</p>

<p>Step 2: Calculated the two-tailed p value.</p>

<p>We can use the Fisher’s Exact Test Calculator with the following input:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Group1 Group1 Category1	4	9 Category2	8	4
</code></pre></div></div>

<p>One tailed p value: 0.081178
Two-tailed p value is 0.115239</p>

<p>Fisher’s Exact test example</p>

<p>The two-tailed p value is 0.115239. Since this value is less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that there is any statistically significant association between gender and political party preference.</p>

<p>Additional Resources</p>

<p>Additional Resources</p>

<p>The following tutorials explain how to perform a Fisher’s Exact Test using different statistical programs:</p>

<p>How to Perform Fisher’s Exact Test in R
https://www.statology.org/fishers-exact-test-in-r/</p>

<p>Fisher’s Exact Test Calculator
https://www.statology.org/fishers-exact-test-calculator/</p>

</p>

  <h2> - </h2>
  <p><h1 id="how-latex-is-used">How LaTeX is used</h1>
<p class="meta">28 Apr 2020</p>

<ul id="markdown-toc">
  <li><a href="#how-latex-is-used" id="markdown-toc-how-latex-is-used">How LaTeX is used</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
</ul>

<h1 id="introduction">Introduction</h1>
<p>This page simply demonstrates how LaTeX format is included on this website.
The LaTeX equation is written as normal
The code is then converted to SVG by http://latex.codecogs.com
The resulting file is saved into site.baseurl/equations</p>

<p>code cogs for latex
<img src="https://latex.codecogs.com/svg.latex?\Large&space; x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" title="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" /></p>

<p><img src="https://latex.codecogs.com/svg.latex?x%3D%5Cfrac%7B-b%5Cpm%5Csqrt%7Bb%5E2-4ac%7D%7D%7B2a%7D" alt="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" /></p>

<p><img src="/equations/svg.latex.svg" width="40%" /></p>

</p>

  <h2> - </h2>
  <p><h1 id="linear-regression">Linear regression</h1>
<ul id="markdown-toc">
  <li><a href="#linear-regression" id="markdown-toc-linear-regression">Linear regression</a></li>
  <li><a href="#simple-linear-regression" id="markdown-toc-simple-linear-regression">Simple linear regression</a></li>
  <li><a href="#drawing-the-line" id="markdown-toc-drawing-the-line">Drawing the line</a></li>
  <li><a href="#accuracy-of-the-coefficient-estimates" id="markdown-toc-accuracy-of-the-coefficient-estimates">Accuracy of the Coefficient Estimates</a></li>
  <li><a href="#se-in-hypothesis-tests-for-coefficients" id="markdown-toc-se-in-hypothesis-tests-for-coefficients">SE in hypothesis tests for coefficients</a></li>
  <li><a href="#model-accuracy" id="markdown-toc-model-accuracy">Model accuracy</a>    <ul>
      <li><a href="#residual-standard-error" id="markdown-toc-residual-standard-error">Residual Standard Error</a></li>
      <li><a href="#r2-statistic" id="markdown-toc-r2-statistic">\(R^2\) Statistic</a></li>
    </ul>
  </li>
  <li><a href="#multiple-linear-regression" id="markdown-toc-multiple-linear-regression">Multiple linear regression</a></li>
</ul>

<p><br />
This page is being formulated currently by plagerising “An Introduction to Statistical Learning”. If you find this page before a lot of changes are complete, then keep this in mind. Once major changes/completion occurs, this message will be updated to references instead.</p>

<h1 id="simple-linear-regression">Simple linear regression</h1>

<p>Predict a quantitative response \(Y\) using a predictor variable \(X\); regressing \(Y\) onto \(X\).
The <em>intercept</em> and <em>splope</em> are written as \(\beta_0\) and \(\beta_1\), respectively.
These are unknwon constants and together are knwon as the model <em>coefficients</em> or <em>parameters</em>.
The simple linear regression is written as</p>

<p>[\label{eq1}\tag{1} 
Y \approx \beta_0 + \beta_1 X]</p>

<p>Values that are estimated are labelled with a “hat”, e.g. 
\(\hat y\) - a prediction of \(Y\) based on \(X = x\).
With some sample data, one can begin to predict \(Y\) based on the predictor \(X\) using the estimated model coefficients \(\hat \beta_0\) and \(\hat \beta_1\);</p>

<p>[\label{eq2}\tag{2} 
\hat y \approx \hat\beta_0 + \hat\beta_1 x]</p>

<p>In this case, the estimated response \(\hat y\) equals the estimated intercept and slope (\(\hat \beta_0\) and \(\hat \beta_1\)) according to a sample of the predictor values (\(x\)).</p>

<h1 id="drawing-the-line">Drawing the line</h1>

<p>The estimated intercept and slope (\(\hat \beta_0\) and \(\hat \beta_1\)) are unknown, therefore we need to get these values to predict \(Y\) based on \(X\).
A number (\(n\)) of obersevations are made where we measure \(X\) and \(Y\). Measurements could be recorded as: (measure 1, x = 5, y = 10), (measure 2, x = 10, y = 20), and so on up to \(n\) obersavations;</p>

<p>[\label{eq3}\tag{3} 
(5,10), (10,20),…, (x_n,y_n)]</p>

<p>[(x_1,y_1), (x_2,y_2),…, (x_n,y_n)]</p>

<p>We want to combine each measurment on a plot so that the line drawn through the data fits well and produces coefficient estimates \(\hat \beta_0\) and \(\hat \beta_1\).
Each measurement (\(i\)) is represented with \(y_i \approx \hat \beta_0 + \hat \beta_1 x_i\) for \(i = 1,2,...,n\).
The ideal result will be a line that fits all points closely. 
The measure of <em>closeness</em> has many topics of interest, but the most common method is to minimise the <em>least squares</em>.</p>

<p>\(e_i = y_i - \hat y_i\) represents the \(i\)th <em>residual</em> - the difference between our \(i\)th response according to our model versus the true \(i\)th observed response.
The <em>residual sum of squares</em> (RSS) is written as
\(\label{eq4}\tag{4} 
RSS = e^2 _1 + e^2 _2 +...+ e^2 _n\)</p>

<p>[RSS = (y_1-\hat\beta0-\hat\beta_1x_1)^2+(y_2-\hat\beta_0-\hat\beta_1x_2)^2+…+(y_n-\hat\beta_0-\hat\beta_1x_n)^2.]</p>

<p>The least squares method uses \(\hat\beta_0 and \hat\beta_1\) such that RSS is minimised. The minimisers are as follows</p>

<p>[\label{eq5}\tag{5} 
 \hat \beta_1  = 
\frac{ 
\sum_{i=1}^{n}	(	xi -\bar{x} )	(yi - \bar{y}	)	} 
{\sum_{i=1}^{n}	(	xi -\bar{x} )^2
}]</p>

<p>[\hat\beta_0 - \bar{y} - \hat\beta_1 \bar{x}]</p>

<p>where the sample means are
\(\bar{y} \equiv \frac{1}{n}\sum_{i=1}^{n} y_i\)
and
\(\bar{x} \equiv \frac{1}{n}\sum_{i=1}^{n} x_i\)
so the equation above (\ref{eq5}) defines the least squares coefficient estimates for simple linear regression.</p>

<h1 id="accuracy-of-the-coefficient-estimates">Accuracy of the Coefficient Estimates</h1>

<p>We will want to account for error \(\epsilon\) to draw an accurate line. 
\(\epsilon\) would be the mean-zero random error for the relationship between \(Y\) and \(X\) for the unknown function \(f\).</p>

<p>[\label{eq6}\tag{6} 
Y = \beta_0 + \beta_1 X + \epsilon]</p>

<p>This equation represents the <em>population regression line</em>.
We assume that the error term will be independet of \(X\), and the model is a best approximation of the \(X - Y\) relationship.
Equation 5 shows the least squares regression coefficient estimates to model the <em>least squares line</em>.
In real data, the population regression line is not observed but from the sample observations we can calculate the least squares line.</p>

<p>We would like to know how closely these two lines could be from our sampled data. 
The mean of a random variable \(Y\) would be written as \(\mu\).
If we have \(n\) number of observations of \(Y\) (\(y_1, y_2,...,y_n\)) then we can get the estimate of \(\mu\). 
So, the estimate \(\hat \mu = \hat y\), where the sample mean is \(\hat y = \frac{1}{n} \sum_{i=1}^{n} y_i\). 
Obviously the sample mean and true population mean may not be the very same, but they should be close. 
Similary, we want to know the true \(\beta_0\) and \(\beta_1\) in a linear regression so we will estimate the \(\hat\beta_0\) and \(\hat\beta_1\) as shown in eqn \ref{eq5}, the coefficient estimates that define the least squares line.</p>

<p>Likewise, \(\hat\mu\) is used to estimate \(\mu\) in an unbiased way; each estimate might be over- or underestimated but there is no particular bias in one direction from the random samples. 
The least squares coefficient estimates for \(\beta_0\) and \(\beta_1\) will also be unbiased. 
Over a large number of observations the estimate should be very accurate but since we will have a limited number of samples the estimate accuracy estimate should be established. 
This is gerneally done using the <em>standard error</em>.
When considering the estimate mean \(\hat\mu\), the formula for SE(\(\hat\mu\)) will be</p>

<p>[\label{eq7}\tag{7} 
Var( \hat\mu ) = SE( \hat\mu )^2 = \frac{\sigma^2}{n}]</p>

<p>\(\sigma\) (sigma) is the standard deviation for every \(y_i\) of \(Y\) (approximately; further reading on Gaussian error assumption and number of observations).
This SE will shirk with more frequent observations.
In the same direction we can measure the standard errors for \(\hat\beta_0\) and \(\hat\beta_1\)</p>

<p>[\label{eq8}\tag{8} 
SE(\hat\beta_0)^2 = \sigma\left[  \frac{1}{n}</p>
<ul>
  <li>\frac {\bar x^2}{ \sum_{i=1}^{n} (x_i - \bar x)^2 } \right]]</li>
</ul>

<p>[SE(\hat\beta_1)^2 =  \frac{1}{n}</p>
<ul>
  <li>\frac {\sigma^2}{ \sum_{i=1}^{n} (x_i - \bar x)^2 }]</li>
</ul>

<p>and \(\sigma^2 = Var(\epsilon)\). (To be strictly valid, the errors \(\epsilon_i\) for each observation should be uncorrelated with common variance \(\sigma^2\))
The estimate of \(\sigma\) is the <em>residual standard error</em>, and shown by \(RSE = \sqrt{ \frac{RSS}{(n-2)} }\).</p>

<p>In turn, the SE can be used to calculate the <em>confidence interval</em>.
A range of values that will contain the true unknown value of the parameter with 95% probability is the 95% confidence interval. 
This interval for \(\hat\beta_1\) is approximately</p>

<p>[\label{eq9}\tag{9} 
\hat\beta_1 \pm 2 \cdot SE(\hat\beta_1)]</p>

<p>a 95% chance that the true \(\beta_1\) value is in this range.
The same fomula is true for \(\beta_0\), swapping terms.</p>

<h1 id="se-in-hypothesis-tests-for-coefficients">SE in hypothesis tests for coefficients</h1>

<p>The SE can be used for a <em>hypothesis test</em> on the corfficients, i.e. testing the <em>null hypothesis</em> and <em>alternative hypothesis</em>,<br />
\(\label{eq10}\tag{10} 
H_0 - there is not relationship between X and Y\)<br />
\(H_0 : \beta_1 = 0\)
\(H_0 - there is not relationship between X and Y\)
\(H_a : \beta_1 = 0\),
respectively.</p>

<p>Therefore if \(\beta_1 = 0\), according to
\ref(eqn 6)
this equation reduces to 
\(Y = \beta+0 + \epsilon\), and an association is not found between \(X\) and \(Y\).
For the null hypothesis to be true (no association) we must determine if the slope \(\beta_1\), or rather our estimate \(\hat\beta_1\) is non-zero.
If the SE\(\hat\beta_1\) is small then we are confident that \(\hat\beta_1\) is accurate, if for example \(\beta_1 \neg 0\) indicating an 
\(X - Y\) relationship.
If our estimate SE (SE \(\hat\beta_1\)) is large, then we will need to see a much greater 
\(X - Y\) association before rejecting the null hypothesis (association is true).
A <em>t</em>-statistic is used to measure how many <em>standard deviations</em> (SD) 
\(\hat\beta_1\) is from 0.
T-statistic:
\(\label{eq11}\tag{11} 
t = \frac{
\hat\beta_1 - 0}{
SE(\hat\beta_1)}\)
No relationship will give <em>t</em>-distribution \(n - 2\) degrees of freedom.
(bell curve shape, for values of n greater than \(\approx\) 30 it is similar to normal distribution).</p>

<p>The probability of observing any number equal to |<em>t</em>| or larger, assuming \(\beta_1 = 0\), is the <em>p-value</em>.
A very low p-value indicates that it is unlikely that an assocation will be measured by chance, and therefore is like a true association between predictor and response, and we can <em>reject the null hypothesis</em>.</p>

<h1 id="model-accuracy">Model accuracy</h1>

<p>After rejecting the null we want to check if the line fits well - does the model fit the data?
Ttwo related quantities can asses the fit of linear regression; <em>residual standard error</em> (RSE) and \(R^2\)
statistic.</p>
<h2 id="residual-standard-error">Residual Standard Error</h2>

<p>Because of the error term \(\epsilon\),
the LR cannot perfectly predict \(Y\) from \(X\).
RSE is an estimate of the SD of \(\epsilon\).</p>

<p>[\label{eq12}\tag{12} 
RSE = \sqrt{
\frac{1}{n-2} RSS
}
=
\sqrt{
\frac{1}{n-2}
\sum_{i=1}^n 
(y_i - \hat y_i)^2
}]</p>

<p>The RSS part is expanded on the right hand side of the equation since:
$$</p>

<p>RSS = 
\sum_{i=1}^n 
(y_i - \hat y_i)^2</p>

<p>$$.</p>

<p>The RSS is a measure of the <em>lack of fit</em> of the model equation \ref{eq6} to
the dataset.
The value calculated in eqn \ref{eq12} will become smaller when the estimate and true value become closer; 
\(\hat y_1 \approx y_1\) for 
\(i = 1,2,...,n\), in which case the model will fit the data well.</p>

<h2 id="r2-statistic">\(R^2\) Statistic</h2>
<p>We use this all the time; it will be worth getting into the discussion from 
Cosma Rohilla Shalizi in
<a href="http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/">Advanced Data Analysis from an Elementary Point of View</a>
<em>Chapter 2 The Truth about Linear Regression</em>
``2.2.1.1 R2: Distraction or Nuisance?’’. 
The short summary following just covers the basic “normal” usage, rather getting into the statistica weeds.</p>

<h1 id="multiple-linear-regression">Multiple linear regression</h1>

<p>In a linear regression we use a predictor variable X to predict a quantitative response Y.
If we want to use more than one variable (\(X_1, X_2, ...\)) 
that might affect the response Y, then we will use a multiple linear regression.</p>

<p>[\label{eq }\tag{ }]</p>

<p>[\label{eq }\tag{ }]</p>

<p>[\label{eq }\tag{ }]</p>

</p>

  <h2> - </h2>
  <p><h1 id="pca">PCA</h1>
<ul id="markdown-toc">
  <li><a href="#pca" id="markdown-toc-pca">PCA</a></li>
</ul>

<p><br />
We will look at principal component analysis (PCA) and singular value decomposition (SVD).
Example: variable 1 and 2 (e.g. gene expression), and 6 observations (6 mice).
One measurement could be plotted on a single line; low values (left) to high values (right).
You might see a cluster of half the group on one side (low expression) and the rest of the group on the other side of the plot line (high expression).
Measuring two variables (ie. two genes), the sample approach would now make an x/y 2-D graph. You might see one half of the measurement group clustering with low values for both variables (low expression of gene 1 and gene 2).
If we measure 3 genes it would be, of course, a 3-D graph. Higher dimensions cannot be easily graphed.
PCA can make the multiple dimension measurements into 2-D graphs and identify what measurements are most valuable for clustering. PCA can also tell us how accurate the 2-D graph is.</p>

<p>We calculate the average value of variable 1 (gene 1) and the average value of variable 2. With the average, we can calculate the center of the data. Once this is done, we no longer need the original values, rather just the relative position on the 2-D graph.
If the center of the data were a crosshair on the 2-D plots, we will shift the plotted values so the that crosshair rests on the origin (0,0) of the graph. Once the data is centered on the origin we will then fit a line through the origin that best fits the data.</p>

<p>To quantify how well a line is fit to the data, PCA projects the data onto the line.
It can either measure the distance from the data to the line to find the line that minimises distance, or it can find the line that maximises the distance from projected points to the origin.
Both of these actions are equivalent. i.e. a point at 3,2 has a set distance from the origin (line a).
The line that we use to separate the whole dataset could be labelled line c.
Our original point at 3,2 would be joints to its projected position on line c by line b at a 90 degree angle.
As our separator line c rotates around the origin to find the best fit to the dataset, the line b will grow or shrink with the projected distance.
Line a does not change, (joining origin to 3,2).
Therefore b and c form a right angle and Pythagorean theorem shows how b and c are inversely related</p>

<p>\(a^2 = b^2 + c^2\).</p>

<p>Thus, PCA can can either minimise the distance from the data to the line (via line b), or it can find the line that maximises the distance from projected points to the origin (via line c). C is the easiest to calculate (sum of squared distances of projected position to the origin, i.e. \(sum of d_{1}^2 + d_{2}^2 + d_{3}^2 ... d_{n}^2\)), “Sum of squared distances”. The values are squared to cancel negative values.
The line is rotated and the same process is repeated to find the largest sum of squared distances, the Principal Component 1 (PC1).
The slope of PC1 is recorded, e.g. slope 0.5 - for every 2 units from origin along x we move up 1 unit, and data are spread more along axis-x then axis-y. PC1 is a linear combination of variables means that to get PC1 we would have 2 parts of x-axis variable and 1 part y-axis variable (i.e. gene 1 and gene 2).</p>

<p>If we were to use singular value decomposition (SVD), we could say that the line separator line distance for 1,0.5 would be:</p>

<p>\(a^2 = b^2 + c^2\),</p>

<p>\(a^2 = 2^2 + 1^2\),</p>

<p>\(a = \sqrt{2^2 + 1^2}\),</p>

<p>[a = 2.236]</p>

<p>Doing PCA with SVD, PC1 would be scaled so that the length of the line is = 1.
Each side of the Pythagorean triangle would be divided by 2.236;</p>

<p>(2.236/2.236)^2 =  (2/2.236)^2 + (1/2.236)^2</p>

<p>PC1 we would have 2/2.236 (0.894) parts of x-axis variable and 1/2.236 (0.447) part y-axis variable (i.e. gene 1 and gene 2).
The ratio is still the same
as 2 out, 1 up.
The 1 unit along vector (the slope normalised to 1, 0.894 gene 1 and 0.447 gene 2) is the “Singular Vector” or the “Eigenvector” for PC1.
The proportions of each gene/varaible are “Loading Scores).
Squared sum distances for PC1 = Eigenvalue for PC1.
“Square root of Eigenvalue for PC1” = “Singular Value for PC1”</p>

<p>PC2 is perpendicular to PC1. 90 degrees rotated e.g. 2 up, -1 out. Scaling to get a unit vector it would be
-0.447 gene 1 and 0.894 gene 2, the Eigenvector for PC2.</p>

<p>Variation for PC1 = Square sum of dist for PC1 divided by n-1 (e.g. 12)</p>

<p>Variation for PC2 = Square sum of dist for PC2 divided by n-1 (e.g. 3)</p>

<p>The total variation around both PCs is 12+3=15. PC1 accounts for 12/15 = 0.8, 80% of variation around the PCs; PC2 accounts for 20%.
A “scree plot” shows the percentage of variation that each PC accounts for.
For a third variable, center the data, find the best fit line through the origin. The best fit is PC1. But the recipe now has 3 components. Variable 3 (gene 3) might have the most important contribution (e.g. 0.5 part gene 1, 0.1 part gene 2, 0.8 part gene 3). Find PC2, the next best fit line through the origin, that is perpendicular to PC1. This time, gene 1 might be the most important part of PC2. Lastly, PC3 is the best fit line through the origin and perpendicular to PC1 and PC2.
The PCs can be either the numbers variables or the number of samples - whichever is smallest.</p>

<p>With all of the PCs calculated, the Eigenvalues (sum of squared distances) can be used to determine the proportion of variation that each PC accounts for. The scree plot of variation accounted for by each PC, you can decide how many PCs are useful, e.g. PC1 and PC2 may account for 95% of variation.
You may keep just PC1 and PC2, projecting the data onto these, so that PC1 and PC2 are horizontal and perpendicular. The final plot might just need one 2-D graph to account for the majority of data, although we can use several plots if needed to view more complexity from PC3, PC4 etc..
Lastly, some analysis like GWAS can incorporate multiple PCs as individual covariates (with Plink or GCTA this would be a table with one data column per PC, and one row per sample ID) to account for complexity.
In that case, our visualisation plots are more for sanity and understanding the diversity within the dataset.</p>
</p>

  <h2> - </h2>
  <p><h1 id="statistics-books">Statistics books</h1>
<p>Statistical Inference, Casella &amp; Berger<br />
<a href="https://fsalamri.files.wordpress.com/2015/02/casella_berger_statistical_inference1.pdf">https://fsalamri.files.wordpress.com/2015/02/casella_berger_statistical_inference1.pdf</a><br />
Advanced Data Analysis from an Elementary Point of View by Cosma Rohilla Shalizi. <br />
<a href="http://www.stat.cmu.edu/%7Ecshalizi/ADAfaEPoV/">http://www.stat.cmu.edu/%7Ecshalizi/ADAfaEPoV/</a>
Mathematical statistics and data analysis<br />
<a href="https://epdf.tips/mathematical-statistics-and-data-analysis65096.html">https://epdf.tips/mathematical-statistics-and-data-analysis65096.html</a><br />
 The Probability and Statistics Cookbook<br />
<a href="http://statistics.zone">http://statistics.zone</a><br />
 The Elements of Statistical Learning Data Mining, Inference, and Prediction<br />
<a href="https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print11.pdf">https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print11.pdf</a><br />
<a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a><br />
Core Statistics, Simon N. Wood<br />
<a href="https://people.maths.bris.ac.uk/~sw15190/core-statistics.pdf">https://people.maths.bris.ac.uk/~sw15190/core-statistics.pdf</a><br />
Calculus Made Easy Thompson<br />
<a href="http://www.gutenberg.org/ebooks/33283?msg=welcome_stranger">http://www.gutenberg.org/ebooks/33283?msg=welcome_stranger</a><br />
 Bayesian Approaches to Clinical Trials and Health-Care Evaluation<br />
<a href="http://the-eye.eu/public/Books/Medical/texts/Bayesian%20Approaches%20to%20Clinical%20Trials%20and%20HealthCare%20Eval.%20-%20D.%20Spiegelhalter%20%282004%29%20WW.pdf">http://the-eye.eu/public/Books/Medical/texts/Bayesian%20Approaches%20to%20Clinical%20Trials%20and%20HealthCare%20Eval.%20-%20D.%20Spiegelhalter%20%282004%29%20WW.pdf</a><br />
Bayesian Data Analysis<br />
<a href="https://www.academia.edu/32086149/Bayesian_Data_Analysis_Third_Edition_Gelman_.pdf">https://www.academia.edu/32086149/Bayesian_Data_Analysis_Third_Edition_Gelman.pdf</a><br />
Doing Bayesian data analysis a tutorial with R and BUGS.pdf<br />
<a href="http://www.users.csbsju.edu/~mgass/robert.pdf">http://www.users.csbsju.edu/~mgass/robert.pdf</a></p>

</p>

  <h2> - </h2>
  <p><h1 id="zero-inflated-negative-binomial-regression">Zero-inflated negative binomial regression</h1>
<ul id="markdown-toc">
  <li><a href="#zero-inflated-negative-binomial-regression" id="markdown-toc-zero-inflated-negative-binomial-regression">Zero-inflated negative binomial regression</a></li>
  <li><a href="#zero-inflated-negative-binomial-regression-1" id="markdown-toc-zero-inflated-negative-binomial-regression-1">Zero-inflated negative binomial regression</a></li>
  <li><a href="#analysis-methods-you-might-consider" id="markdown-toc-analysis-methods-you-might-consider">Analysis methods you might consider</a></li>
</ul>

<h1 id="zero-inflated-negative-binomial-regression-1">Zero-inflated negative binomial regression</h1>

<p>Zero-inflated negative binomial regression (zinbr) is for modeling count variables with excessive zeros and it is usually for overdispersed count outcome variables.</p>

<p>The excess zeros are generated by a process that can be explained separately from the count values. The excess zeros can be modeled independently.</p>

<p>We have data on 250 groups that went to a park. 
Fish count - how many fish a group caught
Child count - how many children were in the group, 
Person count  - many people were in the group, 
Camper binary - whether or not they brought a camper to the park.</p>

<p>In addition to predicting the number of fish caught, 
there is interest in predicting the existence of excess zeros, i.e., the probability that a group caught zero fish.</p>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zinb</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"https://stats.idre.ucla.edu/stat/data/fish.csv"</span><span class="p">)</span><span class="w">
</span><span class="n">zinb</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">within</span><span class="p">(</span><span class="n">zinb</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">nofish</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">nofish</span><span class="p">)</span><span class="w">
  </span><span class="n">livebait</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">livebait</span><span class="p">)</span><span class="w">
  </span><span class="n">camper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">camper</span><span class="p">)</span><span class="w">
</span><span class="p">})</span><span class="w">

</span><span class="n">summary</span><span class="p">(</span><span class="n">zinb</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>A zero-inflated model assumes that zero outcome is due to two different processes.</p>

<ul>
  <li>a subject has gone fishing vs.</li>
  <li>not gone fishing.</li>
</ul>

<p>If gone fishing = count process.
If not gone fishing = the only outcome possible is zero.</p>

<p>The two parts of the a zero-inflated model are</p>
<ol>
  <li>Binary model
    <ul>
      <li>usually a logit model: models which of the two processes the zero outcome is associated with.</li>
    </ul>
  </li>
  <li>Count model
    <ul>
      <li>in this case, a negative binomial model: models the count process.</li>
    </ul>
  </li>
</ol>

<p>The expected count is expressed as a combination of the two processes.</p>

<p>Taking the example of fishing again:</p>

<p>$
E(n_{\text{fish caught}} = k) = P(\text{not gone fishing}) * 0 + P(\text{gone fishing}) * E(y = k | \text{gone fishing})
$</p>

<h3 id="a-negative-binomial-model">A negative binomial model.</h3>
<p>There are multiple parameterizations of the negative binomial model, 
we focus on NB2. 
The negative binomial probability density function is:</p>

<p>$
PDF(y; p, r) = \frac{(y_i + r – 1)!}{y_i!(r-1)!}p_{i}^{r}(1 – p_i)^{y_i}
$
where  (p) is the probability of (r) successes.</p>

<p>From this we can derive the likelihood function, which is given by:
$
L(\mu; y, \alpha) = \prod_{i=1}^{n}exp\left(y_i ln\left(\frac{\alpha\mu_i}{1 +\alpha\mu_i}\right)-\frac{1}{\alpha}ln(1 + \alpha\mu_i) + ln\Gamma(y_i + \frac{1}{\alpha})-ln\Gamma(y_i + 1) – ln\Gamma(\frac{1}{\alpha})\right)
$</p>

<p>here we find the likelihood of the expected value, 
\(\mu\) (mu)
 given the data and 
\(\alpha\) (alpha)
which allows for dispersion. 
Typically, this would be expressed as a log likelihood, denoted by
\(\mathcal{L}\)
(script L)
(<a href="https://stats.stackexchange.com/questions/284816/why-do-people-use-mathcall-thetax-for-likelihood-instead-of-px-theta">sidenote</a>):</p>

<p>$
\mathcal{L}(\mu; y, \alpha) = \sum_{i=1}^{n}y_i ln\left(\frac{\alpha\mu_i}{1 + \alpha\mu_i}\right)-\frac{1}{\alpha}ln(1 + \alpha\mu_i) + ln\Gamma(y_i + \frac{1}{\alpha})-ln\Gamma(y_i + 1) – ln\Gamma(\frac{1}{\alpha})
$</p>

<p>which can be expressed in terms of our model by replacing
\(\mu_i\)
with 
\(exp(x_i'\beta)\).</p>

<p>Turning to the zero-inflated negative binomial model, 
the expression of the likelihood function depends on whether the observed value is a zero or greater than zero. 
From the logistic model of 
\(y_i &gt; 1\) versus \(y = 0\):</p>

<p>$p = \frac{1}{1 + e^{-x_i’\beta}}$ 
and 
$1 - p = \frac{1}{1 + e^{x_i’\beta}}$ then</p>

<p>$
\mathcal{L} = \left{ \begin{array}{ll} \sum_{i=1}^{n} \left[ ln(p_{i}) + (1 – p_i)\left(\frac{1}{1 + \alpha\mu_{i}}\right)^{\frac{1}{\alpha}} \right] &amp;\mbox{if } y_{i} = 0 <br />
\sum_{i=1}^{n} \left[ ln(p_{i}) + ln\Gamma\left(\frac{1}{\alpha} + y_i\right) – ln\Gamma(y_i + 1) – ln\Gamma\left(\frac{1}{\alpha}\right) + \left(\frac{1}{\alpha}\right)ln\left(\frac{1}{1 + \alpha\mu_{i}}\right) + y_iln\left(1 – \frac{1}{1 + \alpha\mu_{i}}\right) \right] &amp;\mbox{if } y_{i} &gt; 0 \end{array} \right. ] ]
$</p>

<p>Finally, note that R does not estimate 
\(\alpha\)
 but its inverse:
 \(\theta\).</p>

<p>Now let’s build up our model. 
We are going to use the variables</p>
<ul>
  <li>child and</li>
  <li>camper 
to model the count in the part of negative binomial model and the</li>
  <li>variable persons 
in the logit part of the model.
We use the pscl to run a zero-inflated negative binomial regression. We begin by estimating the model with the variables of interest.</li>
</ul>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">zeroinfl</span><span class="p">(</span><span class="n">count</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">child</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">camper</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">persons</span><span class="p">,</span><span class="w">
  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">zinb</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"negbin"</span><span class="p">,</span><span class="w"> </span><span class="n">EM</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
  </span><span class="n">summary</span><span class="p">(</span><span class="n">m1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="analysis-methods-you-might-consider">Analysis methods you might consider</h1>
<p>Some other methods that you might use.</p>

<p>OLS Regression – You could try to analyze these data using OLS regression. However, count data are highly non-normal and are not well estimated by OLS regression.
Zero-inflated Poisson Regression – Zero-inflated Poisson regression does better when the data is not overdispersed, i.e. when variance is not much larger than the mean.
Ordinary Count Models – Poisson or negative binomial models might be more appropriate if there are not excess zeros.</p>

</p>

 -->
</feed>
